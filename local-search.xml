<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Qt学习笔记</title>
    <link href="/2023/11/20/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/11/20/Qt%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p><strong>目录</strong></p><p><a href="#1%E3%80%81%E5%88%9B%E5%BB%BA%E7%AC%AC%E4%B8%80%E4%B8%AAQt%E7%A8%8B%E5%BA%8F">1、创建第一个Qt程序</a></p><p><a href="#2%E3%80%81%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%E4%BB%A5%E5%8F%8A%E5%BF%AB%E6%8D%B7%E9%94%AE">2、命名规范以及快捷键</a></p><p><a href="#3%E3%80%81QPushBottom%E7%9A%84%E5%88%9B%E5%BB%BA">3、QPushBottom的创建</a></p><p><a href="#%C2%A04%E3%80%81%E5%AF%B9%E8%B1%A1%E6%A0%91">4、对象树</a></p><p><a href="#5%E3%80%81Qt%E4%B8%AD%E7%9A%84%E5%9D%90%E6%A0%87%E7%B3%BB">5、Qt中的坐标系</a></p><p><a href="#6%E3%80%81%E4%BF%A1%E5%8F%B7%E5%92%8C%E6%A7%BD">6、信号和槽</a></p><p><a href="#6.1%20%E5%AE%9E%E7%8E%B0%E7%82%B9%E5%87%BB%E6%8C%89%E9%92%AE%E5%85%B3%E9%97%AD%E7%AA%97%E5%8F%A3">6.1 实现点击按钮关闭窗口</a></p><p><a href="#%C2%A06.2%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%92%8C%E6%A7%BD">6.2 自定义的信号和槽</a></p><p><a href="#6.3%20%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E4%BF%A1%E5%8F%B7%E5%92%8C%E6%A7%BD%E5%8F%91%E7%94%9F%E9%87%8D%E8%BD%BD%E7%9A%84%E8%A7%A3%E5%86%B3">6.3 自定义的信号和槽发生重载的解决</a></p><p><a href="#%C2%A06.4%20%E4%BF%A1%E5%8F%B7%E8%BF%9E%E6%8E%A5%E4%BF%A1%E5%8F%B7">6.4 信号连接信号</a></p><p><a href="#6.5%20Qt4%E7%89%88%E6%9C%AC%E4%BF%A1%E5%8F%B7%E8%BF%9E%E6%8E%A5">6.5 Qt4版本信号连接</a></p><p><a href="#%C2%A06.5%20Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F">6.5 Lambda表达式</a></p><p><a href="#%C2%A06.6%20%E4%BF%A1%E5%8F%B7%E6%A7%BD%E7%9A%84%E6%80%BB%E7%BB%93">6.6 信号槽的总结</a></p><p><a href="#7%E3%80%81QMainWindow">7、QMainWindow</a></p><p><a href="#7.1%C2%A0%E8%8F%9C%E5%8D%95%E6%A0%8F%E5%92%8C%E5%B7%A5%E5%85%B7%E6%A0%8F">7.1 菜单栏和工具栏</a></p><p><a href="#7.2%20%E7%8A%B6%E6%80%81%E6%A0%8F%E3%80%81%E9%93%86%E6%8E%A5%E9%83%A8%E4%BB%B6%E3%80%81%E6%A0%B8%E5%BF%83%E9%83%A8%E4%BB%B6%C2%A0">7.2 状态栏、铆接部件、核心部件</a> </p><p><a href="#8%E3%80%81%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E7%9A%84%E6%B7%BB%E5%8A%A0%C2%A0">8、资源文件的添加</a> </p><p><a href="#9%E3%80%81%E6%A8%A1%E6%80%81%E5%92%8C%E9%9D%9E%E6%A8%A1%E6%80%81%E5%AF%B9%E8%AF%9D%E6%A1%86%E5%88%9B%E5%BB%BA">9、模态和非模态对话框创建</a></p><p><a href="#10%E3%80%81%E6%B6%88%E6%81%AF%E5%AF%B9%E8%AF%9D%E6%A1%86">10、消息对话框</a></p><p><a href="#11%E3%80%81%E5%85%B6%E4%BB%96%E5%AF%B9%E8%AF%9D%E6%A1%86">11、其他对话框</a></p><p><a href="#12%E3%80%81%E7%99%BB%E9%99%86%E7%AA%97%E5%8F%A3%E5%B8%83%E5%B1%80">12、登陆窗口布局</a></p><p><a href="#13%E3%80%81%E6%8E%A7%E4%BB%B6">13、控件</a></p><p><a href="#13.1%20%E6%8C%89%E9%92%AE%E7%BB%84">13.1 按钮组</a></p><p><a href="#%C2%A013.2%20QListWidget%E6%8E%A7%E4%BB%B6">13.2 QListWidget控件</a></p><p><a href="#%C2%A013.3%20QTreeWidget%E6%8E%A7%E4%BB%B6">13.3 QTreeWidget控件</a></p><p><a href="#%C2%A013.4%20QTableWidget%E6%8E%A7%E4%BB%B6">13.4 QTableWidget控件</a></p><p><a href="#%C2%A013.5%20%E5%85%B6%E4%BB%96%E6%8E%A7%E4%BB%B6%E4%BB%8B%E7%BB%8D">13.5 其他控件介绍</a></p><p><a href="#14%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%A7%E4%BB%B6">14、自定义控件</a></p><p><a href="#%C2%A015%E3%80%81Qt%E7%9A%84%E9%BC%A0%E6%A0%87%E4%BA%8B%E4%BB%B6">15、Qt的鼠标事件</a></p><p><a href="#16%E3%80%81%E5%AE%9A%E6%97%B6%E5%99%A8">16、定时器</a></p><p><a href="#17%E3%80%81event%20%E4%BA%8B%E4%BB%B6%E5%88%86%E5%8F%91%E5%99%A8%E5%92%8C%E4%BA%8B%E4%BB%B6%E8%BF%87%E6%BB%A4%E5%99%A8%C2%A0">17、event 事件分发器和事件过滤器</a> </p><p><a href="#%E2%80%8B%E7%BC%96%E8%BE%91">​编辑</a></p><p><a href="#18%E3%80%81QPainter">18、QPainter</a></p><p><a href="#18.1%20%E7%BB%98%E5%9B%BE%E4%BA%8B%E4%BB%B6%C2%A0">18.1 绘图事件</a> </p><p><a href="#%C2%A018.2%20%E7%BB%98%E5%9B%BE%E9%AB%98%E7%BA%A7%E8%AE%BE%E7%BD%AE">18.2 绘图高级设置</a></p><p><a href="#%C2%A018.3%20%E6%89%8B%E5%8A%A8%E8%B0%83%E7%94%A8%E7%BB%98%E5%9B%BE%E4%BA%8B%E4%BB%B6">18.3 手动调用绘图事件</a></p><p><a href="#18.4%20%E7%BB%98%E5%9B%BE%E8%AE%BE%E5%A4%87%C2%A0">18.4 绘图设备</a> </p><p><a href="#19%E3%80%81QFile%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%E6%93%8D%E4%BD%9C">19、QFile文件读写操作</a></p><p><a href="#%E6%96%87%E4%BB%B6QFile%E5%92%8C%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%E8%AF%BB%E5%86%99QFileInfo">文件QFile和文件信息读写QFileInfo</a></p><p><a href="#20%E3%80%81%E7%BF%BB%E9%87%91%E5%B8%81%E9%A1%B9%E7%9B%AE%C2%A0">20、翻金币项目</a> </p><p> <a href="#%C2%A0***%E9%97%AE%E9%A2%98%E6%80%BB%E7%BB%93">***问题总结</a></p><hr><h2 id="1、创建第一个Qt程序"><a href="#1、创建第一个Qt程序" class="headerlink" title="1、创建第一个Qt程序"></a>1、创建第一个Qt程序</h2><blockquote><p>Create Project-&gt;Qt Widgets Application(创建一个Qt应用，包含一个基于qt设计师的主窗体)</p><p>-&gt;Location(不能有空格和中文，可以有下划线)，**路径选择不能有中文(重要！！！)**-&gt;Build System(<strong>选择qmake</strong>，ps：一般的Qt工程你就直接使用qmake就可以了，cmake的强大功能一般人是用不到的 &#x2F;&#x2F;参考的另一篇博客)-&gt;Details(QWidget是QDialog和QMainWindow的父类，Qwidget是空窗口，QMainWindow多了工具栏，QDialog是对话框)，选择QWidget作为基类，取消Generate form使用代码编写。-&gt;Kits(选择套件)-&gt;Summary(finish)团队开发时，添加到版本控制系统（svn，vss，git）</p></blockquote><p><img src="https://img-blog.csdnimg.cn/9e6a1e572f5b43e2a47e600a65ab76a9.png"></p><p> main函数代码</p><pre><code class="hljs">#include &quot;mywidget.h&quot;#include &lt;QApplication&gt;// 包含一个应用程序类的头文件// main程序入口 argc命令行变量的数量 argv命令行变量的数组int main(int argc, char *argv[])&#123;    QApplication a(argc, argv);// a应用程序对象，在qt中，有且仅有一个    MyWidget w;// 创建窗口对象，MyWidget的父类-&gt;QWidget    w.show();// 窗口对象 默认不会显示，必须调用show方法显示    return a.exec();//让应用程序对象a进入消息循环机制，等待用户点叉叉，使得窗口不会一闪而过，使代码阻塞到这一行&#125;</code></pre><h2 id="2、命名规范以及快捷键"><a href="#2、命名规范以及快捷键" class="headerlink" title="2、命名规范以及快捷键"></a>2、命名规范以及快捷键</h2><p><strong>.pro文件不要添加任何东西，除非你知道写的是什么</strong>。.pro文件就是工程文件，它是qmake自动生</p><p>成的用于生产makefile的配置文件。</p><pre><code class="hljs">QT       += core gui //Qt包含的模块greaterThan(QT_MAJOR_VERSION, 4): QT += widgets//大于4版本以上，包含widget模块CONFIG += c++17# You can make your code fail to compile if it uses deprecated APIs.# In order to do so, uncomment the following line.#DEFINES += QT_DISABLE_DEPRECATED_BEFORE=0x060000    # disables all the APIs deprecated before Qt 6.0.0//源文件SOURCES += \    main.cpp \    mywidget.cpp//头文件 自动生成的HEADERS += \    mywidget.h</code></pre><p>Qt基本模块</p><p><img src="https://img-blog.csdnimg.cn/4a89150ea2da448198e805c3c6822571.png"></p><p> mywidget.h</p><pre><code class="hljs">#ifndef MYWIDGET_H#define MYWIDGET_H#include &lt;QWidget&gt;//窗口类头文件 QWidgetclass MyWidget : public QWidget&#123;    Q_OBJECT // Q_OBJECT宏，允许类中使用信号和槽的机制public:    MyWidget(QWidget *parent = nullptr); // 有参构造函数    ~MyWidget();&#125;;#endif // MYWIDGET_H</code></pre><p>mywidget.cpp </p><pre><code class="hljs">#include &quot;mywidget.h&quot;// 命名规范// 类名 首字母大写，单词和单词之间首字母大写// 函数名 变量名称 首字母小写，单词和单词之间首字母大写// 快捷键// 注释 ctrl + /// 运行 ctrl + r// 编译 ctrl + b// 字体缩放 ctrl + 鼠标滚轮// 查找 ctrl + f// 整行移动 ctrl + shift + ⬆或者⬇// 帮助文档 F1// 自动对齐 ctrl + i// 同名之间的.h和.cpp切换 F4// 帮助文档，左侧的帮助；在Qt5.16\mingw49_32\bin的Qt助手MyWidget::MyWidget(QWidget *parent)    : QWidget(parent)// 初始化列表&#123;&#125;MyWidget::~MyWidget()&#123;&#125;</code></pre><p>​    </p><h2 id="3、QPushBottom的创建"><a href="#3、QPushBottom的创建" class="headerlink" title="3、QPushBottom的创建"></a>3、QPushBottom的创建</h2><p> 构造函数里创建</p><pre><code class="hljs">#include &quot;mywidget.h&quot;#include &lt;QPushButton&gt;MyWidget::MyWidget(QWidget *parent)    : QWidget(parent)// 初始化列表&#123;    // 创建一个按钮    QPushButton * btn = new QPushButton;    // btn-&gt;show();// show以顶层方式弹出窗口控件    // 让btn对象 依赖在 MyWdget窗口中    btn-&gt;setParent(this);    // 显示文本    btn-&gt;setText(&quot;first button&quot;);    // 创建第二个按钮 按照控件的大小创建窗口    QPushButton * btn2 = new QPushButton(&quot;second button&quot;,this);    // 重置窗口大小 长x宽    resize(600,400);        // 移动btn2按钮,设置坐标    btn2-&gt;move(100,100);        // 设置固定窗口大小,用户不能改变串窗口大小    setFixedSize(600,400);        // 设置窗口标题    setWindowTitle(&quot;第一个窗口&quot;);&#125;MyWidget::~MyWidget()&#123;&#125;</code></pre><p>​    </p><h2 id="4、对象树"><a href="#4、对象树" class="headerlink" title="4、对象树"></a>4、对象树</h2><p>父类先构造，子类先析构</p><p>在Qt中创建对象的时候会提供一个Parent对象指针。</p><p>QObject是以对象树的形式组织起来的。</p><blockquote><p>当你创建一个QObject对象时候，会看到QObject的构造函数接收一个QObject指针作为参数，这个参数就是Parent，也就是父对象指针。</p><p>这相当于，在创建QObject对象时，可以提供一个其父对象，我们创建的这个QObject对象会自动添加到其父类对象的children()列表。</p><p>当父类对象析构的时候，这个列表中的所有对象也会被析构（<strong>注意：这里的父对象并不是继承意义的父类</strong>）</p><p>QWdget是能够在屏幕上显示的一切组件的父类。<br>QWidget继承自QObject，因此也继承了这种对象树关系。一个孩子自动地成为父组件的一个子组件。因此，它会显示在父组件的坐标系统中，被父组件的边界剪裁。例如，当用户关闭一个对话框的时侯，应用程序将共刑除，那么，我们希望属于这个对话框的按钮、图标等应该一起被迸除。事实就是如此，因为这些都是对话框的子组件。</p></blockquote><p> MyPushButton类的创建</p><pre><code class="hljs">#ifndef MYPUSHBUTTON_H#define MYPUSHBUTTON_H#include &lt;QPushButton&gt;//继承QPushButton，没有这个选择就先选择继承它的父亲class MyPushButton : public QPushButton&#123;    Q_OBJECTpublic:    explicit MyPushButton(QWidget *parent = nullptr);    ~MyPushButton();signals:&#125;;#endif // MYPUSHBUTTON_H#include &quot;mypushbutton.h&quot;#include &lt;QDebug&gt;//打印输出MyPushButton::MyPushButton(QWidget *parent)    : QPushButton(parent)//换父亲&#123;    qDebug()&lt;&lt;&quot;我的按钮类构造调用&quot;;&#125;MyPushButton::~MyPushButton()&#123;    qDebug()&lt;&lt;&quot;我的按钮类析构调用&quot;;&#125;</code></pre><p>打印先打印的是儿子的析构，但是是后面释放。 </p><pre><code class="hljs">#include &quot;mywidget.h&quot;#include &lt;QPushButton&gt;#include &lt;mypushbutton.h&gt;#include &lt;QDebug&gt;//打印输出MyWidget::MyWidget(QWidget *parent)    : QWidget(parent)// 初始化列表&#123;    // 创建一个自己的按钮对象    MyPushButton *mybtn = new MyPushButton;    mybtn-&gt;setText(&quot;我自己的按钮&quot;);    mybtn-&gt;move(200,0);    mybtn-&gt;setParent(this);    qDebug()&lt;&lt;&quot;MyWidget构造&quot;;&#125;MyWidget::~MyWidget()&#123;    qDebug()&lt;&lt;&quot;MyWidget析构&quot;;&#125;</code></pre><p>​<br>​    </p><blockquote><p><strong>总结：</strong>当创建的对象在堆区时候，如果指定的父亲是QObject派生下来的类或者QObject子类派生下来的类，**可以不用管理释放的操作(就是不用deletex)**，将对象会放入到对象树中。一定程度上简化了内存回收机制</p></blockquote><h2 id="5、Qt中的坐标系"><a href="#5、Qt中的坐标系" class="headerlink" title="5、Qt中的坐标系"></a>5、Qt中的坐标系</h2><p>左上角为(0,0)，x向右增大，y向下增大</p><h2 id="6、信号和槽"><a href="#6、信号和槽" class="headerlink" title="6、信号和槽"></a>6、信号和槽</h2><h3 id="6-1-实现点击按钮关闭窗口"><a href="#6-1-实现点击按钮关闭窗口" class="headerlink" title="6.1 实现点击按钮关闭窗口"></a>6.1 实现点击按钮关闭窗口</h3><blockquote><p><img src="https://img-blog.csdnimg.cn/8bcf33facc9a4fb4892d00e04c5426c5.png"></p><p>connect( 信号的发送者，发送的具体信号，信号的接受者，信号的处理（槽）)</p><p>信号槽的优点：松散耦合，信号发送端和接受端本身是没有关联的，通过connect连接将两端耦合在一起。 </p></blockquote><pre><code class="hljs">#include &quot;mywidget.h&quot;#include &lt;QPushButton&gt;#include &lt;mypushbutton.h&gt;#include &lt;QDebug&gt;//打印输出MyWidget::MyWidget(QWidget *parent)    : QWidget(parent)// 初始化列表&#123;    // 创建一个自己的按钮对象    MyPushButton *mybtn = new MyPushButton;    mybtn-&gt;setText(&quot;我自己的按钮&quot;);    mybtn-&gt;move(200,0);    mybtn-&gt;setParent(this);    // 点击我的按钮，关掉窗口    // 参数1：信号的发送者，参数2：发送的具体信号(点击)函数的地址;参数3：信号的接受者this窗口，参数4：信号的处理（槽）函数地址    connect(mybtn,&amp;MyPushButton::clicked,this,&amp;MyWidget::close);    //connect(mybtn,&amp;QPushButton::clicked,this,&amp;QWidget::close);// 用父类的也可以&#125;MyWidget::~MyWidget()&#123;&#125;</code></pre><p>​    </p><h3 id="6-2-自定义的信号和槽"><a href="#6-2-自定义的信号和槽" class="headerlink" title="6.2 自定义的信号和槽"></a>6.2 自定义的信号和槽</h3><blockquote><p>自定义信号：写到signals下；返回值是void，只需要声明，不需要实现；可以有参数，可以重载。</p><p>自定义槽：早期Qt槽函数必须写在public slot下，高级版本可以写道public或者全局下；返回值是void，需要声明，也需要实现；可以有参数，可以重载。</p><p>触发自定义信号：emit</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;// Teacher 类 老师类// Student 类 学生类// 下课后，老师会触发一个信号，饿了，学生响应信号，请客吃饭Widget::Widget(QWidget *parent)    : QWidget(parent)&#123;    // 创建老师和学生对象，并且指定父亲，就不用释放    this-&gt;zt = new Teacher(this);    this-&gt;st = new Student(this);    connect(zt,&amp;Teacher::Hungry,st,&amp;Student::treat);    // 调用下课,触发老师饿了，随后学生响应    classisover();&#125;Widget::~Widget()&#123;&#125;void Widget::classisover()&#123;    // 下课函数 调用后触发老师饿了信号    emit zt-&gt;Hungry();&#125;</code></pre><h3 id="6-3-自定义的信号和槽发生重载的解决"><a href="#6-3-自定义的信号和槽发生重载的解决" class="headerlink" title="6.3 自定义的信号和槽发生重载的解决"></a>6.3 自定义的信号和槽发生重载的解决</h3><blockquote><p>1.需要利用函数指针明确指向函数的地址，成员函数指针需要加上作用域</p><p>2.QString-&gt;char * 先转成QByteArray(.toUtf8())再转char*(),.data的返回值是char *</p></blockquote><p>Widget代码 </p><pre><code class="hljs">#include &quot;widget.h&quot;// Teacher 类 老师类// Student 类 学生类// 下课后，老师会触发一个信号，饿了，学生响应信号，请客吃饭Widget::Widget(QWidget *parent)    : QWidget(parent)&#123;    // 创建老师和学生对象，并且指定父亲，就不用释放    this-&gt;zt = new Teacher(this);    this-&gt;st = new Student(this);    //connect(zt,&amp;Teacher::Hungry,st,&amp;Student::treat);    // 调用下课,触发老师饿了，随后学生响应    //classisover();    // 函数指针-&gt;函数地址,&amp;+函数名    void(Teacher::*teacherSignal)(QString) = &amp;Teacher::Hungry;// 成员函数的函数指针    void(Student::*studentSlot)(QString) = &amp;Student::treat;    // 当出现重载的时候，需要出现设置信号和槽的函数地址    connect(zt,teacherSignal,st,studentSlot);//重载出现二义性    classisover();&#125;Widget::~Widget()&#123;&#125;void Widget::classisover()&#123;    // 下课函数 调用后触发老师饿了信号,两个信号    emit zt-&gt;Hungry();    emit zt-&gt;Hungry(&quot;宫保鸡丁&quot;);&#125;</code></pre><p> 槽函数重载</p><pre><code class="hljs">#include &quot;student.h&quot;#include &lt;QDebug&gt;Student::Student(QObject *parent)    : QObject&#123;parent&#125;&#123;&#125;void Student::treat()&#123;    qDebug()&lt;&lt;&quot;请老师吃饭&quot;;&#125;void Student::treat(QString foodname)// 重载treat&#123;    //打印QString类型有引号，要转成char*就没有引号    //qDebug()&lt;&lt;&quot;请老师吃饭,老师要吃：&quot;&lt;&lt;foodname;    // QString-&gt;char * 先转成QByteArray(.toUtf8())再转char*(),data的返回值是char *    qDebug()&lt;&lt;&quot;请老师吃饭,老师要吃：&quot;&lt;&lt;foodname.toUtf8().data();&#125;</code></pre><p> 信号重载</p><pre><code class="hljs">void Hungry();void Hungry(QString foodname);</code></pre><h3 id="6-4-信号连接信号"><a href="#6-4-信号连接信号" class="headerlink" title="6.4 信号连接信号"></a>6.4 信号连接信号</h3><blockquote><p>connect(btn,&amp;QPushButton::clicked,zt,teacherSignal);teacherSignal要换成无参形式，否则参数不匹配；</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &lt;QPushButton&gt;// Teacher 类 老师类// Student 类 学生类// 下课后，老师会触发一个信号，饿了，学生响应信号，请客吃饭Widget::Widget(QWidget *parent)    : QWidget(parent)&#123;    // 创建老师和学生对象，并且指定父亲，就不用释放    this-&gt;zt = new Teacher(this);    this-&gt;st = new Student(this);    //点击一个按钮，再下课，再触发老师饿了    QPushButton *btn = new QPushButton(&quot;下课&quot;,this);    this-&gt;resize(600,400); // 重置窗口大小    connect(btn,&amp;QPushButton::clicked,this,&amp;Widget::classisover);    //无参信号和槽连接    void(Teacher::*teacherSignal)(void) = &amp;Teacher::Hungry;// 成员函数的函数指针    void(Student::*studentSlot)(void) = &amp;Student::treat;    connect(zt,teacherSignal,st,studentSlot);    // 信号连接信号 之间跳过下课，按钮直接使老师饿了    connect(btn,&amp;QPushButton::clicked,zt,teacherSignal);</code></pre><p>​<br>​        &#x2F;&#x2F; 断开信号<br>​        &#x2F;&#x2F;disconnect(zt,teacherSignal,st,studentSlot);<br>​    }<br>​<br>​    Widget::~Widget()<br>​    {<br>​    }<br>​<br>​    void Widget::classisover()<br>​    {<br>​        &#x2F;&#x2F; 下课函数 调用后触发老师饿了信号,两个信号<br>​        emit zt-&gt;Hungry();<br>​        emit zt-&gt;Hungry(“宫保鸡丁”);<br>​    }</p><h3 id="6-5-Qt4版本信号连接"><a href="#6-5-Qt4版本信号连接" class="headerlink" title="6.5 Qt4版本信号连接"></a>6.5 Qt4版本信号连接</h3><blockquote><p>1.信号可以连接信号；</p><p>2.一个信号可以连接多个槽函数；</p><p>3.多个信号可以连接同一个槽函数；</p><p><strong>4.信号和槽函数的参数，必须一一对应；</strong></p><p>5.<strong>信号的参数个数可以多于槽函数的参数个数，但是类型要一一对应</strong>；</p><p>clicked的参数是bool类型，teacherSignal如果是QString参数就不是一一对应，如果是void参数就是信号的参数比槽函数的参数多，所以不会报错。</p><p>6.Qt4：connect(zt,SIGNAL(hungry()),st,SLOT(treat(QString));参数直观，但是不做类型检测，不推荐。</p></blockquote><h3 id="6-5-Lambda表达式"><a href="#6-5-Lambda表达式" class="headerlink" title="6.5 Lambda表达式"></a>6.5 Lambda表达式</h3><blockquote><p>C++11中的Lambda表达式用于定义并创建匿名函数对象，以简化编程工作。</p><p>表达式：[函数对象参数](操作符重载函数参数)mutable-&gt;返回值(函数体)</p><p><img src="https://img-blog.csdnimg.cn/99021ca875844da2975a459e809f7d52.png"></p><p> ① “&#x3D;”为值传递，“&amp;”为地址传递，a为只对a可见；</p><p> ② mutable关键字，用于修饰值传递的变量，修改拷贝而不是本体；</p><p> ③ int ret &#x3D; [ ]( )-&gt;<strong>int</strong> {return 100;}();使得ret&#x3D;100；</p></blockquote><pre><code class="hljs">Widget::Widget(QWidget *parent)    : QWidget(parent)&#123;    QPushButton *btn = new QPushButton;    this-&gt;resize(600,400); // 重置窗口大小    btn-&gt;setText(&quot;close&quot;);    btn-&gt;setParent(this);//把按钮安到窗口上    //利用lambda表达式实现关闭按钮    connect(btn,&amp;QPushButton::clicked,this,[=]()&#123;        this-&gt;close();        btn-&gt;setText(&quot;aaa&quot;);    &#125;);&#125;</code></pre><h3 id="6-6-信号槽的总结"><a href="#6-6-信号槽的总结" class="headerlink" title="6.6 信号槽的总结"></a>6.6 信号槽的总结</h3><blockquote><p>  任务：设计一个窗口，两个按钮，点击open打开另一个窗口，点击close关闭窗口。</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QPushButton&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    QPushButton *btn = new QPushButton;    btn-&gt;setText(&quot;open&quot;);    btn-&gt;setParent(this);    resize(600,400);    QPushButton *btn2 = new QPushButton;    btn2-&gt;setText(&quot;close&quot;);    btn2-&gt;setParent(this);    btn2-&gt;move(200,200);    QWidget *w2=new QWidget;    connect(btn,&amp;QPushButton::clicked,w2,&amp;QWidget::show);    connect(btn2,&amp;QPushButton::clicked,w2,&amp;QWidget::close);&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><p>​    </p><blockquote><p>    任务：设计一个窗口，一个按钮，点击open打开另一个窗口，open变成close，再点击close关闭窗口，close变成open。</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QPushButton&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    QPushButton *btn = new QPushButton;    btn-&gt;setText(&quot;open&quot;);    btn-&gt;setParent(this);    resize(600,400);    QWidget *w1 = new QWidget;    connect(btn,&amp;QPushButton::clicked,w1,[=]()&#123;        if(btn-&gt;text()==&quot;open&quot;)        &#123;            btn-&gt;setText(&quot;close&quot;);            w1-&gt;show();        &#125;        if(btn-&gt;text()==&quot;close&quot;)        &#123;            btn-&gt;setText(&quot;open&quot;);            w1-&gt;close();        &#125;    &#125;);&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><p>​    </p><h2 id="7、QMainWindow"><a href="#7、QMainWindow" class="headerlink" title="7、QMainWindow"></a>7、QMainWindow</h2><h3 id="7-1-菜单栏和工具栏"><a href="#7-1-菜单栏和工具栏" class="headerlink" title="7.1 菜单栏和工具栏"></a>7.1 菜单栏和工具栏</h3><blockquote><p>1.菜单栏最多只有一个，工具栏可以有多个</p><p>2.QMenu，QToolBar</p></blockquote><pre><code class="hljs">#include &quot;mainwindow.h&quot;#include &lt;QMenuBar&gt;#include &lt;QToolBar&gt;#include &lt;QPushButton&gt;MainWindow::MainWindow(QWidget *parent)    : QMainWindow(parent)&#123;    // 重置窗口大小    resize(600,400);    // 菜单栏的创建 最多只有一个    QMenuBar *bar = menuBar();// 本身在对象树    setMenuBar(bar); // 将菜单栏放入窗口中    QMenu *fileMenu = bar-&gt;addMenu(&quot;文件&quot;); // 创建菜单    QMenu *editMenu = bar-&gt;addMenu(&quot;编辑&quot;);    QAction * newAction = fileMenu-&gt;addAction(&quot;新建&quot;);// 创建菜单项    // 添加分割线    fileMenu-&gt;addSeparator();    QAction * newAction1 = fileMenu-&gt;addAction(&quot;打开&quot;);    editMenu-&gt;addAction(&quot;复制&quot;);    // 工具栏的创建 可以有多个    QToolBar *toolBar = new QToolBar(this);    addToolBar(Qt::LeftToolBarArea,toolBar);//默认在左边    // 只允许左右停靠    toolBar-&gt;setAllowedAreas(Qt::LeftToolBarArea | Qt::RightToolBarArea);    // 设置浮动    toolBar-&gt;setFloatable(false);    // 设置移动,bool值设置是否可以移动,相当于总开关    toolBar-&gt;setMovable(false);    // 设置内容    toolBar-&gt;addAction(newAction);    toolBar-&gt;addSeparator();    toolBar-&gt;addAction(newAction1);    // 工具栏添加控件    QPushButton* btn = new QPushButton(&quot;aa&quot;,this);    toolBar-&gt;addWidget(btn);&#125;MainWindow::~MainWindow()&#123;&#125;</code></pre><h3 id="7-2-状态栏、铆接部件、核心部件"><a href="#7-2-状态栏、铆接部件、核心部件" class="headerlink" title="7.2 状态栏、铆接部件、核心部件"></a>7.2 状态栏、铆接部件、核心部件</h3><blockquote><p>  1.QStatusBar，QDockWidget(浮动窗口)，QTextEdit;</p><p> <img src="https://img-blog.csdnimg.cn/493d66a0b08d49bc9fce17e9892b943c.png"></p></blockquote><pre><code class="hljs">    // 状态栏    QStatusBar* stBar = statusBar();    setStatusBar(stBar);//设置到窗口中    //放标签控件    QLabel *label = new QLabel(&quot;提示信息&quot;,this);    stBar-&gt;addWidget(label);    QLabel *label2 = new QLabel(&quot;右侧提示信息&quot;,this);    stBar-&gt;addPermanentWidget(label2);    // 铆接部件（浮动窗口）可以有多个    QDockWidget *dockWidget = new QDockWidget(&quot;浮动&quot;,this);    addDockWidget(Qt::BottomDockWidgetArea,dockWidget);    // 只允许上下    dockWidget-&gt;setAllowedAreas(Qt::TopDockWidgetArea | Qt::BottomDockWidgetArea);;    //设置中心部件,只能一个    QTextEdit *edit = new QTextEdit(this);    setCentralWidget(edit);</code></pre><h2 id="8、资源文件的添加"><a href="#8、资源文件的添加" class="headerlink" title="8、资源文件的添加 "></a>8、资源文件的添加 </h2><blockquote><p>1. 将图片文件拷贝到项目位置；</p><p>2. 右键项目-&gt;添加新文件-&gt;Qt-&gt;Qt recourse File-&gt;给资源文件起名</p><p>3. rec生成rec.qrc</p><p>4. open in editor打开文件</p><p>5. 添加前缀 添加文件，编译</p><p>6. 使用“:+前缀名+文件名”</p><p><img src="https://img-blog.csdnimg.cn/d8ae4c24ce504df291579ac2aecd8b46.png"></p></blockquote><p><img src="https://img-blog.csdnimg.cn/a2bdc3ff08814234a33ae64691694ff4.png"></p><h2 id="9、模态和非模态对话框创建"><a href="#9、模态和非模态对话框创建" class="headerlink" title="9、模态和非模态对话框创建"></a>9、模态和非模态对话框创建</h2><blockquote><p>1. 模态对话框：不可以对其他窗口进行操作；QDialog dlg(this);dlg.exec();</p><p>2. 非模态对话框：可以对其他窗口进行操作；QDialog *dlg2 &#x3D; new QDialog(this);dlg2-&gt;show();</p></blockquote><pre><code class="hljs">#include &quot;mainwindow.h&quot;#include &quot;ui_mainwindow.h&quot;#include &lt;QDialog&gt;#include &lt;QDebug&gt;MainWindow::MainWindow(QWidget *parent)    : QMainWindow(parent)    , ui(new Ui::MainWindow)&#123;    ui-&gt;setupUi(this);    // 点击新建按钮 弹出会话框    connect(ui-&gt;actionnew,&amp;QAction::triggered,[=]()&#123;        //对话框 分类        // 模态对话框（不可以对其他窗口进行操作） 非模态对话框（可以对其他窗口进行操作）        QDialog dlg(this);        dlg.resize(200,100);        dlg.exec();//模态方式创建，阻塞功能        qDebug()&lt;&lt;&quot;模态对话框弹出了&quot;;        // 非模态对话框        QDialog *dlg2 = new QDialog(this);//存在内存泄漏风险，创建堆区        dlg2-&gt;resize(200,100);        dlg2-&gt;show();        dlg2-&gt;setAttribute(Qt::WA_DeleteOnClose);//设置属性，差掉就释放内存        qDebug()&lt;&lt;&quot;非模态对话框弹出了&quot;;    &#125;);&#125;MainWindow::~MainWindow()&#123;    delete ui;&#125;</code></pre><h2 id="10、消息对话框"><a href="#10、消息对话框" class="headerlink" title="10、消息对话框"></a>10、消息对话框</h2><blockquote><p>QMessageBox 静态成员函数 创建对话框</p><p>错误、信息、提问、警告</p><p>利用返回值来判断用户的选择</p></blockquote><pre><code class="hljs">#include &quot;mainwindow.h&quot;#include &quot;ui_mainwindow.h&quot;#include &lt;QDialog&gt;#include &lt;QDebug&gt;#include &lt;QMessageBox&gt;MainWindow::MainWindow(QWidget *parent)    : QMainWindow(parent)    , ui(new Ui::MainWindow)&#123;    ui-&gt;setupUi(this);    // 点击新建按钮 弹出会话框    connect(ui-&gt;actionnew,&amp;QAction::triggered,[=]()&#123;        //消息对话框        //QMessageBox::critical(this,&quot;critical&quot;,&quot;错误&quot;);//错误对话框        //QMessageBox::information(this,&quot;info&quot;,&quot;信息&quot;);//信息对话框        //提问对话框        //参数1：父亲，参数2：标题；参数3：提示内容；参数4：按键类型；参数5：默认关联回车按键//        QMessageBox::question(this,&quot;ques&quot;,&quot;提问&quot;,QMessageBox::Save|QMessageBox::Cancel,QMessageBox::Cancel);//        if(QMessageBox::Save ==  QMessageBox::question(this,&quot;ques&quot;,&quot;提问&quot;,QMessageBox::Save|QMessageBox::Cancel,QMessageBox::Cancel))//        &#123;//            qDebug()&lt;&lt;&quot;选择了保存&quot;;//        &#125;//        else//        &#123;//            qDebug()&lt;&lt;&quot;选择了取消&quot;;//        &#125;        //警告对话框        QMessageBox::warning(this,&quot;warning&quot;,&quot;警告&quot;);    &#125;);&#125;MainWindow::~MainWindow()&#123;    delete ui;&#125;</code></pre><h2 id="11、其他对话框"><a href="#11、其他对话框" class="headerlink" title="11、其他对话框"></a>11、其他对话框</h2><blockquote><p>QColorDialog,QFileDialog,QFontDialog</p></blockquote><pre><code class="hljs"> // 点击新建按钮 弹出会话框    connect(ui-&gt;actionnew,&amp;QAction::triggered,[=]()&#123;        //颜色对话框//        QColor color = QColorDialog::getColor(QColor(255,0,0));//        qDebug()&lt;&lt;&quot;r = &quot;&lt;&lt;color.red()&lt;&lt;&quot;g = &quot;&lt;&lt;color.green()&lt;&lt;&quot;b = &quot;&lt;&lt;color.blue();        //文件对话框,参数1：父亲 参数2：名字 参数3：路径 参数4：过滤文件格式//        QString str = QFileDialog::getOpenFileName(this,&quot;打开文件&quot;,&quot;E:\\BaseFile\\senior\\C++work&quot;,&quot;(*.doc)&quot;);//        qDebug()&lt;&lt;str;        bool flag;        QFont font = QFontDialog::getFont(&amp;flag,QFont(&quot;华文彩云&quot;,32));        qDebug()&lt;&lt;font.family();    &#125;);</code></pre><h2 id="12、登陆窗口布局"><a href="#12、登陆窗口布局" class="headerlink" title="12、登陆窗口布局"></a>12、登陆窗口布局</h2><blockquote><p>1. 实现登录窗口；</p><p>2. 利用布局方式 给窗口进行美化；</p><p>3. 选取widget进行布局，水平布局、垂直布局、栅格布局；</p><p>4. 给用户名、密码、登录、退出按钮进行布局；</p><p>5. 默认窗口和控件之间有9间隙，可以调整 layoutLeftMargin；</p><p>6. 利用弹簧进行布局。</p><p><img src="https://img-blog.csdnimg.cn/93d865abe0d64a69ab42221e26809c90.png"></p></blockquote><h2 id="13、控件"><a href="#13、控件" class="headerlink" title="13、控件"></a>13、控件</h2><h3 id="13-1-按钮组"><a href="#13-1-按钮组" class="headerlink" title="13.1 按钮组"></a>13.1 按钮组</h3><blockquote><p>1. QPushButton 常用按钮；</p><p>2. QToolButton 工具按钮；用于显示图片，如图想显示文字，修改风格；ToolButtonStyle；</p><p>3. radioButton 单选按钮，设置默认选择ui-&gt;woman-&gt;setChecked(true);</p><p>4. checkbox 多选按钮，监听状态，2是选中，1是半选，0是未选。</p><p><img src="https://img-blog.csdnimg.cn/db156b981d7d452c98fc318f5ebd4181.png"></p></blockquote><pre><code class="hljs">Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    //设置单选按钮，男默认选中    ui-&gt;woman-&gt;setChecked(true);    //多选按钮，0表示为选择，2表示选中    connect(ui-&gt;cBox,&amp;QCheckBox::stateChanged,[=](int state)&#123;               qDebug()&lt;&lt;state;            &#125;);&#125;</code></pre><h3 id="13-2-QListWidget控件"><a href="#13-2-QListWidget控件" class="headerlink" title="13.2 QListWidget控件"></a>13.2 QListWidget控件</h3><blockquote><p>  QListWidget 列表容器：QListWidgetItem 显示一行内容；</p><p> 设置居中方式setTextAlignment（），通过查询assitant帮助文档查询参数。</p></blockquote><pre><code class="hljs"> // 利用listWidget写诗//    QListWidgetItem *item = new QListWidgetItem(&quot;一川烟雨，满城风絮，梅子黄时雨&quot;);//    ui-&gt;listWidget-&gt;addItem(item);//放到listWidget控件里//    item-&gt;setTextAlignment(Qt::AlignCenter);//水平居中    //QStringList QList&lt;QString&gt;    QStringList list;    list&lt;&lt;&quot;陌上花开&quot;&lt;&lt;&quot;可缓缓归矣&quot;;    ui-&gt;listWidget-&gt;addItems(list);</code></pre><h3 id="13-3-QTreeWidget控件"><a href="#13-3-QTreeWidget控件" class="headerlink" title="13.3 QTreeWidget控件"></a>13.3 QTreeWidget控件</h3><blockquote><p>1. 设置水平头 setHeaderLabels();</p><p>2. 创建根节点  QTreeWidgetItem *item1 &#x3D; new QTreeWidgetItem(QStringList()&lt;&lt;”力量”);</p><p>3. 添加根节点到树控件  ui-&gt;treeWidget-&gt;addTopLevelItem(item1);</p><p>4. 添加子节点 item1-&gt;addChild(l1);</p><p><img src="https://img-blog.csdnimg.cn/000a2863ae8f40e6a3125386f8444ac6.png"></p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    // treeWidget    // 设置水平头    ui-&gt;treeWidget-&gt;setHeaderLabels(QStringList()&lt;&lt;&quot;英雄&quot;&lt;&lt;&quot;英雄介绍&quot;);    QTreeWidgetItem *item1 = new QTreeWidgetItem(QStringList()&lt;&lt;&quot;力量&quot;);//匿名对象    QTreeWidgetItem *item2 = new QTreeWidgetItem(QStringList()&lt;&lt;&quot;敏捷&quot;);    QTreeWidgetItem *item3 = new QTreeWidgetItem(QStringList()&lt;&lt;&quot;智力&quot;);    // 加载顶层的节点    ui-&gt;treeWidget-&gt;addTopLevelItem(item1);    ui-&gt;treeWidget-&gt;addTopLevelItem(item2);    ui-&gt;treeWidget-&gt;addTopLevelItem(item3);    //追加子节点    QStringList heroL1,heroL2,heroL3;    heroL1&lt;&lt;&quot;200&quot;;    heroL2&lt;&lt;&quot;100&quot;;    heroL3&lt;&lt;&quot;130&quot;;    QTreeWidgetItem *l1 = new QTreeWidgetItem(heroL1);    QTreeWidgetItem *l2 = new QTreeWidgetItem(heroL2);    QTreeWidgetItem *l3 = new QTreeWidgetItem(heroL3);    item1-&gt;addChild(l1);    item2-&gt;addChild(l2);    item3-&gt;addChild(l3);&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><h3 id="13-4-QTableWidget控件"><a href="#13-4-QTableWidget控件" class="headerlink" title="13.4 QTableWidget控件"></a>13.4 QTableWidget控件</h3><blockquote><p><img src="https://img-blog.csdnimg.cn/3c5da778caae497dabf5861847bce9ac.png"></p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    // TableWidget控件    // 设置列数    ui-&gt;tableWidget-&gt;setColumnCount(3);    // 设置水平表头    ui-&gt;tableWidget-&gt;setHorizontalHeaderLabels(QStringList()&lt;&lt;&quot;姓名&quot;&lt;&lt;&quot;性别&quot;&lt;&lt;&quot;年龄&quot;);    // 设置行数    ui-&gt;tableWidget-&gt;setRowCount(5);    // 设置正文    //ui-&gt;tableWidget-&gt;setItem(0,0,new QTableWidgetItem(&quot;亚瑟&quot;));    QStringList namelist;    namelist&lt;&lt;&quot;亚瑟&quot;&lt;&lt;&quot;赵云&quot;&lt;&lt;&quot;王昭君&quot;&lt;&lt;&quot;关羽&quot;&lt;&lt;&quot;花木兰&quot;;    QList&lt;QString&gt; sexList;    sexList&lt;&lt;&quot;男&quot;&lt;&lt;&quot;男&quot;&lt;&lt;&quot;女&quot;&lt;&lt;&quot;男&quot;&lt;&lt;&quot;女&quot;;    for(int i = 0; i &lt; 5; i++)    &#123;        int col = 0;        ui-&gt;tableWidget-&gt;setItem(i,col++,new QTableWidgetItem(namelist[i]));        ui-&gt;tableWidget-&gt;setItem(i,col++,new QTableWidgetItem(sexList.at(i)));//at越界抛异常        //int 转QString        ui-&gt;tableWidget-&gt;setItem(i,col++,new QTableWidgetItem(QString::number(i+18)));    &#125;&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><h3 id="13-5-其他控件介绍"><a href="#13-5-其他控件介绍" class="headerlink" title="13.5 其他控件介绍"></a>13.5 其他控件介绍</h3><blockquote><p>1. stackedWidget控件</p><p>2. 下拉框控件comboBox</p><p>3. QLabel显示图片和gif </p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QMovie&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    // 栈控件使用    // 欢迎按钮    // 设置默认页面    ui-&gt;stackedWidget-&gt;setCurrentIndex(0);    connect(ui-&gt;btn_welcome,&amp;QPushButton::clicked,[=]()&#123;        ui-&gt;stackedWidget-&gt;setCurrentIndex(0);    &#125;);    // 编辑按钮    connect(ui-&gt;btn_edit,&amp;QPushButton::clicked,[=]()&#123;        ui-&gt;stackedWidget-&gt;setCurrentIndex(1);    &#125;);    // 项目按钮    connect(ui-&gt;btn_project,&amp;QPushButton::clicked,[=]()&#123;        ui-&gt;stackedWidget-&gt;setCurrentIndex(2);    &#125;);    // 下拉框    ui-&gt;comboBox-&gt;addItem(&quot;奔驰&quot;);    ui-&gt;comboBox-&gt;addItem(&quot;宝马&quot;);    ui-&gt;comboBox-&gt;addItem(&quot;自行车&quot;);    connect(ui-&gt;btn_bike,&amp;QPushButton::clicked,[=]()&#123;        //ui-&gt;comboBox-&gt;setCurrentIndex(2);        ui-&gt;comboBox-&gt;setCurrentText(&quot;自行车&quot;);    &#125;);    // 利用QLabel显示图片和gif动态图片    ui-&gt;lb1-&gt;setPixmap(QPixmap(&quot;:/Image/1.jpg&quot;));    QMovie *movie = new QMovie(&quot;:/Image/m.gif&quot;);    ui-&gt;lb1-&gt;setMovie(movie);//嵌入到lbl    movie-&gt;start();//动起来&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><h2 id="14、自定义控件"><a href="#14、自定义控件" class="headerlink" title="14、自定义控件"></a>14、自定义控件</h2><blockquote><p>1、添加新文件，Qt-&gt;设计师界面类（.cpp .h .ui）</p><p>2、.ui中设计 QSpinBox和QSlider两个控件</p><p>3、Widget中使用自定义控件，拖拽一个Widget，点击提升为，点击添加，点击提升，将.ui变成一个smallWidget类</p><p>4、在smallWidget.cpp实现功能，改变数字，滑动条跟着移动，信号槽监听</p><p>5、提供两个按钮，对ui的smallWidget实例对象进行操作</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QDebug&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    // 点击获取控件当前值    connect(ui-&gt;btn_set,&amp;QPushButton::clicked,[=]()&#123;        qDebug()&lt;&lt;ui-&gt;widget-&gt;getNum();    &#125;);    connect(ui-&gt;btn_half,&amp;QPushButton::clicked,[=]()&#123;       ui-&gt;widget-&gt;setNum(50);    &#125;);&#125;Widget::~Widget()&#123;    delete ui;&#125;</code></pre><h2 id="15、Qt的鼠标事件"><a href="#15、Qt的鼠标事件" class="headerlink" title="15、Qt的鼠标事件"></a>15、Qt的鼠标事件</h2><blockquote><p>1、鼠标进入事件enterEvent</p><p>2、鼠标离开事件leaveEvent</p><p>3、鼠标移动 mouseMoveEvent</p><p>4、鼠标按下 mousePressEvent</p><p>5、鼠标释放 mouseReleaseEvent</p><p>6、ev-&gt;x(),ev-&gt;y()</p><p>7、ev-&gt;button() 可以判断所有按键，Qt::LeftButton,Qt::RightButton</p><p>8、ev-&gt;buttons() 判断组合按键，判断用 &amp;</p><p>9、格式化字符串 QString str &#x3D; QString（“%1  %2 %3 …”).arg().arg().arg()…</p></blockquote><pre><code class="hljs">#include &quot;mylabel.h&quot;#include &lt;QDebug&gt;#include &lt;QMouseEvent&gt;myLabel::myLabel(QWidget *parent)    : QLabel&#123;parent&#125;&#123;    //设置鼠标追踪状态,默认是false    setMouseTracking(true);</code></pre><p>​<br>​    }<br>​    void myLabel::enterEvent(QEvent *event)<br>​    {<br>​<br>​        qDebug()&lt;&lt;”鼠标进入”;<br>​    }<br>​<br>​    void myLabel::leaveEvent(QEvent *)<br>​    {<br>​        qDebug()&lt;&lt;”鼠标离开”;<br>​    }<br>​    </p><pre><code class="hljs">void myLabel::mouseMoveEvent(QMouseEvent *ev)//持续过程&#123;//    if(ev-&gt;buttons() &amp; Qt::LeftButton)//同真才为真//    &#123;        QString str = QString(&quot;鼠标移动了，x = %1 y = %2 globalx = %3 globaly = %4&quot;).arg(ev-&gt;x()).arg(ev-&gt;y()).arg(ev-&gt;globalX()).arg(ev-&gt;globalY());        qDebug()&lt;&lt;str;//    &#125;&#125;void myLabel::mousePressEvent(QMouseEvent *ev)//瞬间&#123;//    if(ev-&gt;button() == Qt::LeftButton)//左键才打印//    &#123;        QString str = QString(&quot;鼠标按下了，x = %1 y = %2 globalx = %3 globaly = %4&quot;).arg(ev-&gt;x()).arg(ev-&gt;y()).arg(ev-&gt;globalX()).arg(ev-&gt;globalY());        qDebug()&lt;&lt;str;//    &#125;&#125;void myLabel::mouseReleaseEvent(QMouseEvent *ev)//瞬间&#123;//    if(ev-&gt;button() == Qt::LeftButton)//左键才打印//    &#123;        QString str = QString(&quot;鼠标释放了，x = %1 y = %2 globalx = %3 globaly = %4&quot;).arg(ev-&gt;x()).arg(ev-&gt;y()).arg(ev-&gt;globalX()).arg(ev-&gt;globalY());        qDebug()&lt;&lt;str;//    &#125;&#125;</code></pre><h2 id="16、定时器"><a href="#16、定时器" class="headerlink" title="16、定时器"></a>16、定时器</h2><blockquote><p>1、利用事件void timerEvent（QTimerEvent *e）</p><p>2、启动定时器 startTimer（1000）毫秒单位</p><p>3、timerEvent的返回值是定时器定时器的唯一标识，可以和 e-&gt;timerId 做比较</p><p>4、利用定时器类 QTimer</p><p>5、先创建定时器对象，启动定时器start（毫秒）</p><p>6、每隔一定毫秒，发送信号timeout，进行监听</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QTimer&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    // 启动定时器 单位是毫秒    id1 = startTimer(1000);    id2 = startTimer(2000);    //定时器第二种方式    QTimer *timer = new QTimer(this);    //启动定时器    timer-&gt;start(500);//0.5s进入中断    connect(timer,&amp;QTimer::timeout,[=]()&#123;        static int num = 1;        //每0.5s加1；        ui-&gt;label_4-&gt;setText(QString::number(num++));    &#125;);    connect(ui-&gt;stop,&amp;QPushButton::clicked,[=]()&#123;        timer-&gt;stop();    &#125;);&#125;Widget::~Widget()&#123;    delete ui;&#125;void Widget::timerEvent(QTimerEvent *e)&#123;    //label_2 每隔1s +1    if(e-&gt;timerId()==id1)    &#123;        static int num1 = 1;        ui-&gt;label_2-&gt;setText(QString::number(num1++));    &#125;    //label_3 每隔2s +1    if(e-&gt;timerId()==id2)//判断定时器    &#123;        static int num2 = 1;        ui-&gt;label_3-&gt;setText(QString::number(num2++));    &#125;&#125;</code></pre><h2 id="17、event-事件分发器和事件过滤器"><a href="#17、event-事件分发器和事件过滤器" class="headerlink" title="17、event 事件分发器和事件过滤器 "></a>17、event 事件分发器和事件过滤器 </h2><blockquote><p>1、用于时间的分发，也可以做拦截(不建议)</p><p>2、bool event（QEvent *e）返回值是true代表永华处理这个事件，不向下分发 </p><p>3、e-&gt;type() &#x3D;&#x3D; 鼠标按下</p><p><img src="https://img-blog.csdnimg.cn/0b39e92349db4e7481d4e0f1a6883274.png"></p></blockquote><pre><code class="hljs">bool myLabel::event(QEvent *e)&#123;    if(e-&gt;type() == QEvent::MouseButtonPress)//鼠标按下，在事件event事件中做拦截操作    &#123;        QMouseEvent *ev = static_cast&lt;QMouseEvent*&gt;(e);//将e转换为ev类型        QString str = QString(&quot;event中，，鼠标按下了，x = %1 y = %2 globalx = %3 globaly = %4&quot;).arg(ev-&gt;x()).arg(ev-&gt;y()).arg(ev-&gt;globalX()).arg(ev-&gt;globalY());        qDebug()&lt;&lt;str;        return true;//代表用户自己处理事件，不向下分发    &#125;    //其他事件交给父类处理    return QLabel::event(e);&#125;---------------------------------------------------------------------------------bool Widget::eventFilter(QObject *obj,QEvent *e)&#123;    if(obj == ui-&gt;label)    &#123;        if(e-&gt;type() == QEvent::MouseButtonPress)//鼠标按下，在事件event事件中做拦截操作        &#123;            QMouseEvent *ev = static_cast&lt;QMouseEvent*&gt;(e);//将e转换为ev类型            QString str = QString(&quot;事件过滤器中，，鼠标按下了，x = %1 y = %2 globalx = %3 globaly = %4&quot;).arg(ev-&gt;x()).arg(ev-&gt;y()).arg(ev-&gt;globalX()).arg(ev-&gt;globalY());            qDebug()&lt;&lt;str;            return true;//代表用户自己处理事件，不向下分发        &#125;    &#125;    // 其他默认处理    return QWidget::eventFilter(obj,e);&#125;</code></pre><h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://img-blog.csdnimg.cn/ad0ea8cd5b1e465aa1504df2bb775326.png"></h2><h2 id="18、QPainter"><a href="#18、QPainter" class="headerlink" title="18、QPainter"></a>18、QPainter</h2><h3 id="18-1-绘图事件"><a href="#18-1-绘图事件" class="headerlink" title="18.1 绘图事件"></a>18.1 绘图事件</h3><blockquote><p>1、绘图事件 void paintEvent()</p><p>2、声明一个画家对象</p></blockquote><pre><code class="hljs">void Widget::paintEvent(QPaintEvent *)&#123;    //实例化画家对象 this指定的是绘图设备    QPainter painter(this);    //设置画笔    QPen pen(QColor(255,0,0));    //设置画笔宽度    pen.setWidth(3);    //设置画笔风格    pen.setStyle(Qt::DotLine);    //让画家使用这个笔    painter.setPen(pen);    //设置画刷    QBrush brush(Qt::cyan);    //设置画刷风格    brush.setStyle(Qt::Dense7Pattern);    //让画家使用画刷    painter.setBrush(brush);​        //划线​        painter.drawLine(QPoint(0,0),QPoint(100,100));​        //画圆 椭圆​        painter.drawEllipse(QPoint(100,100),50,50);​    &#125;</code></pre><h3 id="18-2-绘图高级设置"><a href="#18-2-绘图高级设置" class="headerlink" title="18.2 绘图高级设置"></a>18.2 绘图高级设置</h3><blockquote><p>1、抗锯齿，效率低</p><p>2、对画家进行移动，保存状态，还原状态</p></blockquote><pre><code class="hljs">void Widget::paintEvent(QPaintEvent *)&#123;    QPainter painter(this);    painter.drawEllipse(QPoint(100,50),50,50);    //设置抗锯齿能力 效率低    painter.setRenderHint(QPainter::Antialiasing);    painter.drawEllipse(QPoint(200,50),50,50);    //画矩形    painter.drawRect(QRect(20,20,50,50));    //让画家移动位置    painter.translate(100,0);    //保存画家状态    painter.save();    //画另一个矩形    painter.drawRect(QRect(20,20,50,50));    painter.translate(100,0);    //还原画家状态    painter.restore();    painter.drawRect(QRect(20,20,50,50));&#125;</code></pre><h3 id="18-3-手动调用绘图事件"><a href="#18-3-手动调用绘图事件" class="headerlink" title="18.3 手动调用绘图事件"></a>18.3 手动调用绘图事件</h3><blockquote><p>如果想手动调用绘图事件，利用update，利用画家画图片painterDrawPixmap</p></blockquote><pre><code class="hljs">Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    //移动    connect(ui-&gt;btn_move,&amp;QPushButton::clicked,[=]()&#123;      //如果要手动调用绘图事件，用update更新      update();      posx += 20;    &#125;);&#125;void Widget::paintEvent(QPaintEvent *)&#123;    QPainter painter(this);    //如果超过屏幕，重新开始    if(posx &gt; this-&gt;width())    &#123;        posx = 0;    &#125;    painter.drawPixmap(posx,0,QPixmap(&quot;:/Image_1/10.jpg&quot;));&#125;</code></pre><h3 id="18-4-绘图设备"><a href="#18-4-绘图设备" class="headerlink" title="18.4 绘图设备"></a>18.4 绘图设备</h3><blockquote><p>1. QPixmap QImage QBitmap(黑白)QPicture QWidget</p><p>2. QPixmap 对不同平台做了显示优化</p><p>3. QImage可以对像素进行访问</p><p>4. QPicture可以记录和重现绘图指令</p></blockquote><pre><code class="hljs">#include &quot;widget.h&quot;#include &quot;ui_widget.h&quot;#include &lt;QPixmap&gt;#include &lt;QPainter&gt;#include &lt;QImage&gt;#include &lt;QPicture&gt;Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);//    //Pixmap绘图设备 专门为平台做了显示的优化//    QPixmap pix(400,400);//    QPainter painter(&amp;pix);//    //填充颜色//    pix.fill(Qt::white);//    painter.setPen(QPen(Qt::blue));//    painter.drawEllipse(QPoint(200,200),100,100);//    //保存到磁盘//    pix.save(&quot;E:\\pix.png&quot;);    //QImage 绘图设备 可以对像素进行访问//    QImage img(300,300,QImage::Format_RGB666);//    img.fill(Qt::white);//    QPainter painter(&amp;img);//    painter.setPen(QPen(Qt::blue));//    painter.drawEllipse(QPoint(200,200),100,100);//    img.save(&quot;E:\\img.png&quot;);    //QPicture 绘图设备 可以记录和重新绘图指令    QPicture pic;    QPainter painter;    painter.begin(&amp;pic);//开始往pic画    painter.setPen(QPen(Qt::cyan));    painter.drawEllipse(QPoint(150,150),100,100);    painter.end();//结束画图    pic.save(&quot;E:\\pic.zt&quot;);​    &#125;​    void Widget::paintEvent(QPaintEvent *event)​    &#123;​         //利用QImage对像素点修改​    //    QPainter painter(this);​    //    QImage img;​    //    img.load(&quot;:/Image_1/10.jpg&quot;);​    ​    //    //修改像素点​    //    for(int i = 50;i&lt;100;i++)​    //    &#123;​    //        for(int j = 50; j&lt;100;j++)​    //        &#123;​    //            QRgb value = qRgb(255,0,0);​    //            img.setPixel(i,j,value);​    //        &#125;​    //    &#125;​    //    painter.drawImage(0,0,img);​            //重现QPicture的绘图指令         QPainter painter(this);         QPicture pic;         pic.load(&quot;E:\\pic.zt&quot;);         painter.drawPicture(0,0,pic);    &#125;</code></pre><h2 id="19、QFile文件读写操作"><a href="#19、QFile文件读写操作" class="headerlink" title="19、QFile文件读写操作"></a>19、QFile文件读写操作</h2><h3 id="文件QFile和文件信息读写QFileInfo"><a href="#文件QFile和文件信息读写QFileInfo" class="headerlink" title="文件QFile和文件信息读写QFileInfo"></a>文件QFile和文件信息读写QFileInfo</h3><blockquote><p><img src="https://img-blog.csdnimg.cn/c05ec249778e4864adf7014d74cdaa2c.png"></p></blockquote><pre><code class="hljs">Widget::Widget(QWidget *parent)    : QWidget(parent)    , ui(new Ui::Widget)&#123;    ui-&gt;setupUi(this);    //点击选取文件按钮，弹出文件对话框    connect(ui-&gt;btn_file,&amp;QPushButton::clicked,[=]()            &#123;                QString path = QFileDialog::getOpenFileName(this,&quot;打开文件&quot;,&quot;E:\\1.Qt_temporary_files&quot;);                //将路径放入到lineEdit                ui-&gt;lineEdit-&gt;setText(path);                //编码格式类                //QTextCodec *codec = QTextCodec::codecForName(&quot;gbk&quot;);                //读取内容，放入textEdit中                QFile file(path);//参数就是读取文件的路径                //设置打开方式                file.open(QIODevice::ReadOnly);                //QByteArray array = file.readAll();                //按行读取                QByteArray array;                while(!file.atEnd())                &#123;                    array += file.readLine();                &#125;                 //将读入的数据放入textEdit                ui-&gt;textEdit-&gt;setText(array);                //转成gbk格式，默认是utf-8格式              //ui-&gt;textEdit-&gt;setText(codec-&gt;toUnicode(array));                   //对文件对象进行关闭                file.close();                //进行写文件//                file.open(QIODevice::Append);//用追加的方式进行写//                file.write(&quot;aaaaaa&quot;);//                file.close();                //QFileInfo读取文件信息                QFileInfo info(path);                qDebug()&lt;&lt;&quot;大小：&quot;&lt;&lt;info.size()&lt;&lt;&quot;后缀名：&quot;&lt;&lt;info.suffix()&lt;&lt;&quot;文件名：&quot;&lt;&lt;info.fileName();                qDebug()&lt;&lt;&quot;创建日期：&quot;&lt;&lt;info.birthTime().toString(&quot;yyyy/MM/dd hh:mm:ss&quot;);            &#125;);&#125;</code></pre><h2 id="20、翻金币项目"><a href="#20、翻金币项目" class="headerlink" title="20、翻金币项目 "></a>20、翻金币项目 </h2><p><a href="https://blog.csdn.net/q5120192609/article/details/127470422">https://blog.csdn.net/q5120192609/article/details/127470422</a></p><p>转载就当作是自己的（</p>]]></content>
    
    
    
    <tags>
      
      <tag>Qt</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch_tudui</title>
    <link href="/2023/09/07/Pytorch-tudui/"/>
    <url>/2023/09/07/Pytorch-tudui/</url>
    
    <content type="html"><![CDATA[<div id="article_content" class="article_content clearfix">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-25cebea3f9.css">                <div id="content_views" class="htmledit_views">                    <p id="main-toc"><strong>目录</strong></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t0" target="_self">1. Pytorch环境的配置及安装</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t1" target="_self">如何管理项目环境？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t2" target="_self">如何看自己电脑cuda版本？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t3" target="_self">安装Pytorch&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t4" target="_self">2. Python编辑器的选择、安装及配置</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t5" target="_self">PyCharm&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t6" target="_self">PyCharm神器</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t7" target="_self">Jupyter（可交互）&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t8" target="_self">3. Python学习中的两大法宝函数</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t9" target="_self">说明&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t10" target="_self">实战操作</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t11" target="_self">总结</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t12" target="_self">4. Pycharm及Jupyter使用及对比</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t13" target="_self">如何在PyCharm中新建项目？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t14" target="_self">Python控制台​编辑</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t15" target="_self">如何在Jupyter中新建项目？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t16" target="_self">三种运行方式（PyCharm、PyCharm的Python控制台、Jupyter Notebook）的适用场景：</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t17" target="_self">5. PyTorch加载数据初认识</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t18" target="_self">PyTorch 读取数据涉及两个类：Dataset &amp; Dataloader</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t19" target="_self">数据集的几种组织形式</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t20" target="_self">Dataset类&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t21" target="_self">6. Dataset类代码实战</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t22" target="_self">两种方法读图片</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t23" target="_self">控制台读取&amp;可视化图片</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t24" target="_self">（一）数据格式1&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t25" target="_self">读数据</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t26" target="_self">（二）数据格式2</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t27" target="_self">7. TensorBoard的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t28" target="_self">SummaryWriter类</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t29" target="_self">安装TensorBoard</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#add_scalar%28%29%20%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%9A" target="_self">add_scalar() 方法的使用</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#add_image%28%29%20%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%9A" target="_self">add_image() 的使用</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#%E5%88%A9%E7%94%A8numpy.array%28%29%EF%BC%8C%E5%AF%B9PIL%E5%9B%BE%E7%89%87%E8%BF%9B%E8%A1%8C%E8%BD%AC%E6%8D%A2%EF%BC%9A" target="_self">利用numpy.array()，对PIL图片进行转换</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t33" target="_self">8. 图像变换，torchvision中transforms的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t34" target="_self">transforms的结构及用法</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t35" target="_self">结构</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t36" target="_self">一些类</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t37" target="_self">使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t38" target="_self">两个问题</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t39" target="_self">1、transforms 该如何使用（python）</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t40" target="_self">2、为什么我们需要 Tensor 数据类型</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t41" target="_self">两种读取图片的方式</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t42" target="_self">9. 常见的Transforms的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t43" target="_self">Compose 的使用</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t44" target="_self">Python中 __call__ 的用法</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t45" target="_self">ToTensor 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t46" target="_self">ToPILImage 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t47" target="_self">Normalize 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#Resize%28%29%20%E7%9A%84%E4%BD%BF%E7%94%A8" target="_self">Resize() 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#Compose%28%29%20%E7%9A%84%E4%BD%BF%E7%94%A8" target="_self">Compose() 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#RandomCrop%28%29%20%E7%9A%84%E4%BD%BF%E7%94%A8" target="_self">RandomCrop() 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t51" target="_self">总结使用方法</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t52" target="_self">10. torchvision 中的数据集使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t53" target="_self">CIFAR10数据集</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t54" target="_self">标准数据集如何下载、查看、使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t55" target="_self">如何把数据集（多张图片）和 transforms 结合在一起</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t56" target="_self">11. DataLoader 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t57" target="_self">参数介绍&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t58" target="_self">示例&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t59" target="_self">batch_size</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t60" target="_self">drop_last</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t61" target="_self">shuffle</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t62" target="_self">12. 神经网络的基本骨架 - nn.Module 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t63" target="_self">Containers</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t64" target="_self">debug看流程&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t65" target="_self">13. 土堆说卷积操作</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t66" target="_self">stride（步进）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t67" target="_self">要求输入的维度&nbsp;&amp; reshape函数</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t68" target="_self">padding（填充）</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t69" target="_self">14. 神经网络 - 卷积层</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t70" target="_self">kernel_size</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t71" target="_self">in_channels &amp; out_channels</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t72" target="_self">CIFAR10数据集实例&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t73" target="_self">卷积层 vgg16</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t74" target="_self">卷积前后维度计算公式</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t75" target="_self">15. 神经网络 - 最大池化的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t76" target="_self">参数&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t77" target="_self">ceil_mode参数</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t78" target="_self">输入输出维度计算公式</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t79" target="_self">代码实现&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t80" target="_self">为什么要进行最大池化？最大池化的作用是什么？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t81" target="_self">用数据集 CIFAR10 实现最大池化</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t82" target="_self">16. 神经网络 - 非线性激活&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t83" target="_self">最常见：RELU&nbsp; &nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t84" target="_self">代码举例：RELU</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t85" target="_self">Sigmoid</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t86" target="_self">代码举例：Sigmoid（数据集CIFAR10）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t87" target="_self">关于inplace</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t88" target="_self">17. 神经网络 - 线性层及其他层介绍&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t89" target="_self">批标准化层（不难，自学）&nbsp; &nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t90" target="_self">Recurrent Layers（特定网络中使用，自学）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t91" target="_self">Transformer Layers（特定网络中使用，自学）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t92" target="_self">Linear Layers（本节讲解）</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t93" target="_self">代码实例</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t94" target="_self">flatten 摊平</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t95" target="_self">Dropout Layers（不难，自学）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t96" target="_self">Sparse Layers（特定网络中使用，自学）</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t97" target="_self">Embedding</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t98" target="_self">Distance Functions</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t99" target="_self">Loss Functions</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t100" target="_self">pytorch提供的一些网络模型</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t101" target="_self">18. 神经网络 - 搭建小实战和 Sequential 的使用</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t102" target="_self">对 CIFAR10 进行分类的简单神经网络</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t103" target="_self">直接搭建，实现上图 CIFAR10 model 的代码</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t104" target="_self">实际过程中如何检查网络的正确性？</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t105" target="_self">若不知道flatten之后的维度是多少该怎么办？</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t106" target="_self">用 Sequential&nbsp;搭建，实现上图 CIFAR10 model 的代码</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t107" target="_self">引入 tensorboard 可视化模型结构</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t108" target="_self">19. 损失函数与反向传播</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t109" target="_self">L1LOSS</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t110" target="_self">代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t111" target="_self">MSELOSS（均方误差）</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t112" target="_self">代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t113" target="_self">CROSSENTROPYLOSS（交叉熵）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t114" target="_self">如何在之前写的神经网络中用到 Loss Function（损失函数）</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t115" target="_self">backward&nbsp; 反向传播</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t116" target="_self">20. 优化器</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t117" target="_self">如何使用优化器？</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t118" target="_self">算法</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t119" target="_self">SGD为例&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t120" target="_self">完整代码</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t121" target="_self">21. 现有网络模型的使用及修改</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t122" target="_self">数据集 ImageNet</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t123" target="_self">参数及下载&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t124" target="_self">VGG16 模型</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t125" target="_self">参数 pretrained=True/False&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t126" target="_self">vgg16 网络架构&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t127" target="_self">如何利用现有网络去改动它的结构？</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t128" target="_self">添加&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t129" target="_self">修改&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t130" target="_self">22. 网络模型的保存与读取</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t131" target="_self">两种方式保存模型</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t132" target="_self">两种方式加载模型</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t133" target="_self">方式1 有陷阱（自己定义网络结构，没有用 vgg16 时）</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t134" target="_self">问题描述&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t135" target="_self">解决</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t136" target="_self">解决另法：</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t137" target="_self">23. 完整的模型训练套路</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t138" target="_self">model.py 文件代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t139" target="_self">train.py 文件代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t140" target="_self">如何知道模型是否训练好，或达到需求？</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t141" target="_self">完整代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t142" target="_self">与 TensorBoard 结合</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t143" target="_self">保存每一轮训练的模型&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t144" target="_self">正确率的实现（对分类问题）&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t145" target="_self">train.py 完整代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t146" target="_self">model.train() 和 model.eval()</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t147" target="_self">作用&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t148" target="_self">回顾案例</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t149" target="_self">24. 利用GPU训练</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t150" target="_self">第一种使用GPU训练的方式</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t151" target="_self">比较CPU/GPU训练时间&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t152" target="_self">对于CPU</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t153" target="_self">对于GPU</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t154" target="_self">查看GPU信息&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t155" target="_self">Google Colab</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t156" target="_self">如何使用GPU？</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t157" target="_self">查看GPU配置&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t158" target="_self">第二种使用GPU训练的方式（更常用）</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t159" target="_self">25. 完整的模型验证（测试、demo）套路</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t160" target="_self">示例&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t161" target="_self">test.py（把训练模型运用到实际环境中）完整代码</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t162" target="_self">示例二</a></p> <p id="" style="margin: 0px 0px 2px; padding-left: 24px;"><a href="#t163" target="_self">26. 看看开源项目</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t164" target="_self">README.md&nbsp;</a></p> <p id="" style="margin: 0px 0px 2px 48px; padding-left: 24px;"><a href="#t165" target="_self">train.py</a></p> <p id="" style="margin: 0px 0px 2px 96px; padding-left: 24px;"><a href="#t166" target="_self">训练参数设置</a></p> <hr id="hr-toc"> <h1 id="1.%20Pytorch%E7%8E%AF%E5%A2%83%E7%9A%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%AE%89%E8%A3%85"><a name="t0"></a>1. Pytorch环境的配置及安装</h1> <p>首先需要下载Anaconda（包含了大量的package/工具包）</p> <p>深度学习离不开显卡（TensorFlow/Pytorch支持英伟达的显卡），起到训练加速的作用</p> <ul><li>显卡的配置：驱动 + CUDA Toolkit（CUDA工具包）</li><li>CUDA Toolkit 会跟随Pytorch一键安装</li><li>主要检查显卡的驱动是否正确安装：任务管理器—性能—GPU，若能看到GPU的型号，即意味着显卡的驱动已经正确安装</li></ul> <h2 id="%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E9%A1%B9%E7%9B%AE%E7%8E%AF%E5%A2%83%EF%BC%9F"><a name="t1"></a>如何管理项目环境？</h2> <p>一个package相当于一个工具包，把环境理解成一个房子，初始环境base，不同环境可以有不同版本的工具包，切换环境即可</p> <p><strong>conda指令创建pytorch环境</strong>（<strong><span style="color:#fe2c24;">如果开了代理服务器，务必关闭！！！</span></strong>）</p> <p>以下命令在 Anaconda Prompt 中输入：</p> <pre data-index="0"><code class="hljs language-cobol">conda create -n pytorch python<span class="hljs-operator">=</span><span class="hljs-number">3.8</span>   # -n是name的意思</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <pre data-index="1"><code class="hljs language-csharp">conda activate pytorch  <span class="hljs-meta"># 激活环境</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="340" src="https://img-blog.csdnimg.cn/7e3a99d450a84be2af17d637b643f1b1.png" width="475"></p> <p>左边括号里的环境由base变成了pytorch（环境名称）</p> <p><strong>看一下环境中的工具包：</strong></p> <pre data-index="2"><code class="hljs language-undefined">pip list</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;<img alt="" height="247" src="https://img-blog.csdnimg.cn/244d6a9563d24ca180a556592ff209fa.png" width="400"></p> <p>并没有pytorch，接下来：<a href="https://so.csdn.net/so/search?q=%E5%AE%89%E8%A3%85pytorch&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%AE%89%E8%A3%85pytorch&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;安装pytorch\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=%E5%AE%89%E8%A3%85pytorch&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;安装pytorch\&quot;}&quot;}" data-tit="安装pytorch" data-pretit="安装pytorch">安装pytorch</a></p> <p>网址：<a href="https://pytorch.org/" title="PyTorch">PyTorch</a></p> <h2 id="%E5%A6%82%E4%BD%95%E7%9C%8B%E8%87%AA%E5%B7%B1%E7%94%B5%E8%84%91cuda%E7%89%88%E6%9C%AC%EF%BC%9F"><a name="t2"></a>如何看自己电脑cuda版本？</h2> <ul><li>任务管理器—性能—GPU<br><img alt="" height="487" src="https://img-blog.csdnimg.cn/263848fdf292432fa88a6c6e68d9f633.png" width="550"></li><li>或：设备管理器—显示适配器   <figure class="image">    <img alt="" height="521" src="https://img-blog.csdnimg.cn/1056454eced64934824077c0e23a841c.png" width="550">    <figcaption>     独立显卡    </figcaption>   </figure></li></ul> <p>在cmd里输入：</p> <pre data-index="3"><code class="hljs language-undefined">nvidia-smi</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="369" src="https://img-blog.csdnimg.cn/84e17fd957d04cccb4075034a80dd693.png" width="946"></p> <h2 id="%E5%AE%89%E8%A3%85Pytorch%C2%A0"><a name="t3"></a>安装Pytorch&nbsp;</h2> <p>找到自己适合的版本，复制命令：&nbsp;</p> <ul><li>Stable 稳定版：1.1版本以后加入了TensorBoard，可以看到训练过程中的数据，如损失函数的变化</li><li>Package：一般Windows下推荐使用Conda，Linux下推荐使用pip</li><li>Compute Platform：   <ul><li>无英伟达显卡或只有集显：CPU</li><li>有英伟达显卡：30系列显卡不支持11.1以下的CUDA</li></ul></li></ul> <p><img alt="" height="587" src="https://img-blog.csdnimg.cn/8e6d9ab13b8246f0a596aa8d7895f9a9.png" width="1200"></p> <p>在刚刚激活了pytorch环境的窗口里输入：&nbsp;</p> <pre data-index="4"><code class="hljs language-cobol">conda install pytorch torchvision torchaudio cudatoolkit<span class="hljs-operator">=</span><span class="hljs-number">11.3</span> -c pytorch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;等待安装成功之后，再</p> <pre data-index="5"><code class="hljs language-undefined">pip list</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="433" src="https://img-blog.csdnimg.cn/2230f29e33d446a3862d8afa1ab4dfba.png" width="700"></p> <p>可以看到已经安装成功</p> <p><strong>检验安装是否成功：</strong>先输入</p> <pre data-index="6"><code class="hljs language-undefined">python</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>再输入</p> <pre data-index="7"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> torch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>若没有报错则安装成功，如图</p> <p><img alt="" height="509" src="https://img-blog.csdnimg.cn/920bbccfabd14e42b2760596486c849f.png" width="879"></p> <p><strong>检验pytorch是否可以用GPU：</strong></p> <pre data-index="8"><code class="hljs language-scss"> torch<span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.is_available</span>()</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>返回True即可</p> <hr> <h1 id="2.%20Python%E7%BC%96%E8%BE%91%E5%99%A8%E7%9A%84%E9%80%89%E6%8B%A9%E3%80%81%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE"><a name="t4"></a>2. <a href="https://so.csdn.net/so/search?q=Python%E7%BC%96%E8%BE%91%E5%99%A8&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=Python%E7%BC%96%E8%BE%91%E5%99%A8&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;Python编辑器\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=Python%E7%BC%96%E8%BE%91%E5%99%A8&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;Python编辑器\&quot;}&quot;}" data-tit="Python编辑器" data-pretit="python编辑器">Python编辑器</a>的选择、安装及配置</h1> <h2 id="PyCharm%C2%A0"><a name="t5"></a>PyCharm&nbsp;</h2> <p><a href="https://www.jetbrains.com/pycharm/" title="PyCharm: the Python IDE for Professional Developers by JetBrains">PyCharm: the Python IDE for Professional Developers by JetBrains</a></p> <p><img alt="" height="884" src="https://img-blog.csdnimg.cn/a9ab093506074d5cbde28ab5df4b2006.png" width="1170"></p> <p><img alt="" height="842" src="https://img-blog.csdnimg.cn/2c93daea1a98486ab06d2fb261e63757.png" width="1200"></p> <p><strong>在Python工作台/控制台验证：</strong></p> <p><img alt="" height="543" src="https://img-blog.csdnimg.cn/ef5947d225f048fc9652f9df31a88fb2.png" width="1200"></p> <p>&nbsp;先输入</p> <pre data-index="9"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> torch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>再输入</p> <pre data-index="10"><code class="hljs language-scss"> torch<span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.is_available</span>()</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>返回True即可，如上图</p> <h2 id="PyCharm%E7%A5%9E%E5%99%A8"><a name="t6"></a>PyCharm神器</h2> <p><img alt="" height="536" src="https://img-blog.csdnimg.cn/727367fd38d947baa4b6bc1ce63dedaf.png" width="1200"></p> <p>在左边输入，右边有变量的属性，很直观&nbsp;</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Jupyter%EF%BC%88%E5%8F%AF%E4%BA%A4%E4%BA%92%EF%BC%89%C2%A0"><a name="t7"></a>Jupyter（可交互）&nbsp;</h2> <p><a href="https://jupyter.org/" title="Project Jupyter | Home">Project Jupyter | Home</a></p> <p>建议直接安装Anaconda，Jupyter会随着Anaconda一起安装</p> <p>Jupyter 默认安装在 base 环境中，但是base环境中没有安装 Pytorch，导致Jupyter无法使用Pytorch，两种解决方式：</p> <ul><li>在base环境中再安装一遍Pytorch</li><li>在Pytorch环境中安装Jupyter（选择这种）</li></ul> <p>打开Anaconda Prompt是base环境，从base环境启用Jupyter需要一个package：ipykernel，如图：</p> <p>输入</p> <pre data-index="11"><code class="hljs language-undefined">conda list</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="683" src="https://img-blog.csdnimg.cn/129c406236704ab8abe07d34da84f7d1.png" width="889"></p> <p>可以看到要用到的 package是 ipykernel</p> <p>进入Pytorch环境中：</p> <pre data-index="12"><code class="hljs language-undefined">conda activate pytorch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>再输入</p> <pre data-index="13"><code class="hljs language-undefined">conda list</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="612" src="https://img-blog.csdnimg.cn/9f5c678aa2934e1abce0fecad18b7c3f.png" width="769"></p> <p>可以发现没有&nbsp;ipykernel ，安装这个 package（<strong><span style="color:#fe2c24;">同样需要关闭代理服务器！！！</span></strong>）</p> <pre data-index="14"><code class="hljs language-undefined">conda install nb_conda</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>等到done之后，再输入</p> <pre data-index="15"><code class="hljs language-undefined">jupyter notebook</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;等到页面跳转到浏览器，New — Python[conda env:pytorch]*</p> <p><img alt="" height="430" src="https://img-blog.csdnimg.cn/9d3591b012df4ed38664ce8fb8c9b200.png" width="1200"></p> <p>&nbsp;同样，先输入</p> <pre data-index="16"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> torch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>再输入</p> <pre data-index="17"><code class="hljs language-scss"> torch<span class="hljs-selector-class">.cuda</span><span class="hljs-selector-class">.is_available</span>()</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>返回True即可，如下图</p> <p><img alt="" height="169" src="https://img-blog.csdnimg.cn/7d288897160e4f758692270c09f1e628.png" width="540"></p> <p><strong>意外插曲：</strong></p> <p>网页可以正常跳转，但是会有这个窗口弹出：</p> <p><img alt="" height="251" src="https://img-blog.csdnimg.cn/066a3662e3f84f4f868de10b0fa2f9da.png" width="604"></p> <p><strong>解决方式：</strong>按照地址删去 pythoncom38.dll 文件即可（可能需要删多个 pythoncom38.dll 文件）</p> <hr> <h1 id="3.%20Python%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%B8%A4%E5%A4%A7%E6%B3%95%E5%AE%9D%E5%87%BD%E6%95%B0"><a name="t8"></a>3. Python学习中的两大法宝函数</h1> <h2 id="%E8%AF%B4%E6%98%8E%C2%A0"><a name="t9"></a>说明&nbsp;</h2> <p>package（名称为 pytorch）就像一个工具箱，有不同的分隔区，分隔区里有不同的工具</p> <p>探索工具箱，两个道具：</p> <ul><li><strong><span style="background-color:#ffd900;">dir() 函数：</span></strong>能让我们知道工具箱以及工具箱中的分隔区有什么东西<strong>（打开，看见）</strong></li><li><strong><span style="background-color:#ffd900;">help() 函数：</span></strong>能让我们知道每个工具是如何使用的，工具的使用方法<strong>（说明书）</strong></li></ul> <p>例：</p> <p><img alt="" height="232" src="https://img-blog.csdnimg.cn/96bcf2b50a714e87add4ebe42c07d122.png" width="230"></p> <p>dir(pytorch)，就能看到输出1、2、3、4等分隔区；想继续探索第3个分隔区里有什么的话，dir(pytorch.3)，输出会是a,b,c（3号分隔区里有a,b,c等工具），如何使用？</p> <p>help(pytorch.3.a)&nbsp; 输出：将此扳手放在特定地方，然后拧动</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%AE%9E%E6%88%98%E6%93%8D%E4%BD%9C"><a name="t10"></a><strong>实战操作</strong></h2> <p>打开PyCharm，输入</p> <pre data-index="18"><code class="hljs language-scss"><span class="hljs-built_in">dir</span>(torch)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="356" src="https://img-blog.csdnimg.cn/ed01f8c5109d437790b18e7908a90dd9.png" width="500"></p> <p>&nbsp;可以看到输出了大量的分隔区（或理解为更小的工具箱），ctrl+F找到cuda</p> <p><img alt="" height="291" src="https://img-blog.csdnimg.cn/5bb67ea2081b4b1a9211af5d6b249038.png" width="550"></p> <p>看cuda分隔区里有什么，输入</p> <pre data-index="19"><code class="hljs language-scss"><span class="hljs-built_in">dir</span>(torch.cuda)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>可以看到又输出了大量的分隔区</p> <p><img alt="" height="327" src="https://img-blog.csdnimg.cn/31af6665ac354f729b6cb2bf58c4eb19.png" width="460"></p> <p>继续输入：</p> <pre data-index="20"><code class="hljs language-scss"><span class="hljs-built_in">dir</span>(torch.cuda.is_available)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>可以看到<strong>输出的前后都带有双下划线__</strong>，这是一种规范，说明这个变量不容许篡改，即它不再是一个分隔区，而是一个确确实实的函数<strong>（相当于工具，可以用<span style="color:#956fe7;">help()函数</span>）</strong></p> <p><img alt="" height="287" src="https://img-blog.csdnimg.cn/50c5badb6a424104bb3720e8e152087b.png" width="450"></p> <p>&nbsp;对工具使用 help()：</p> <pre data-index="21"><code class="hljs language-scss">help(torch.cuda.is_available)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong><span style="color:#fe2c24;">注意 is_available 不带括号</span></strong></p> <p><img alt="" height="153" src="https://img-blog.csdnimg.cn/3a125cd4eb114958872198fde9ab8625.png" width="651"></p> <p>&nbsp;返回一个布尔值（True或False），表明cuda是否可用</p> <h2 id="%E6%80%BB%E7%BB%93"><a name="t11"></a><strong>总结</strong></h2> <ul><li>dir() 函数：打开package</li><li>help() 函数：官方的解释文档，看函数怎么用   <hr><h1 id="4.%20Pycharm%E5%8F%8AJupyter%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%AF%B9%E6%AF%94"><a name="t12"></a>4. Pycharm及Jupyter使用及对比</h1> </li></ul> <h2 id="%E5%A6%82%E4%BD%95%E5%9C%A8PyCharm%E4%B8%AD%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE%EF%BC%9F"><a name="t13"></a><strong>如何在PyCharm中新建项目？</strong></h2> <p><strong>（1）新建文件夹 Learn_torch（右键：New Folder）</strong><br><img alt="" height="890" src="https://img-blog.csdnimg.cn/56b208ca671c48cfb26c153e2dc3a592.png" width="1190"><br><img alt="" height="891" src="https://img-blog.csdnimg.cn/10b4cc6ee59946d79be8f30310e9114f.png" width="1192"></p> <p>File —&gt; Settings</p> <p><img alt="" height="852" src="https://img-blog.csdnimg.cn/64f7dfbee52e41c595f0e6b705edfec5.png" width="841"></p> <p></p> <p><strong>（2）新建 Python文件，命名 first_demo</strong><br><img alt="" height="725" src="https://img-blog.csdnimg.cn/630372af9ef8414088d44356cf0aa8ce.png" width="1023"><br> &nbsp;</p> <p><strong>（3）运行程序：为该Python文件设置相应的Python解释器后，点击绿色的运行符号即可</strong><br><img alt="" height="1200" src="https://img-blog.csdnimg.cn/4a3c4b595d6348e49662d7ce99847028.png" width="1200"><br><br> 或直接右键：<br><img alt="" height="677" src="https://img-blog.csdnimg.cn/b0bdaa8265404098afdc0a995fdef678.png" width="1133"><br> &nbsp;</p> <h2 id="Python%E6%8E%A7%E5%88%B6%E5%8F%B0%E2%80%8B%E7%BC%96%E8%BE%91"><a name="t14"></a>Python控制台<br><img alt="" height="546" src="https://img-blog.csdnimg.cn/38530ddce773486aaf827e700b063548.png" width="988"></h2> <p>Python控制台（Python Console）是以每一行作为一个块进行执行&nbsp;</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%A6%82%E4%BD%95%E5%9C%A8Jupyter%E4%B8%AD%E6%96%B0%E5%BB%BA%E9%A1%B9%E7%9B%AE%EF%BC%9F"><a name="t15"></a><strong>如何在Jupyter中新建项目？</strong></h2> <p>&nbsp;首先在开始菜单打开anaconda的命令行，进入pytorch的conda环境，再打开Jupyter</p> <p><img alt="" height="215" src="https://img-blog.csdnimg.cn/1b19e1a4e66e406c8556c0f2fa0791b2.png" width="500"></p> <p>&nbsp;<img alt="" height="314" src="https://img-blog.csdnimg.cn/dc1a8b4a51ea4017bafa3aa71b8079b1.png" width="350"></p> <p>以每一个<strong><span style="color:#956fe7;">块</span></strong>为一个运行整体</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%89%E4%B8%AA%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F%EF%BC%88PyCharm%E3%80%81PyCharm%E7%9A%84Python%E6%8E%A7%E5%88%B6%E5%8F%B0%E3%80%81Jupyter%20Notebook%EF%BC%89%E7%9A%84%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A"><a name="t16"></a><strong>三种运行方式（PyCharm、PyCharm的Python控制台、Jupyter Notebook）的适用场景：</strong></h2> <p>代码是以块为一个整体运行的话，Python文件的块是所有行的代码，即在<strong><span style="color:#0d0016;"><span style="background-color:#ffd900;">PyCharm</span></span><span style="color:#ff9900;">运行时出现错误时，修改后要从头开始运行</span></strong></p> <p><span style="color:#0d0016;"><strong><span style="background-color:#ffd900;">PyCharm的Python控制台</span></strong></span>是一行一行代码运行的，即<strong>以每一行为一个块来运行的</strong>（也可以以任意行为块运行，按Shift+回车，输入下一行代码，再按回车运行）</p> <ul><li>优点：<span style="color:#fe2c24;"><strong>Python控制台可以看到每个变量的属性</strong></span></li><li>缺点：出现错误后代码的可阅读性大大降低</li><li>一般调试时使用</li></ul> <p><span style="color:#0d0016;"><strong><span style="background-color:#ffd900;">Jupyter</span></strong></span>以任意行为块运行</p> <p>Python控制台和Jupyter的好处是：某一块发生错误时，修改这一块时不会影响前面已经运行的块</p> <div class="table-box"><table border="1" cellpadding="1" cellspacing="1" style="width:680px;"><tbody><tr><td style="width:188px;"><strong>PyCharm</strong></td><td style="width:130px;">从头开始运行</td><td style="width:165px;">通用，传播方便，适用于大型项目</td><td style="width:192px;">需要从头运行</td></tr><tr><td style="width:188px;"><strong>PyCharm的Python控制台</strong></td><td style="width:130px;">一行一行运行（也可以以任意行）</td><td style="width:165px;">可以显示每个变量的属性，一般调试时使用</td><td style="width:192px;">出错时会破坏整体阅读性，不利于代码阅读及修改</td></tr><tr><td style="width:188px;"><strong>Jupyter Notebook</strong></td><td style="width:130px;">以任意行为块运行</td><td style="width:165px;">代码阅读性较高，利于代码的阅读及修改</td><td style="width:192px;">环境需要配置</td></tr></tbody></table></div> <hr> <h1 id="5.%20PyTorch%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%88%9D%E8%AE%A4%E8%AF%86"><a name="t17"></a>5. PyTorch加载数据初认识</h1> <p>对于神经网络训练，要从数据海洋里找到有用的数据</p> <h2 id="PyTorch%20%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E6%B6%89%E5%8F%8A%E4%B8%A4%E4%B8%AA%E7%B1%BB%EF%BC%9A"><a name="t18"></a><strong>PyTorch 读取数据涉及两个类：Dataset &amp; Dataloader</strong></h2> <p><span style="color:#ff9900;"><strong>Dataset：</strong></span>提供一种方式，获取其中需要的数据及其对应的真实的 label 值，并完成编号。主要实现以下两个功能：</p> <ul><li>如何获取每一个数据及其label</li><li>告诉我们总共有多少的数据</li></ul> <p><strong><span style="color:#ff9900;">Dataloader：</span></strong>打包（batch_size），为后面的神经网络提供不同的数据形式</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%87%A0%E7%A7%8D%E7%BB%84%E7%BB%87%E5%BD%A2%E5%BC%8F"><a name="t19"></a>数据集的几种组织形式</h2> <p>数据集 hymenoptera_data（识别蚂蚁和蜜蜂的数据集，二分类）</p> <p><img alt="" height="208" src="https://img-blog.csdnimg.cn/249c3f031b634f7ba304a14e31845141.png" width="400"></p> <ol><li>train 里有两个文件夹：ants 和 bees，其中分别都是一些蚂蚁和蜜蜂的图片</li><li>train_images是一个文件夹，train_labels是另一个文件夹，如OCR数据集</li><li>label直接为图片的名称</li></ol> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Dataset%E7%B1%BB%C2%A0"><a name="t20"></a>Dataset类&nbsp;</h2> <pre data-index="22"><code class="language-python hljs"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>查看Dataset类的介绍：</p> <pre data-index="23"><code class="language-python hljs"><span class="hljs-built_in">help</span>(Dataset)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>或者：</p> <pre data-index="24"><code class="language-python hljs">Dataset??</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>Dataset 是一个抽象类，所有数据集都需要继承这个类，所有子类都需要重写 __getitem__ 的方法，这个方法主要是获取每个数据集及其对应 label，还可以重写长度类 __len__</p> <pre data-index="25"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">raise</span> NotImplementedError</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__add__</span>(<span class="hljs-params">self, other</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> ConcatDataset([self, other])</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <hr> <h1 id="6.%20Dataset%E7%B1%BB%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98"><a name="t21"></a>6. Dataset类代码实战</h1> <h2 id="%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%E8%AF%BB%E5%9B%BE%E7%89%87"><a name="t22"></a>两种方法读图片</h2> <pre data-index="26"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 法1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path = <span class="hljs-string">"xxx"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img.show()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 法2：利用opencv读取图片，获得numpy型图片数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> cv2</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">cv_img=cv2.imread(img_path)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>安装opencv：&nbsp;</strong></p> <p>在 PyCharm的 Terminal 里输入（<span style="color:#fe2c24;"><strong>关闭代理服务器！！！</strong></span>）</p> <pre data-index="27"><code class="hljs language-undefined">pip install opencv-python</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>再</p> <pre data-index="28"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> cv2</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%8E%A7%E5%88%B6%E5%8F%B0%E8%AF%BB%E5%8F%96%26%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E7%89%87"><a name="t23"></a>控制台读取&amp;可视化图片</h2> <h3 id="%EF%BC%88%E4%B8%80%EF%BC%89%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F1%C2%A0"><a name="t24"></a>（一）数据格式1&nbsp;</h3> <p><img alt="" height="276" src="https://img-blog.csdnimg.cn/e396575aa6b14def81eb2e57800776d6.png" width="286"></p> <ul><li><strong>绝对路径：</strong>E:\学完了学完了\PyTorch\土堆-Pytorch\Learn_torch\dataset\train\ants</li><li><strong>相对路径：</strong>dataset/train/ants&nbsp;</li></ul> <p><img alt="" height="210" src="https://img-blog.csdnimg.cn/f909f7b9912b4b6c8775a2a2097d6aa6.png" width="413"></p> <p><img alt="" height="216" src="https://img-blog.csdnimg.cn/fd593fe2ea604d80b1c003c087517828.png" width="772"></p> <p>注意，<span style="color:#fe2c24;">路径引号前加 r 可以防止转义，或使用双斜杠&nbsp;</span>&nbsp;</p> <p>在Python控制台读取数据，可以看到图片的属性：</p> <pre data-index="29"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path = <span class="hljs-string">r"E:\学完了学完了\PyTorch\土堆-Pytorch\Learn_torch\dataset\train\ants\0013035.jpg"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;<img alt="" height="387" src="https://img-blog.csdnimg.cn/88888a5164d6447ca618d564dd94c5e3.png" width="446"></p> <p>输入 img.size 就可以返回属性的数值</p> <p><img alt="" height="93" src="https://img-blog.csdnimg.cn/bbe0260ea88e499f86dcaaf2315c62aa.png" width="309"></p> <p>可视化图片输入：img.show()</p> <p><img alt="" height="509" src="https://img-blog.csdnimg.cn/8452a9bd1ef84bda9b6604324b07d829.png" width="762"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E8%AF%BB%E6%95%B0%E6%8D%AE%EF%BC%9A"><a name="t25"></a><strong>读数据</strong></h3> <p>想要获取图片地址（通过索引），需要os库</p> <pre data-index="30"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> os</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dir_path = <span class="hljs-string">"dataset/train/ants"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path_list = os.listdir(dir_path)  <span class="hljs-comment"># 将文件夹下的东西变成一个列表</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="296" src="https://img-blog.csdnimg.cn/390ab5d8af664c84af6d702dda7e8ded.png" width="524">&nbsp;&nbsp;&nbsp;</p> <pre data-index="31"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> os </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">root_dir = <span class="hljs-string">"dataset/train"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">label_dir = <span class="hljs-string">"ants"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">path = os.path.join(root_dir, label_dir)  <span class="hljs-comment"># 把两个路径拼接在一起</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="98" src="https://img-blog.csdnimg.cn/66f82c2f0d5e48b3b15ffaaac07f163d.png" width="327"></p> <p><strong>完整代码：&nbsp;</strong></p> <pre data-index="32" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image   <span class="hljs-comment">#读取图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> os   <span class="hljs-comment">#想要获得所有图片的地址，需要导入os（系统库）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#创建一个class，继承Dataset类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,root_dir,label_dir</span>):   <span class="hljs-comment">#创建初始化类，即根据这个类去创建一个实例时需要运行的函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#通过索引获取图片的地址，需要先创建图片地址的list</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#self可以把其指定的变量给后面的函数使用，相当于为整个class提供全局变量</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    self.root_dir=root_dir</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    self.label_dir=label_dir</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    self.path=os.path.join(self.root_dir,self.label_dir)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    self.img_path=os.listdir(self.path)  <span class="hljs-comment">#获得图片下所有的地址</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):   <span class="hljs-comment">#idx为编号</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#获取每一个图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img_name=self.img_path[idx]  <span class="hljs-comment">#名称</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img_item_path=os.path.join(self.root_dir,self.label_dir,img_name)  <span class="hljs-comment"># 每张图片的相对路径</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img=Image.<span class="hljs-built_in">open</span>(img_item_path)  <span class="hljs-comment">#读取图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    label=self.label_dir</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> img,label</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):    <span class="hljs-comment">#数据集的长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.img_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#用类创建实例</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">root_dir=<span class="hljs-string">"dataset/train"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">ants_label_dir=<span class="hljs-string">"ants"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">bees_label_dir=<span class="hljs-string">"bees"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">ants_dataset=MyData(root_dir,ants_label_dir)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">bees_dataset=MyData(root_dir,bees_label_dir)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img, label = ants_dataset[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img.show()   <span class="hljs-comment"># 可视化第一张图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#将ants(124张)和bees(121张)两个数据集进行拼接</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataset=ants_dataset+bees_dataset</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h2 id="%EF%BC%88%E4%BA%8C%EF%BC%89%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F2"><a name="t26"></a>（二）数据格式2</h2> <p>当label比较复杂，存储数据比较多时，不可能以文件夹命名的方式，而是以<span style="color:#956fe7;"><strong>每张图片对应一个txt文件，txt里存储label信息</strong></span>的方式</p> <p><img alt="" height="237" src="https://img-blog.csdnimg.cn/d905548d1fef4a33bee96ecde804fafc.png" width="284"></p> <pre data-index="33"><strong>rename_dataset.py</strong>代码如下：&nbsp;</pre> <p><img alt="" height="647" src="https://img-blog.csdnimg.cn/cc8febf0e1ea4f93ba06dcc49276ca2c.png" width="1200"></p> <pre data-index="34"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> os</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">root_dir=<span class="hljs-string">r"E:\学完了学完了\PyTorch\土堆-Pytorch\Learn_torch\dataset\train"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 把原来的ants重命名为ants_image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">target_dir=<span class="hljs-string">"ants_image"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path=os.listdir(os.path.join(root_dir,target_dir))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">label=target_dir.split(<span class="hljs-string">'_'</span>)[<span class="hljs-number">0</span>]   <span class="hljs-comment"># ants</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">out_dir=<span class="hljs-string">"ants_label"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> img_path:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    file_name=i.split(<span class="hljs-string">'.jpg'</span>)[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(root_dir,out_dir,<span class="hljs-string">"&#123;&#125;.txt"</span>.<span class="hljs-built_in">format</span>(file_name)),<span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> f:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        f.write(label)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行效果如图：&nbsp;</p> <p><img alt="" height="373" src="https://img-blog.csdnimg.cn/b78dccb471574c3da2079b5dbe6e300b.png" width="980"></p> <hr> <h1 id="7.%20TensorBoard%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t27"></a>7. TensorBoard的使用</h1> <ul><li><span style="color:#956fe7;">安装</span></li><li><span style="color:#956fe7;">add_scalar() 的使用（常用来绘制 train/val loss）</span></li><li><span style="color:#956fe7;">add_image() 的使用（常用来观察训练结果）</span></li></ul> <p>transforms 在 Dataset 类中很常用，对图像进行变换，如图像要统一到某一个尺寸，或图像中的每一个数据进行类的转换</p> <p>学 TensorBoard 探究：</p> <ul><li>训练过程中loss是如何变化的</li><li>模型在不同阶段的输出</li></ul> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="SummaryWriter%E7%B1%BB"><a name="t28"></a>SummaryWriter类</h2> <pre data-index="35"><code class="language-python hljs"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <blockquote>  <p>查看一个类如何使用：在PyCharm中，按住Ctrl键，把鼠标移到类上</p> </blockquote> <p id="SummaryWriter%E7%B1%BB%EF%BC%9A">是一个直接向 log_dir 文件夹写入的事件文件，可以被 TensorBoard 进行解析</p> <p><strong>初始化函数：</strong></p> <pre data-index="36"><code class="language-python hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, log_dir=<span class="hljs-literal">None</span></span>):</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="536" src="https://img-blog.csdnimg.cn/c06f42df11e24e72a75fff80aabbdc2a.png" width="1200"></p> <p><img alt="" height="781" src="https://img-blog.csdnimg.cn/815329f73675411cb57ab417c1075905.png" width="1200"></p> <pre data-index="37"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 实例化SummaryWriter类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"logs"</span>)   <span class="hljs-comment"># 把对应的事件文件存储到logs文件夹下</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>主要用到两个方法：</strong></p> <pre data-index="38"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_scalar()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E5%AE%89%E8%A3%85TensorBoard%EF%BC%9A"><a name="t29"></a>安装TensorBoard</h3> <p>在 Anaconda 命令行中激活 pytorch 环境，或直接在 PyCharm 的 Terminal 的 pytorch 环境中安装</p> <p>输入：</p> <pre data-index="39"><code class="language-python hljs">pip install tensorboard</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>即可安装成功</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <blockquote>  <p>Ctrl + /&nbsp; &nbsp; 注释</p> </blockquote> <h3 id="add_scalar()%20%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%9A"><a name="t30"></a>add_scalar() 方法的使用</h3> <pre data-index="40"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_scalar</span>(<span class="hljs-params"><span class="hljs-params"></span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        self,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        tag,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        scalar_value,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        global_step=<span class="hljs-literal">None</span>,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        walltime=<span class="hljs-literal">None</span>,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        new_style=<span class="hljs-literal">False</span>,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">        double_precision=<span class="hljs-literal">False</span>,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-params">    </span>):</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>添加一个标量数据到 Summary 当中，需要参数</p> <ul><li><span style="color:#956fe7;"><strong>tag：</strong></span>Data指定方式，类似于图表的title</li><li><span style="color:#956fe7;"><strong>scalar_value：</strong></span>需要保存的数值（y轴）</li><li><span style="color:#956fe7;"><strong>global_step：</strong></span>训练到多少步（x轴）</li></ul> <p><strong>例：y=x</strong></p> <pre data-index="41"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter   <span class="hljs-comment">#导入SummaryWriter类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#创建实例</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer=SummaryWriter(<span class="hljs-string">"logs"</span>)   <span class="hljs-comment">#把对应的事件文件存储到logs文件夹下</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#两个方法</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># writer.add_image()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># y=x</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"y=x"</span>,i,i)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后多了一个logs文件夹，下面是TensorBoard的一些事件文件，如图：</p> <p><img alt="" height="307" src="https://img-blog.csdnimg.cn/c998d7467d634a20a9ca88696076e939.png" width="300"></p> <p><strong>如何打开事件文件？</strong></p> <p>在 Terminal 里输入：</p> <pre data-index="42"><code class="language-python hljs">tensorboard --logdir=logs  <span class="hljs-comment"># logdir=事件文件所在文件夹名</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果如图：</strong></p> <p><img alt="" height="188" src="https://img-blog.csdnimg.cn/e6bbacdc0b0e4f75b44e30800dd6cf59.png" width="1200"></p> <p><img alt="" height="955" src="https://img-blog.csdnimg.cn/75bb9c1dbb784bc489dcfbc650d216ac.png" width="1132"></p> <p>为了防止和别人冲突（一台服务器上有好几个人训练，默认打开的都是6006端口），也可以指定端口，命令如下：</p> <pre data-index="43"><code class="language-python hljs">​tensorboard --logdir=logs --port=<span class="hljs-number">6007</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>例：y=2x</strong></p> <pre data-index="44"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter   <span class="hljs-comment">#导入SummaryWriter类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#创建实例</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer=SummaryWriter(<span class="hljs-string">"logs"</span>)   <span class="hljs-comment">#把对应的事件文件存储到logs文件夹下</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#两个方法</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># writer.add_image()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># y=2x</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"y=2x"</span>,<span class="hljs-number">2</span>*i,i)  <span class="hljs-comment"># 标题、y轴、x轴</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;<img alt="" height="314" src="https://img-blog.csdnimg.cn/06ebc66c21ad4904845b439460813eb5.png" width="350"></p> <p><strong>title 和 y 不一致的情况：</strong></p> <p>&nbsp;<img alt="" height="71" src="https://img-blog.csdnimg.cn/88179f35f1584ae9bf1705bfeb01843a.png" width="400"></p> <figure class="image">  <img alt="" height="316" src="https://img-blog.csdnimg.cn/2e440026a29b4f10b62bbecd246a1ea4.png" width="350">  <figcaption>   过程中会发生拟合  </figcaption> </figure> <p>每向 writer 中写入新的事件，也记录了上一个事件</p> <p><strong>如何解决？</strong></p> <p>把logs文件夹下的所有文件删掉，程序删掉，重新开始</p> <p>或：重新写一个子文件，即创建新的 SummaryWriter("新文件夹")</p> <blockquote>  <p>删掉logs下的文件，重新运行代码，在 Terminal 里按 Ctrl+C ，再输入命令：</p>  <p>​tensorboard --logdir=logs --port=6007</p>  <p>就可以出现名字为y=2x，但实际纵坐标是y=3x数值的图像</p> </blockquote> <p><span style="color:#fe2c24;"><strong>以上即是显示 train_loss 的一个方式</strong></span></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="add_image()%20%E7%9A%84%E4%BD%BF%E7%94%A8%EF%BC%9A"><a name="t31"></a>add_image() 的使用</h3> <pre data-index="45"><code class="language-python hljs"><span class="hljs-keyword">def</span> <span class="hljs-title function_">add_image</span>(<span class="hljs-params">self, tag, img_tensor, global_step=<span class="hljs-literal">None</span></span>):</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <ul><li>tag：对应图像的title</li><li><span style="color:#956fe7;"><strong>img_tensor：图像的数据类型，只能是torch.Tensor、numpy.array、string/blobname</strong></span></li><li>global_step：训练步骤，int 类型</li></ul> <p><img alt="" height="739" src="https://img-blog.csdnimg.cn/2c100a52161541f5a5fcc928a0efdda2.png" width="1200"><img alt="" height="261" src="https://img-blog.csdnimg.cn/aa2de5b83a1c4cecbbc630cd73053acc.png" width="1200"></p> <p>例子：</p> <p><img alt="" height="740" src="https://img-blog.csdnimg.cn/cb08600ad5b0487988f758a97f367ba7.png" width="1200"></p> <p>在Python控制台输入：<img alt="" height="438" src="https://img-blog.csdnimg.cn/5a02562f7ae3480f816ab45844fdc2f7.png" width="1200"></p> <pre data-index="46"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 打开控制台，其位置就是项目文件夹所在的位置</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 故只需复制相对地址</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path = <span class="hljs-string">"data/train/ants_image/0013035.jpg"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(image_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img))</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E5%88%A9%E7%94%A8numpy.array()%EF%BC%8C%E5%AF%B9PIL%E5%9B%BE%E7%89%87%E8%BF%9B%E8%A1%8C%E8%BD%AC%E6%8D%A2%EF%BC%9A"><a name="t32"></a>利用numpy.array()，对PIL图片进行转换</h3> <p>在Python控制台，把<strong>PIL类型的img变量</strong>转换为<strong><span style="color:#fe2c24;">numpy类型（add_image() 函数所需要的图像的数据类型）</span></strong>，重新赋值给img_array：</p> <pre data-index="47"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_array=np.array(img)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img_array))   <span class="hljs-comment"># numpy.ndarray</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><span style="color:#fe2c24;"><strong>从PIL到numpy，需要在add_image()中指定shape中每一个数字/维表示的含义&nbsp;</strong></span></p> <p><strong>step1：蚂蚁为例&nbsp;</strong></p> <pre data-index="48" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter   <span class="hljs-comment">#导入SummaryWriter类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#创建实例</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer=SummaryWriter(<span class="hljs-string">"logs"</span>)   <span class="hljs-comment">#把对应的事件文件存储到logs文件夹下</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path=<span class="hljs-string">"data/train/ants_image/0013035.jpg"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_PIL=Image.<span class="hljs-built_in">open</span>(image_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_array=np.array(img_PIL)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img_array))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_array.shape)   <span class="hljs-comment">#(512,768,3)  即(H,W,C)(高度，宽度，通道)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"test"</span>,img_array,<span class="hljs-number">1</span>, dataformats=<span class="hljs-string">'HWC'</span>)  <span class="hljs-comment"># 第1步</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果：</strong></p> <p><img alt="" height="574" src="https://img-blog.csdnimg.cn/b08282ae5d0349bf83477ac15c149554.png" width="1000"></p> <p><strong>step2：蜜蜂为例&nbsp;</strong></p> <pre data-index="49" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter   <span class="hljs-comment">#导入SummaryWriter类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#创建实例</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer=SummaryWriter(<span class="hljs-string">"logs"</span>)   <span class="hljs-comment">#把对应的事件文件存储到logs文件夹下</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path=<span class="hljs-string">"data/train/bees_image/16838648_415acd9e3f.jpg"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_PIL=Image.<span class="hljs-built_in">open</span>(image_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_array=np.array(img_PIL)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img_array))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_array.shape)   <span class="hljs-comment">#(512,768,3)  即(H,W,C)(高度，宽度，通道)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"test"</span>,img_array,<span class="hljs-number">2</span>, dataformats=<span class="hljs-string">'HWC'</span>)   <span class="hljs-comment"># 第2步</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果：</strong></p> <p><img alt="" height="363" src="https://img-blog.csdnimg.cn/e6752a99752d477c924228a8055f211d.png" width="350"></p> <p>在一个title下，<span style="color:#956fe7;"><strong>通过滑块显示每一步的图形</strong></span>，可以直观地观察训练中给model提供了哪些数据，或者想对model进行测试时，可以看到每个阶段的输出结果</p> <p>如果想要<span style="color:#956fe7;"><strong>单独显示</strong></span>，重命名一下title即可，即 writer.add_image() 的第一个字符串类型的参数</p> <hr> <h1 id="8.%20Transforms%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t33"></a>8. 图像变换，torchvision中transforms的使用</h1> <p>对图片进行一些变换</p> <h2 id="Transforms%E7%9A%84%E7%BB%93%E6%9E%84%E5%8F%8A%E7%94%A8%E6%B3%95"><a name="t34"></a>transforms的结构及用法</h2> <pre data-index="50"><code class="language-python hljs"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h3 id="%E7%BB%93%E6%9E%84"><a name="t35"></a><strong>结构</strong></h3> <p>按住Ctrl，看&nbsp;<strong><span style="color:#956fe7;">transforms.py文件（工具箱）</span></strong>，它定义了很多 <strong><span style="color:#956fe7;">class文件（工具）</span></strong></p> <blockquote>  <p><img alt="" height="454" src="https://img-blog.csdnimg.cn/9cd08d7d363d46febe63d32c7b51f94f.png" width="250"></p>  <p></p>  <p><strong>搜索快捷键：</strong></p>  <p>File—&gt; Settings—&gt; Keymap—&gt; 搜索 structure（快捷键 Alt+7）</p> </blockquote> <h3 id="%E4%B8%80%E4%BA%9B%E7%B1%BB"><a name="t36"></a><strong>一些类</strong></h3> <ul><li><strong><span style="color:#956fe7;">Compose类：</span></strong>结合不同的transforms   <figure class="image">    <img alt="" height="292" src="https://img-blog.csdnimg.cn/641af1754a874db684b5781b38756092.png" width="888">    <figcaption>     &nbsp;图片先经过中心裁剪，再变成Tensor返回    </figcaption>   </figure></li><li><span style="color:#956fe7;"><strong>ToTensor类：</strong></span>把一个PIL的Image或者numpy数据类型的图片转换成 tensor 的数据类型</li><li><span style="color:#956fe7;"><strong>ToPILImage类：</strong></span>把一个图片转换成PIL Image</li><li><span style="color:#956fe7;"><strong>Normalize类：</strong></span>归一化</li><li><span style="color:#956fe7;"><strong>Resize类：</strong></span>尺寸变换</li><li><span style="color:#956fe7;"><strong>CenterCrop类：</strong></span>中心裁剪</li></ul> <h3 id="%E4%BD%BF%E7%94%A8"><a name="t37"></a><strong>使用</strong></h3> <ul><li>transforms.py&nbsp; &nbsp;工具箱</li><li>totensor / resize等类&nbsp; &nbsp;工具</li></ul> <p>拿一些<strong><span style="color:#fe2c24;">特定格式</span></strong>的图片，经过工具（class文件）后，就会输出我们想要的图片变换的结果</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%A4%E4%B8%AA%E9%97%AE%E9%A2%98"><a name="t38"></a>两个问题</h2> <p>python的用法 ——&gt; tensor数据类型<br> 通过 transforms.ToTensor去解决两个问题</p> <ol><li>Transforms该如何使用</li><li>Tensor数据类型与其他图片数据类型有什么区别？为什么需要Tensor数据类型&nbsp;</li></ol> <pre data-index="51"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 绝对路径 C:\Users\11842\Desktop\Learn_torch\data\train\ants_image\0013035.jpg</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 相对路径 data/train/ants_image/0013035.jpg</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path=<span class="hljs-string">"data/train/ants_image/0013035.jpg"</span>   <span class="hljs-comment">#用相对路径，绝对路径里的\在Windows系统下会被当做转义符</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># img_path_abs="C:\Users\11842\Desktop\Learn_torch\data\train\ants_image\0013035.jpg"，双引号前加r表示转义</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)   <span class="hljs-comment">#Image是Python中内置的图片的库</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img)  <span class="hljs-comment"># PIL类型</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h3 id="1%E3%80%81transforms%20%E8%AF%A5%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%EF%BC%88python%EF%BC%89"><a name="t39"></a>1、transforms 该如何使用（python）</h3> <p>从transforms中选择一个class，对它进行创建，对创建的对象传入图片，即可返回出结果&nbsp;</p> <p><span style="color:#956fe7;"><strong>ToTensor</strong></span>将一个 PIL Image 或 numpy.ndarray 转换为 tensor的数据类型&nbsp;</p> <p><img alt="" height="678" src="https://img-blog.csdnimg.cn/25ceef308920482e99d1167ca19b2d9b.png" width="1072"></p> <pre data-index="52"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 1、Transforms该如何使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_trans = transforms.ToTensor()  <span class="hljs-comment">#从工具箱transforms里取出ToTensor类，返回tensor_trans对象</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_img=tensor_trans(img)   <span class="hljs-comment">#创建出tensor_trans后，传入其需要的参数，即可返回结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(tensor_img)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <blockquote>  <p>Ctrl+P可以提示函数里需要填什么参数&nbsp;</p> </blockquote> <p><img alt="" height="944" src="https://img-blog.csdnimg.cn/3aab025d1a6e4fee9d4effb56a6259cf.png" width="1200"></p> <h3 id="2%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%BB%AC%E9%9C%80%E8%A6%81%20Tensor%20%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><a name="t40"></a>2、为什么我们需要 Tensor 数据类型</h3> <p>在Python Console输入：</p> <pre data-index="53"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path= <span class="hljs-string">"data/train/ants_image/0013035.jpg"</span>  </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)   </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_trans = transforms.ToTensor() </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_img = tensor_trans(img)  </div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="168" src="https://img-blog.csdnimg.cn/1ef2f761588c4007965d8bb97eb928b1.png" width="805"></p> <p>打开img，即用Python内置的函数读取的图片，具有的参数有：</p> <p><img alt="" height="425" src="https://img-blog.csdnimg.cn/a2e16b83cc414c369746f0be3f8dcf86.png" width="593"></p> <p>再打开tensor_img，看一下它有哪些参数：</p> <p><img alt="" height="389" src="https://img-blog.csdnimg.cn/f2d870dd257546268dc9faa309edc33f.png" width="490"></p> <p><img alt="" height="352" src="https://img-blog.csdnimg.cn/dbd71c7b9c2442e294dc8272b4cdf58a.png" width="438"></p> <p><span style="color:#fe2c24;"><strong>Tensor 数据类型包装了反向神经网络所需要的一些理论基础的参数</strong></span>，如：_backward_hooks、_grad等<strong>（先转换成Tensor数据类型，再训练）</strong></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%A4%E7%A7%8D%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E7%9A%84%E6%96%B9%E5%BC%8F"><a name="t41"></a><span style="color:#0d0016;"><strong>两种读取图片的方式</strong></span></h2> <ul><li><strong><span style="background-color:#fefcd8;">PIL Image</span></strong> <pre data-index="54"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path = <span class="hljs-string">"xxx"</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img.show()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> </li><li><strong><span style="background-color:#fefcd8;">numpy.ndarray（通过opencv）</span></strong> <pre data-index="55"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> cv2</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">cv_img=cv2.imread(img_path)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> </li></ul> <p>上节课以 numpy.array 类型为例，这节课使用 <strong><span style="color:#956fe7;">torch.Tensor 类型：</span></strong></p> <pre data-index="56" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># python的用法 ——&gt; tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 通过 transforms.ToTensor去解决两个问题</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 1、Transforms该如何使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 2、Tensor数据类型与其他图片数据类型有什么区别？为什么需要Tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 绝对路径 C:\Users\11842\Desktop\Learn_torch\data\train\ants_image\0013035.jpg</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 相对路径 data/train/ants_image/0013035.jpg</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_path=<span class="hljs-string">"data/train/ants_image/0013035.jpg"</span>   <span class="hljs-comment">#用相对路径，绝对路径里的\在Windows系统下会被当做转义符</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># img_path_abs="C:\Users\11842\Desktop\Learn_torch\data\train\ants_image\0013035.jpg"，双引号前加r表示转义</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img = Image.<span class="hljs-built_in">open</span>(img_path)   <span class="hljs-comment">#Image是Python中内置的图片的库</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#print(img)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"logs"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 1、Transforms该如何使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_trans = transforms.ToTensor()  <span class="hljs-comment">#从工具箱transforms里取出ToTensor类，返回tensor_trans对象</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor_img = tensor_trans(img)   <span class="hljs-comment">#创建出tensor_trans后，传入其需要的参数，即可返回结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#print(tensor_img)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"Tensor_img"</span>,tensor_img)  <span class="hljs-comment"># .add_image(tag, img_tensor, global_step)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># tag即名称</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># img_tensor的类型为torch.Tensor/numpy.array/string/blobname</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># global_step为int类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后，在 Terminal 里输入：</p> <pre data-index="57"><code class="language-python hljs">tensorboard --logdir=logs</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="208" src="https://img-blog.csdnimg.cn/27e90ac1e8b6432bac9174ffb09e94be.png" width="1200"></p> <p>进入网址后可以看到图片：</p> <p><img alt="" height="264" src="https://img-blog.csdnimg.cn/d8746a4fab774cd5b7659f69709f6c29.png" width="350"></p> <hr> <h1 id="9.%20%E5%B8%B8%E8%A7%81%E7%9A%84Transforms"><a name="t42"></a>9. 常见的Transforms的使用</h1> <ul><li>输入</li><li>输出</li><li>作用</li></ul> <p>图片有不同的格式，打开方式也不同</p> <div class="table-box"><table border="1" cellpadding="1" cellspacing="1" style="width:413px;"><tbody><tr><td><strong>图片格式</strong></td><td style="width:314px;"><strong>打开方式</strong></td></tr><tr><td>PIL</td><td style="width:314px;">Image.open()&nbsp; &nbsp;——Python自带的图片打开方式</td></tr><tr><td>tensor</td><td style="width:314px;">ToTensor()</td></tr><tr><td>narrays</td><td style="width:314px;">cv.imread()&nbsp; &nbsp;——Opencv</td></tr></tbody></table></div> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Compose%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t43"></a>Compose 的使用</h2> <p>把不同的 transforms 结合在一起，后面接一个数组，里面是不同的transforms</p> <pre data-index="58"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">Example:图片首先要经过中心裁剪，再转换成Tensor数据类型</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        &gt;&gt;&gt; transforms.Compose([</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        &gt;&gt;&gt;     transforms.CenterCrop(<span class="hljs-number">10</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        &gt;&gt;&gt;     transforms.PILToTensor(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        &gt;&gt;&gt;     transforms.ConvertImageDtype(torch.<span class="hljs-built_in">float</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        &gt;&gt;&gt; ])</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="Python%E4%B8%AD%20__call__%20%E7%9A%84%E7%94%A8%E6%B3%95"><a name="t44"></a>Python中 __call__ 的用法</h3> <p>内置函数 __call__ ，<strong>不用.的方式调用方法，可以直接拿对象名，加上需要的参数，即可调用方法</strong></p> <blockquote>  <p>按 Ctrl+p，会提示需要什么参数</p> </blockquote> <pre data-index="59"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Person</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, name</span>):   <span class="hljs-comment">#下划线__表示为内置函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"__call__"</span>+<span class="hljs-string">"Hello "</span>+name)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">hello</span>(<span class="hljs-params">self,name</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"hello"</span>+name)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">person = Person()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">person(<span class="hljs-string">"zhangsan"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">person.hello(<span class="hljs-string">"lisi"</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>输出结果如下：</p> <pre data-index="60"><code class="hljs language-markdown"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-strong">__call__</span>Hello zhangsan</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">hellolisi</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="ToTensor%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t45"></a>ToTensor 的使用</h2> <p>把 PIL Image 或 numpy.ndarray 类型转换为 tensor 类型（TensorBoard 必须是 tensor 的数据类型）</p> <pre data-index="61"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"logs"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img=Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">"images/people.jpg"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img)  <span class="hljs-comment">#可以看到类型是PIL</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#ToTensor的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_totensor = transforms.ToTensor()  <span class="hljs-comment">#将类型转换为tensor</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_tensor = trans_totensor(img)   <span class="hljs-comment">#img变为tensor类型后，就可以放入TensorBoard当中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"ToTensor"</span>,img_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>（运行前要先把之前的logs进行删除）</strong>运行后，在 Terminal 里输入：</p> <pre data-index="62"><code class="language-python hljs">tensorboard --logdir=logs</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="214" src="https://img-blog.csdnimg.cn/aa841d274d8b47c8be5791a2e2fd7cc7.png" width="1200"></p> <p>进入网址后可以看到图片：</p> <p><img alt="" height="298" src="https://img-blog.csdnimg.cn/782100bcd14243b7a00831a5fa354554.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="ToPILImage%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t46"></a>ToPILImage 的使用</h2> <p>把 tensor 数据类型或 ndarray 类型转换成 PIL Image</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Normalize%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t47"></a>Normalize 的使用</h2> <p>用平均值/标准差归一化 <strong>tensor 类型的 image<span style="color:#ff9900;">（输入）</span></strong></p> <p>图片RGB三个信道，将每个信道中的输入进行归一化</p> <pre data-index="63">output[channel] = (input[channel] - mean[channel]) / std[channel]</pre> <p>设置 mean 和 std 都为0.5，则 output= 2*input -1。如果 input 图片像素值为0~1范围内，那么结果就是 -1~1之间</p> <pre data-index="64"><code class="language-python hljs"><ol class="hljs-ln" style="width:947px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#Normalize的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_tensor[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])  <span class="hljs-comment"># 第0层第0行第0列</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_norm = transforms.Normalize([<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>],[<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>,<span class="hljs-number">0.5</span>])  <span class="hljs-comment"># mean,std，因为图片是RGB三信道，故传入三个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_norm = trans_norm(img_tensor)  <span class="hljs-comment"># 输入的类型要是tensor</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_norm[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"Normalize"</span>,img_norm)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>输出结果：&nbsp;</strong></p> <pre data-index="65"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor(<span class="hljs-number">0.6549</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor(<span class="hljs-number">0.3098</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;刷新网页：</p> <p>&nbsp;<img alt="" height="288" src="https://img-blog.csdnimg.cn/37058758f6ee48ff9f2117f370f52e02.png" width="350"></p> <p><strong>加入step值：</strong></p> <pre data-index="66"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#Normalize的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_tensor[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_norm = transforms.Normalize([<span class="hljs-number">6</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">9</span>,<span class="hljs-number">3</span>,<span class="hljs-number">5</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_norm = trans_norm(img_tensor)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_norm[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>][<span class="hljs-number">0</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"Normalize"</span>,img_norm,<span class="hljs-number">2</span>)  <span class="hljs-comment"># 第二步</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="544" src="https://img-blog.csdnimg.cn/acc6aa6d0ce245378994fbe162fd5347.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Resize()%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t48"></a>Resize() 的使用</h2> <p><strong><span style="color:#fe2c24;">输入：PIL Image</span></strong>&nbsp; &nbsp; &nbsp; 将输入转变到给定尺寸</p> <ul><li><strong>序列：</strong>（h,w）高度，宽度</li><li><strong>一个整数：</strong>不改变高和宽的比例，只单纯改变最小边和最长边之间的大小关系。之前图里最小的边将会匹配这个数（等比缩放）</li></ul> <blockquote>  <p><strong>PyCharm小技巧设置：忽略大小写，进行提示匹配</strong></p>  <ul><li>一般情况下，你需要输入R，才能提示出Resize</li><li>我们想设置，即便你输入的是r，也能提示出Resize，也就是忽略了大小写进行匹配提示</li></ul>  <p>File—&gt; Settings—&gt; 搜索case—&gt; Editor-General-Code Completion-去掉Match case前的√</p>  <p>—&gt;Apply—&gt;OK</p> </blockquote> <p><span style="color:#fe2c24;"><strong>返回值还是 PIL Image</strong></span></p> <pre data-index="67"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#Resize的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img.size)  <span class="hljs-comment"># 输入是PIL.Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_resize = transforms.Resize((<span class="hljs-number">512</span>,<span class="hljs-number">512</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#img：PIL --&gt; resize --&gt; img_resize：PIL</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_resize = trans_resize(img)  <span class="hljs-comment">#输出还是PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#img_resize：PIL --&gt; totensor --&gt; img_resize：tensor（同名，覆盖）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_resize = trans_totensor(img_resize)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"Resize"</span>,img_resize,<span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img_resize)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="461" src="https://img-blog.csdnimg.cn/42a5e657926a488583f3df42a3ebe1b8.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Compose()%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t49"></a>Compose() 的使用</h2> <p><strong>Compose() 中的参数需要是一个<span style="color:#fe2c24;">列表</span></strong>，Python中列表的表示形式为[数据1，数据2，...]</p> <p><strong>在Compose中，数据需要是<span style="color:#fe2c24;">transforms类型</span></strong>，所以得到<strong><span style="background-color:#fefcd8;">Compose([transforms参数1，transforms参数2，...])</span></strong></p> <pre data-index="68"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#Compose的使用（将输出类型从PIL变为tensor类型，第二种方法）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_resize_2 = transforms.Resize(<span class="hljs-number">512</span>)  <span class="hljs-comment"># 将图片短边缩放至512，长宽比保持不变</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># PIL --&gt; resize --&gt; PIL --&gt; totensor --&gt; tensor</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#compose()就是把两个参数功能整合，第一个参数是改变图像大小，第二个参数是转换类型，前者的输出类型与后者的输入类型必须匹配</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_compose = transforms.Compose([trans_resize_2,trans_totensor])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img_resize_2 = trans_compose(img)   <span class="hljs-comment"># 输入需要是PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_image(<span class="hljs-string">"Resize"</span>,img_resize_2,<span class="hljs-number">1</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="422" src="https://img-blog.csdnimg.cn/d14fc5ea8df04f30b954967d91fa84fa.png" width="350">  <figcaption>   长方形  </figcaption> </figure> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="RandomCrop()%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t50"></a>RandomCrop() 的使用</h2> <p>随机裁剪，<span style="color:#fe2c24;"><strong>输入PIL Image</strong></span></p> <p><strong>参数size：</strong></p> <ul><li>sequence：（h,w） 高，宽</li><li>int：裁剪一个该整数×该整数的图像</li></ul> <p><strong>（1）以 int 为例：&nbsp;</strong></p> <pre data-index="69"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#RandomCrop()的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_random = transforms.RandomCrop(<span class="hljs-number">512</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_compose_2 = transforms.Compose([trans_random,trans_totensor])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment">#裁剪10个</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img_crop = trans_compose_2(img)  <span class="hljs-comment"># 输入需要是PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_image(<span class="hljs-string">"RandomCrop"</span>,img_crop,i)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="414" src="https://img-blog.csdnimg.cn/69f6acb888404e929aff38a47ad97bb1.png" width="350"></p> <p><strong>（2）以 sequence 为例：</strong></p> <pre data-index="70"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#RandomCrop()的使用</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_random = transforms.RandomCrop((<span class="hljs-number">500</span>,<span class="hljs-number">1000</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">trans_compose_2 = transforms.Compose([trans_random,trans_totensor])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):  <span class="hljs-comment">#裁剪10个</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img_crop = trans_compose_2(img)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_image(<span class="hljs-string">"RandomCropHW"</span>,img_crop,i)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;<img alt="" height="278" src="https://img-blog.csdnimg.cn/6e41936075584ab0860593106d07c748.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%80%BB%E7%BB%93%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><a name="t51"></a>总结使用方法</h2> <ul><li>关注输入和输出类型</li><li>多看官方文档</li><li>关注方法需要什么参数：参数如果设置了默认值，保留默认值即可，没有默认值的需要指定（看一下要求传入什么类型的参数）</li><li>不知道变量的<strong><span style="color:#956fe7;">输出</span></strong>类型可以   <ul><li><span style="color:#ff9900;">直接print该变量</span></li><li><span style="color:#ff9900;">print(type())</span>，看结果里显示什么类型</li><li><span style="color:#ff9900;">断点调试 dubug</span></li></ul></li><li>最后要 totensor，在 tensorboard 看一下结果（tensorboard需要tensor数据类型进行显示）   <hr><h1 id="10.%20torchvision%20%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8"><a name="t52"></a>10. torchvision 中的数据集使用</h1> </li><li>如何把数据集（多张图片）和 transforms 结合在一起</li><li>标准数据集如何下载、查看、使用</li></ul> <figure class="image">  <img alt="" height="909" src="https://img-blog.csdnimg.cn/710268e222f44d81adce42734b4d45d6.png" width="1200">  <figcaption>   Pytorch官网  </figcaption> </figure> <p>&nbsp;<a href="https://pytorch.org/vision/stable/index.html" title="torchvision — Torchvision 0.11.0 documentation">torchvision — Torchvision 0.11.0 documentation</a></p> <p>（1）<a href="https://pytorch.org/vision/stable/datasets.html" title="torchvision.datasets">torchvision.datasets</a></p> <p>如：COCO 目标检测、语义分割；MNIST 手写文字；CIFAR 物体识别</p> <p>（2）<a href="https://pytorch.org/vision/stable/io.html" title="torchvision.io">torchvision.io</a></p> <p>&nbsp;输入输出模块，不常用</p> <p>（3）<a href="https://pytorch.org/vision/stable/models.html" title="torchvision.models">torchvision.models</a></p> <p>提供一些比较常见的神经网络，有的已经预训练好，如分类、语义分割、目标检测、视频分类</p> <p>（4）<a class="link-info" href="https://pytorch.org/vision/stable/ops.html" title="torchvision.ops">torchvision.ops</a></p> <p>torchvision提供的一些比较少见的特殊的操作，不常用</p> <p>（5）<a href="https://pytorch.org/vision/stable/transforms.html" title="torchvision.transforms">torchvision.transforms</a></p> <p>（6）<a class="link-info" href="https://pytorch.org/vision/stable/utils.html" title="torchvision.utils">torchvision.utils</a></p> <p>提供一些常用的小工具，如TensorBoard</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <p><strong>本节主要讲解torchvision.datasets，以及它如何跟transforms联合使用&nbsp;</strong></p> <h2 id="CIFAR10%E6%95%B0%E6%8D%AE%E9%9B%86"><a name="t53"></a>CIFAR10数据集</h2> <figure class="image">  <img alt="" height="728" src="https://img-blog.csdnimg.cn/fb548bcc22824cd294cc23cdac3d6721.png" width="1200">  <figcaption>   train参数默认为True  </figcaption> </figure> <p>CIFAR10 数据集包含了6万张32×32像素的彩色图片，图片有10个类别，每个类别有6千张图像，其中有5万张图像为训练图片，1万张为测试图片</p> <p><img alt="" height="464" src="https://img-blog.csdnimg.cn/b509064742c349129c892b2534680a47.png" width="500"></p> <h2 id="%E6%A0%87%E5%87%86%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A6%82%E4%BD%95%E4%B8%8B%E8%BD%BD%E3%80%81%E6%9F%A5%E7%9C%8B%E3%80%81%E4%BD%BF%E7%94%A8"><a name="t54"></a>标准数据集如何下载、查看、使用</h2> <pre data-index="71"><code class="language-python hljs"><ol class="hljs-ln" style="width:1354px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#如何使用torchvision提供的标准数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_set=torchvision.datasets.CIFAR10(root=<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">True</span>,download=<span class="hljs-literal">True</span>) <span class="hljs-comment">#root使用相对路径，会在该.py所在位置创建一个叫dataset的文件夹，同时把数据保存进去</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_set=torchvision.datasets.CIFAR10(root=<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">False</span>,download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(test_set[<span class="hljs-number">0</span>])  <span class="hljs-comment"># 查看测试集中的第一个数据，是一个元组：(img, target)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(test_set.classes)  <span class="hljs-comment"># 列表</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img,target = test_set[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(target)  <span class="hljs-comment"># 3</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(test_set.classes[target])  <span class="hljs-comment"># cat</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img.show()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>数据集下载过慢时：</strong></p> <p>获得下载链接后，把下载链接放到迅雷中，会首先下载压缩文件tar.gz，之后会对该压缩文件进行解压，里面会有相应的数据集</p> <p>采用迅雷下载完毕后，在PyCharm里新建directory，名字也叫dataset，再将下载好的压缩包复制进去，download依然为True，运行后，会自动解压该数据</p> <p><strong>没有显示下载地址时：</strong></p> <p>按住Ctrl键，查看数据集的源代码，若其中有 url地址，可直接复制到迅雷中进行下载</p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E5%A6%82%E4%BD%95%E6%8A%8A%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%A4%9A%E5%BC%A0%E5%9B%BE%E7%89%87%EF%BC%89%E5%92%8C%20transforms%20%E7%BB%93%E5%90%88%E5%9C%A8%E4%B8%80%E8%B5%B7"><a name="t55"></a>如何把数据集（多张图片）和 transforms 结合在一起</h2> <p>CIFAR10数据集原始图片是PIL Image，如果要给pytorch使用，需要转为tensor数据类型（转成tensor后，就可以用tensorboard了）</p> <p><span style="color:#fe2c24;"><strong>transforms&nbsp;更多地是用在 datasets 里 transform&nbsp;的选项中</strong></span></p> <pre data-index="72" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1590px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#把dataset_transform运用到数据集中的每一张图片，都转为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset_transform = torchvision.transforms.Compose([</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    torchvision.transforms.ToTensor()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_set=torchvision.datasets.CIFAR10(root=<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">True</span>,transform=dataset_transform,download=<span class="hljs-literal">True</span>) <span class="hljs-comment">#root使用相对路径，会在该.py所在位置创建一个叫dataset的文件夹，同时把数据保存进去</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_set=torchvision.datasets.CIFAR10(root=<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">False</span>,transform=dataset_transform,download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># print(test_set[0])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"p10"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#显示测试数据集中的前10张图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    img,target = test_set[i]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_image(<span class="hljs-string">"test_set"</span>,img,i)  <span class="hljs-comment"># img已经转成了tensor类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后在 terminal 里输入</p> <pre data-index="73"><code class="language-python hljs">tensorboard --logdir=<span class="hljs-string">"p10"</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="435" src="https://img-blog.csdnimg.cn/fd685bbe314c4263a9bd5aca0aaf0995.png" width="350"></p> <hr> <h1 id="11.%20DataLoader%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t56"></a>11. DataLoader 的使用</h1> <ul><li><strong><span style="background-color:#ffd900;">dataset：</span></strong>告诉程序中数据集的位置，数据集中索引，数据集中有多少数据（想象成一叠扑克牌）</li><li><strong><span style="background-color:#ffd900;">dataloader：</span></strong>将数据加载到神经网络中，每次从dataset中取数据，通过dataloader中的参数可以设置如何取数据（想象成抓的一组牌）</li></ul> <p><a href="https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader" title="torch.utils.data — PyTorch 1.10 documentation">torch.utils.data — PyTorch 1.10 documentation</a></p> <h2 id="%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D%C2%A0"><a name="t57"></a>参数介绍&nbsp;</h2> <p>参数如下（大部分有默认值，实际中只需要设置少量的参数即可）：</p> <ul><li><span style="color:#956fe7;"><strong>dataset：</strong></span>只有dataset没有默认值，只需要将之前自定义的dataset实例化，再放到dataloader中即可&nbsp;</li></ul> <p><img alt="" height="1168" src="https://img-blog.csdnimg.cn/e2894b2df838441c87a32ba4cddb03d6.png" width="999"></p> <ul><li><span style="color:#956fe7;"><strong>batch_size：</strong></span>每次抓牌抓几张</li><li><span style="color:#956fe7;"><strong>shuffle：</strong></span>打乱与否，值为True的话两次打牌时牌的顺序是不一样。默认为False，但一般用True</li><li><span style="color:#956fe7;"><strong>num_workers：</strong></span>加载数据时采用单个进程还是多个进程，多进程的话速度相对较快，默认为0（主进程加载）。Windows系统下该值&gt;0会有问题（报错提示：BrokenPipeError）</li><li><span style="color:#956fe7;"><strong>drop_last：</strong></span>100张牌每次取3张，最后会余下1张，这时剩下的这张牌是舍去还是不舍去。值为True代表舍去这张牌、不取出，False代表要取出该张牌</li></ul> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E7%A4%BA%E4%BE%8B%C2%A0"><a name="t58"></a>示例&nbsp;</h2> <pre data-index="74"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 测试数据集中第一张图片及target</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">img,target = test_data[<span class="hljs-number">0</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(img.shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(target)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>输出结果：</strong></p> <pre data-index="75"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>])   <span class="hljs-comment">#三通道，32×32大小</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-number">3</span>   <span class="hljs-comment">#类别为3</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong><span style="color:#ff9900;">dataset&nbsp;</span></strong></p> <ul><li>__getitem()__：return img，target</li></ul> <p><span style="color:#ff9900;"><strong>dataloader(batch_size=4)：</strong></span>从dataset中取4个数据</p> <ul><li>img0，target0 = dataset[0]</li><li>img1，target1 = dataset[1]</li><li>img2，target2 = dataset[2]</li><li>img3，target3 = dataset[3]</li></ul> <p>把 img 0-3 进行打包，记为imgs；target 0-3 进行打包，记为targets；作为dataloader中的返回</p> <pre data-index="76"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(imgs.shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(targets)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>输出结果：</strong></p> <pre data-index="77"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>])   <span class="hljs-comment">#4张图片，三通道，32×32</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor([<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">8</span>])  <span class="hljs-comment">#4个target进行一个打包</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>数据是随机取的（断点debug一下，可以看到采样器sampler是随机采样的），所以两次的 target 0 并不一样</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="batch_size%EF%BC%9A"><a name="t59"></a><strong>batch_size</strong></h3> <pre data-index="78" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:993px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 用上节课torchvision提供的自定义的数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># CIFAR10原本是PIL Image，需要转换成tensor</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备的测试数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载测试集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_loader = DataLoader(dataset=test_data,batch_size=<span class="hljs-number">64</span>,shuffle=<span class="hljs-literal">True</span>,num_workers=<span class="hljs-number">0</span>,drop_last=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#batch_size=4，意味着每次从test_data中取4个数据进行打包</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"dataloader"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">step=<span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data  <span class="hljs-comment">#imgs是tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"test_data"</span>,imgs,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    step=step+<span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后在 terminal 里输入：</p> <pre data-index="79"><code class="language-python hljs"> tensorboard --logdir=<span class="hljs-string">"dataloader"</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果如图，滑动滑块即是每一次取数据时的batch_size张图片：</p> <p><img alt="" height="431" src="https://img-blog.csdnimg.cn/cf4e1d7e268a4459b61548cb5a702f74.png" width="350"></p> <p>由于 drop_last 设置为 False，所以最后16张图片（没有凑齐64张）显示如下：</p> <p><img alt="" height="157" src="https://img-blog.csdnimg.cn/846062f000c44a778a2dbfa4d0b8976e.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="drop_last%EF%BC%9A"><a name="t60"></a>drop_last</h3> <p>若将 drop_last 设置为 True，最后16张图片（step 156）会被舍去，结果如图：</p> <p><img alt="" height="426" src="https://img-blog.csdnimg.cn/4410091b37ea4a7d8644488ecb807cd6.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="shuffle%EF%BC%9A"><a name="t61"></a>shuffle</h3> <p>一个 for data in test_loader 循环，就意味着打完一轮牌（抓完一轮数据），在下一轮再进行抓取时，第二次数据是否与第一次数据一样。值为True的话，会重新洗牌（一般都设置为True）</p> <p>shuffle为False的话两轮取的图片是一样的</p> <p>在外面再套一层 for epoch in range(2) 的循环</p> <pre data-index="80"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># shuffle为True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    step=<span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data  <span class="hljs-comment">#imgs是tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        writer.add_images(<span class="hljs-string">"Epoch:&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(epoch),imgs,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        step=step+<span class="hljs-number">1</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果如下：</strong></p> <p>可以看出两次 step 155 的图片不一样</p> <p><img alt="" height="379" src="https://img-blog.csdnimg.cn/81a22ef7d44b46c3b163952f4d42c60b.png" width="600"></p> <hr> <h1 id="12.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%AA%A8%E6%9E%B6%20-%20nn.Module%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t62"></a>12. 神经网络的基本骨架 - nn.Module 的使用</h1> <p>Pytorch官网左侧：Python API（相当于package，提供了一些不同的工具）</p> <p><strong>关于神经网络的工具主要在torch.nn里&nbsp;</strong></p> <p><a href="https://pytorch.org/docs/stable/nn.html" title="torch.nn — PyTorch 1.10 documentation">torch.nn — PyTorch 1.10 documentation</a></p> <p><img alt="" height="520" src="https://img-blog.csdnimg.cn/f3393a6b83dd44d8b6b3c97e9c13ee51.png" width="400"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Containers"><a name="t63"></a>Containers</h2> <p>包含6个模块：</p> <ul><li>Module</li><li>Sequential</li><li>ModuleList</li><li>ModuleDict</li><li>ParameterList</li><li>ParameterDict</li></ul> <p>其中最常用的是 <strong>Module 模块</strong>（为<span style="color:#fe2c24;"><strong>所有</strong></span>神经网络提供基本骨架）</p> <pre data-index="81"><code class="language-python hljs">CLASS torch.nn.Module  <span class="hljs-comment">#搭建的 Model都必须继承该类</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>模板：&nbsp;</strong></p> <pre data-index="82"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):   <span class="hljs-comment">#搭建的神经网络 Model继承了 Module类（父类）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):   <span class="hljs-comment">#初始化函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Model, self).__init__()   <span class="hljs-comment">#必须要这一步，调用父类的初始化函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv2 = nn.Conv2d(<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):   <span class="hljs-comment">#前向传播（为输入和输出中间的处理过程），x为输入</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = F.relu(self.conv1(x))   <span class="hljs-comment">#conv为卷积，relu为非线性处理</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> F.relu(self.conv2(x))</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <ul><li>前向传播 forward（在所有子类中进行重写）<br><img alt="" height="217" src="https://img-blog.csdnimg.cn/58dcbd298eec4f8bbcfac804334d63f9.png" width="460"></li><li>反向传播 backward</li></ul> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <blockquote>  <p>&nbsp;<img alt="" height="227" src="https://img-blog.csdnimg.cn/bce6c128495f4526b1de05e4f162905e.png" width="350"></p>  <p>Code —&gt; Generate —&gt; Override Methods&nbsp; 可以自动补全代码</p>  <p><img alt="" height="525" src="https://img-blog.csdnimg.cn/ea721bee6e5d4793872ec8f4700c107f.png" width="350"></p> </blockquote> <p>&nbsp;例子：</p> <pre data-index="83" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>().__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># def __init__(self):</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#     super(Tudui, self).__init__()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = <span class="hljs-built_in">input</span> + <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()   <span class="hljs-comment">#拿Tudui模板创建出的神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">x = torch.tensor(<span class="hljs-number">1.0</span>)  <span class="hljs-comment">#将1.0这个数转换成tensor类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果如下：</p> <pre data-index="84"><code class="language-python hljs">tensor(<span class="hljs-number">2.</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h2 id="debug%E7%9C%8B%E6%B5%81%E7%A8%8B%C2%A0"><a name="t64"></a>debug看流程&nbsp;</h2> <p>在下列语句前打断点：</p> <pre data-index="85"><code class="language-python hljs">tudui = Tudui()   <span class="hljs-comment">#整个程序的开始</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>然后点击蜘蛛，点击 Step into My Code，可以看到代码每一步的执行过程</p> <p><img alt="" height="1200" src="https://img-blog.csdnimg.cn/d01f150ad4c440809d4e0d209812bf42.png" width="1200"></p> <hr> <h1 id="13.%20%E5%9C%9F%E5%A0%86%E8%AF%B4%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><a name="t65"></a>13. 土堆说卷积操作</h1> <p><a href="https://pytorch.org/docs/stable/nn.html#convolution-layers" title="torch.nn — PyTorch 1.10 documentation">torch.nn — PyTorch 1.10 documentation</a></p> <p>Convolution Layers&nbsp;</p> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="Conv2d — PyTorch 1.10 documentation">Conv2d — PyTorch 1.10 documentation</a></p> <p>torch.nn 和 torch.nn.functional 的区别：前者是后者的封装，更利于使用</p> <p>点击 torch.nn.functional - Convolution functions - conv2d&nbsp;</p> <p><img alt="" height="416" src="https://img-blog.csdnimg.cn/5f7592f928fb4ecda54ca8bd3c302841.png" width="1193"></p> <h2 id="stride%EF%BC%88%E6%AD%A5%E8%BF%9B%EF%BC%89"><a name="t66"></a><span style="color:#ff9900;"><strong>stride（步进）</strong></span></h2> <p>可以是单个数，或元组（sH,sW） — 控制横向步进和纵向步进</p> <p><img alt="" height="1016" src="https://img-blog.csdnimg.cn/222f0df34411471881ec2ba561ccd6d1.png" width="1200"></p> <p>当 stride = 2 时，横向和纵向都是2，输出是一个2×2的矩阵</p> <p>--------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E8%A6%81%E6%B1%82%E8%BE%93%E5%85%A5%E7%9A%84%E7%BB%B4%E5%BA%A6%C2%A0%26%20reshape%E5%87%BD%E6%95%B0"><a name="t67"></a>要求输入的维度&nbsp;&amp; reshape函数</h2> <p><img alt="" height="91" src="https://img-blog.csdnimg.cn/aab78fafdb3e4c35b49a34f09f66a23a.png" width="753"></p> <ul><li>input：尺寸要求是batch，几个通道，高，宽（4个参数）</li><li>weight：尺寸要求是输出，in_channels（groups一般为1），高，宽（4个参数）</li></ul> <p>使用 torch.reshape 函数，将输入改变为要求输入的维度</p> <p><strong>实现上图的代码：</strong></p> <pre data-index="86" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> =torch.tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                     [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                     [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                     [<span class="hljs-number">5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                     [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]])   <span class="hljs-comment">#将二维矩阵转为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 卷积核kernel</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">kernel = torch.tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                       [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                       [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 尺寸只有高和宽，不符合要求</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)  <span class="hljs-comment">#5×5</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(kernel.shape)  <span class="hljs-comment">#3×3</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 尺寸变换为四个数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))  <span class="hljs-comment">#通道数为1，batch大小为1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">kernel = torch.reshape(kernel,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(kernel.shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = F.conv2d(<span class="hljs-built_in">input</span>,kernel,stride=<span class="hljs-number">1</span>)  <span class="hljs-comment"># .conv2d(input:Tensor, weight:Tensor, stride)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果为：</p> <p><img alt="" height="246" src="https://img-blog.csdnimg.cn/b799a910c6a540cc9cbe45ba69999121.png" width="500"></p> <p><strong>当将步进 stride 改为 2 时：</strong></p> <pre data-index="87"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output2 = F.conv2d(<span class="hljs-built_in">input</span>,kernel,stride=<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output2)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="88" src="https://img-blog.csdnimg.cn/7835117aafa64175aebf0d0d8d478691.png" width="380"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="padding%EF%BC%88%E5%A1%AB%E5%85%85%EF%BC%89"><a name="t68"></a><strong><span style="color:#ff9900;">padding（填充）</span></strong></h2> <p>在输入图像左右两边进行填充，决定填充有多大。可以为一个数或一个元组（分别指定高和宽，即纵向和横向每次填充的大小）。默认情况下不进行填充</p> <p>padding=1：将输入图像左右上下两边都拓展一个像素，空的地方默认为0</p> <p><img alt="" height="839" src="https://img-blog.csdnimg.cn/32d7ac41000a44d8bce3f683263d2d9c.png" width="1200"></p> <p><strong>代码实现：</strong>&nbsp;</p> <pre data-index="88"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output3 = F.conv2d(<span class="hljs-built_in">input</span>,kernel,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output3)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>输出结果如下：可以看出输出尺寸变大&nbsp;</p> <p><img alt="" height="182" src="https://img-blog.csdnimg.cn/e56b3ff8e1ce4890b039b4ff12dfb0bf.png" width="460"></p> <hr> <h1 id="14.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E5%8D%B7%E7%A7%AF%E5%B1%82"><a name="t69"></a>14. 神经网络 - 卷积层</h1> <p><a href="https://pytorch.org/docs/stable/nn.html#convolution-layers" title="torch.nn — PyTorch 1.10 documentation">torch.nn — PyTorch 1.10 documentation</a></p> <p><a href="https://pytorch.org/docs/stable/nn.html#convolution-layers" id="id3" title="Convolution Layers">Convolution Layers</a></p> <div class="table-box"><table><tbody><tr><td> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d" title="nn.Conv1d">nn.Conv1d</a></p> <p>一维卷积</p> </td><td> <p>Applies a 1D convolution over an input signal composed of several input planes.</p> </td></tr><tr><td> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="nn.Conv2d">nn.Conv2d</a></p> <p>二维卷积</p> </td><td> <p>Applies a 2D convolution over an input signal composed of several input planes.</p> </td></tr><tr><td> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d" title="nn.Conv3d">nn.Conv3d</a></p> <p>三维卷积</p> </td><td> <p>Applies a 3D convolution over an input signal composed of several input planes.</p> </td></tr></tbody></table></div> <p><strong>图像为二维矩阵，所以讲解 nn.Conv2d</strong></p> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="Conv2d — PyTorch 1.10 documentation">Conv2d — PyTorch 1.10 documentation</a></p> <p><img alt="" height="416" src="https://img-blog.csdnimg.cn/c59e5f40594447f391bdf07e13ade084.png" width="1183"></p> <pre data-index="89"><code class="language-python hljs"><ol class="hljs-ln" style="width:1440px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">CLASS torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>, padding_mode=<span class="hljs-string">'zeros'</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># in_channels 输入通道数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># out_channels 输出通道数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># kernel_size 卷积核大小 </span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#以上参数需要设置</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment">#以下参数提供了默认值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># stride=1 卷积过程中的步进大小</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># padding=0 卷积过程中对原始图像进行padding的选项</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># dilation=1 每一个卷积核对应位的距离</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># groups=1 一般设置为1，很少改动，改动的话为分组卷积</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># bias=True 通常为True，对卷积后的结果是否加减一个常数的偏置</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># padding_mode='zeros' 选择padding填充的模式</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="478" src="https://img-blog.csdnimg.cn/b4072e35c67a461fa35ad54974255070.png" width="1200">  <figcaption>   dilation 叫空洞卷积  </figcaption> </figure> <p><strong>动图：</strong>&nbsp;</p> <p><a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" title="conv_arithmetic/README.md at master · vdumoulin/conv_arithmetic · GitHub">conv_arithmetic/README.md at master · vdumoulin/conv_arithmetic · GitHub</a></p> <p><img alt="" height="804" src="https://img-blog.csdnimg.cn/37699c115957407ca751e233c2bab753.png" width="1200"></p> <h2 id="kernel_size"><a name="t70"></a><span style="color:#ff9900;"><strong>kernel_size</strong></span></h2> <p>定义了一个卷积核的大小，若为3则生成一个3×3的卷积核</p> <ul><li>卷积核的参数是从一些分布中进行采样得到的</li><li>实际训练过程中，卷积核中的值会不断进行调整</li></ul> <h2 id="in_channels%20%26%20out_channels"><a name="t71"></a><span style="color:#ff9900;">in_channels &amp; out_channels</span></h2> <ul><li>in_channels：输入图片的channel数<span style="color:#fe2c24;"><strong>（彩色图像 in_channels 值为3）</strong></span></li><li>out_channels：输出图片的channel数</li></ul> <p>in_channels 和&nbsp;<span style="color:#956fe7;">out_channels 都为 1</span> 时，拿<span style="color:#956fe7;">一个卷积核</span>在输入图像中进行卷积</p> <p><span style="color:#956fe7;">out_channels 为 2 时，</span>卷积层会生成<span style="color:#956fe7;">两个卷积核</span>（不一定一样），得到两个输出，叠加后作为最后输出</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="CIFAR10%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AE%9E%E4%BE%8B%C2%A0"><a name="t72"></a>CIFAR10数据集实例&nbsp;</h2> <pre data-index="90" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1377px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># CIFAR10数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># 这里用测试数据集，因为训练数据集太大了</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络Tudui</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 因为是彩色图片，所以in_channels=3</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv1 = Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">6</span>,kernel_size=<span class="hljs-number">3</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">0</span>)   <span class="hljs-comment">#卷积层conv1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):  <span class="hljs-comment">#输出为x</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()  <span class="hljs-comment"># 初始化网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 打印一下网络结构</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(tudui)   <span class="hljs-comment">#Tudui((conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1)))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">step = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data  <span class="hljs-comment">#经过ToTensor转换，成为tensor数据类型，可以直接送到网络中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(imgs.shape)     <span class="hljs-comment">#输入大小 torch.Size([64, 3, 32, 32])  batch_size=64，in_channels=3（彩色图像），每张图片是32×32的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)   <span class="hljs-comment">#经过卷积后的输出大小 torch.Size([64, 6, 30, 30])  卷积后变成6个channels，但原始图像减小，所以是30×30的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"input"</span>,imgs,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 6个channel无法显示。torch.Size([64, 6, 30, 30]) ——&gt; [xxx,3,30,30] 第一个值不知道为多少时写-1，会根据后面值的大小进行计算</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = torch.reshape(output,(-<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">30</span>,<span class="hljs-number">30</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"output"</span>,output,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    step = step + <span class="hljs-number">1</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后，在 Terminal 里启动 pytorch 环境：</p> <pre data-index="91"><code class="hljs language-undefined">conda activate pytorch</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>打开 tensorboard：</p> <pre data-index="92"><code class="hljs language-sql">tensorboard <span class="hljs-comment">--logdir=logs</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>打开网址 http://localhost:6006/：</p> <p><img alt="" height="793" src="https://img-blog.csdnimg.cn/612b0fd9a90f4f7bad705d8ab40ee1f1.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%8D%B7%E7%A7%AF%E5%B1%82%20vgg16"><a name="t73"></a>卷积层 vgg16</h2> <p><img alt="" height="901" src="https://img-blog.csdnimg.cn/59c63cf67b324b2e8a9e0fb76d217d96.png" width="1153"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%8D%B7%E7%A7%AF%E5%89%8D%E5%90%8E%E7%BB%B4%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><a name="t74"></a>卷积前后维度计算公式</h2> <p><img alt="" height="378" src="https://img-blog.csdnimg.cn/dd1af3cc16b74b6395c50034330c0ebe.png" width="1043"></p> <hr> <h1 id="15.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t75"></a>15. 神经网络 - 最大池化的使用</h1> <p><a href="https://pytorch.org/docs/stable/nn.html#pooling-layers" title="torch.nn — PyTorch 1.10 documentation">torch.nn — PyTorch 1.10 documentation</a></p> <p><a href="https://pytorch.org/docs/stable/nn.html#pooling-layers" id="id4" title="Pooling layers">Pooling layers</a></p> <ul><li>MaxPool：最大池化（下采样）</li><li>MaxUnpool：上采样</li><li>AvgPool：平均池化</li><li>AdaptiveMaxPool2d：自适应最大池化</li></ul> <p>最常用：<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" title="MaxPool2d — PyTorch 1.10 documentation">MaxPool2d — PyTorch 1.10 documentation</a></p> <h2 id="%E5%8F%82%E6%95%B0%C2%A0"><a name="t76"></a>参数&nbsp;</h2> <pre data-index="93"><code class="language-python hljs"><ol class="hljs-ln" style="width:1018px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">CLASS torch.nn.MaxPool2d(kernel_size, stride=<span class="hljs-literal">None</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, return_indices=<span class="hljs-literal">False</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># kernel_size 池化核</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="415" src="https://img-blog.csdnimg.cn/e85a9de5d0784a6ea6e454592199b49c.png" width="1182"></p> <blockquote>  <p>注意，<strong>卷积中stride默认为1，而池化中stride默认为kernel_size&nbsp;</strong></p> </blockquote> <p><img alt="" height="252" src="https://img-blog.csdnimg.cn/17e28e5fb36c41ef9b0ab3c5a79c13ec.png" width="350"></p> <p>--------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E5%8F%82%E6%95%B0%E5%8F%8A%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><a name="t77"></a>ceil_mode参数</h2> <p><img alt="" height="757" src="https://img-blog.csdnimg.cn/f21bf6b230134ccf9030879c273bd180.png" width="1200"></p> <p><span style="color:#fe2c24;"><strong>Ceil_mode 默认情况下为 False，对于最大池化一般只需设置 kernel_size 即可&nbsp;</strong></span></p> <p>--------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%BB%B4%E5%BA%A6%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><a name="t78"></a>输入输出维度计算公式</h2> <p><img alt="" height="382" src="https://img-blog.csdnimg.cn/2f5cc66b411c4bfea74c4b4a0a2e675c.png" width="1042"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%C2%A0"><a name="t79"></a>代码实现&nbsp;</h2> <p><span style="color:#fe2c24;"><strong>要求的 input 必须是四维的，参数依次是：batch_size、channel、高、宽&nbsp;</strong></span></p> <p><strong>上述图用代码实现：</strong>（以 Ceil_mode = True 为例）</p> <pre data-index="94" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1062px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> MaxPool2d</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                      [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                      [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                      [<span class="hljs-number">5</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                      [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>]],dtype=torch.float32)  <span class="hljs-comment">#最大池化无法对long数据类型进行实现,将input变成浮点数的tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>,(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))  <span class="hljs-comment">#-1表示torch计算batch_size</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>,ceil_mode=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = self.maxpool1(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果如下：</p> <p>&nbsp;<img alt="" height="84" src="https://img-blog.csdnimg.cn/3b2570c082c643d3bb199732a6f04251.png" width="350"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%EF%BC%9F%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><a name="t80"></a>为什么要进行最大池化？最大池化的作用是什么？</h2> <p>最大池化的目的是<span style="color:#956fe7;"><strong>保留输入的特征，同时把数据量减小</strong></span>（数据维度变小），对于整个网络来说，<strong><span style="color:#956fe7;">进行计算的参数变少，会训练地更快</span></strong></p> <ul><li>如上面案例中输入是5x5的，但输出是3x3的，甚至可以是1x1的</li><li><strong>类比：</strong>1080p的视频为输入图像，经过池化可以得到720p，也能满足绝大多数需求，传达视频内容的同时，文件尺寸会大大缩小</li></ul> <p><span style="color:#956fe7;"><strong>池化一般跟在卷积后</strong></span>，卷积层是用来提取特征的，一般有相应特征的位置是比较大的数字，最大池化可以提取出这一部分有相应特征的信息</p> <p>池化不影响通道数</p> <p><span style="color:#956fe7;"><strong>池化后一般再进行非线性激活</strong></span></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E7%94%A8%E6%95%B0%E6%8D%AE%E9%9B%86%20CIFAR10%20%E5%AE%9E%E7%8E%B0%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96"><a name="t81"></a><strong>用数据集 CIFAR10 实现最大池化</strong></h2> <pre data-index="95" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1285px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> MaxPool2d</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,download=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>,ceil_mode=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = self.maxpool1(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_maxpool"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">step = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"input"</span>,imgs,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(imgs)  <span class="hljs-comment">#output尺寸池化后不会有多个channel，原来是3维的图片，经过最大池化后还是3维的，不需要像卷积一样还要reshape操作（影响通道数的是卷积核个数）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"output"</span>,output,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    step = step + <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后在 terminal 里输入（注意是在pytorch环境下）：</p> <pre data-index="96"><code class="language-python hljs">tensorboard --logdir=logs_maxpool</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>打开网址：</p> <p><img alt="" height="790" src="https://img-blog.csdnimg.cn/892cb0c166174d309828c4e07263c8cf.png" width="300"></p> <hr> <h1 id="16.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB%C2%A0"><a name="t82"></a>16. 神经网络 - 非线性激活&nbsp;</h1> <ul><li> <p><a href="https://pytorch.org/docs/stable/nn.html#padding-layers" id="id5" title="Padding Layers">Padding Layers</a>（对输入图像进行填充的各种方式）<br> 几乎用不到，nn.ZeroPad2d（在输入tensor数据类型周围用0填充）<br> nn.ConstantPad2d（用常数填充）<br> 在 Conv2d 中可以实现，故不常用</p> </li><li> <p><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity" id="id6" title="Non-linear Activations (weighted sum, nonlinearity)">Non-linear Activations (weighted sum, nonlinearity)</a></p> </li><li> <p><a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-other" id="id7" title="Non-linear Activations (other)">Non-linear Activations (other)</a></p> </li></ul> <p><span style="color:#fe2c24;"><strong>非线性激活：</strong></span>给神经网络引入一些非线性的特征</p> <p>非线性越多，才能训练出符合各种曲线或特征的模型<strong><span style="color:#fe2c24;">（提高泛化能力）</span></strong></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E6%9C%80%E5%B8%B8%E8%A7%81%EF%BC%9ARELU%C2%A0%20%C2%A0"><a name="t83"></a>最常见：RELU&nbsp; &nbsp;</h2> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" title="ReLU — PyTorch 1.10 documentation">ReLU — PyTorch 1.10 documentation</a></p> <p><img alt="" height="388" src="https://img-blog.csdnimg.cn/43d6f1c1581043829b409c7b61d73bc4.png" width="500"></p> <p>输入：(N,*)&nbsp; &nbsp; N 为 batch_size，*不限制</p> <h3 id="%E4%BB%A3%E7%A0%81%E4%B8%BE%E4%BE%8B%EF%BC%9ARELU"><a name="t84"></a>代码举例：RELU</h3> <pre data-index="97" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> ReLU</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>,-<span class="hljs-number">0.5</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                      [-<span class="hljs-number">1</span>,<span class="hljs-number">3</span>]])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>,(-<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>))  <span class="hljs-comment">#input必须要指定batch_size，-1表示batch_size自己算，1表示是1维的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>.shape)   <span class="hljs-comment">#torch.Size([1, 1, 2, 2])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.relu1 = ReLU()  <span class="hljs-comment">#inplace默认为False</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = self.relu1(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <p><img alt="" height="94" src="https://img-blog.csdnimg.cn/51b62bedd69f4f73a64f9552c1384b3e.png" width="250"></p> <p>跟输入对比可以看到：小于0的值被0截断，大于0的值仍然保留</p> <p><img alt="" height="100" src="https://img-blog.csdnimg.cn/f53c44c255fa46a88ac799a07f785c3e.png" width="219"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="Sigmoid"><a name="t85"></a>Sigmoid</h2> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid" title="Sigmoid — PyTorch 1.10 documentation">Sigmoid — PyTorch 1.10 documentation</a></p> <p><img alt="" height="69" src="https://img-blog.csdnimg.cn/f42fffd3560b4765885e744b76015a8d.png" width="400"></p> <p><img alt="" height="382" src="https://img-blog.csdnimg.cn/18530f16e5314e589a2c4842cb730b62.png" width="500"></p> <p>&nbsp;输入：(N,*)&nbsp; &nbsp; N 为 batch_size，*不限制</p> <h3 id="%E4%BB%A3%E7%A0%81%E4%B8%BE%E4%BE%8B%EF%BC%9ASigmoid%EF%BC%88%E6%95%B0%E6%8D%AE%E9%9B%86CIFAR10%EF%BC%89"><a name="t86"></a>代码举例：Sigmoid（数据集CIFAR10）</h3> <pre data-index="98" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1077px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Sigmoid</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,download=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.sigmoid1 = Sigmoid()  <span class="hljs-comment">#inplace默认为False</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = self.sigmoid1(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_sigmoid"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">step = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"input"</span>,imgs,global_step=step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_images(<span class="hljs-string">"output"</span>,output,step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    step = step + <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后在 terminal 里输入：</p> <pre data-index="99"><code class="hljs language-sql">tensorboard <span class="hljs-comment">--logdir=logs_sigmoid</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>打开网址：</p> <p><img alt="" height="777" src="https://img-blog.csdnimg.cn/41f52662cc11476f8a11a9c260d69ac4.png" width="300"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E5%85%B3%E4%BA%8Einplace"><a name="t87"></a>关于inplace</h2> <p><img alt="" height="509" src="https://img-blog.csdnimg.cn/38d3d0db9c1c44c9a1acf72e4e8d2b8d.png" width="1200"></p> <hr> <h1 id="17.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E7%BA%BF%E6%80%A7%E5%B1%82%E5%8F%8A%E5%85%B6%E4%BB%96%E5%B1%82%E4%BB%8B%E7%BB%8D%C2%A0"><a name="t88"></a>17. 神经网络 - 线性层及其他层介绍&nbsp;</h1> <h2 id="%E6%AD%A3%E5%88%99%E5%8C%96%E5%B1%82%C2%A0%C2%A0%C2%A0"><a name="t89"></a>批标准化层（不难，自学）&nbsp; &nbsp;</h2> <p><a href="https://pytorch.org/docs/stable/nn.html#normalization-layers" id="id8" title="Normalization Layers">Normalization Layers</a></p> <p><a href="https://pytorch.org/docs/stable/nn.html#normalization-layers" title="torch.nn — PyTorch 1.10 documentation">torch.nn — PyTorch 1.10 documentation</a></p> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" title="BatchNorm2d — PyTorch 1.10 documentation">BatchNorm2d — PyTorch 1.10 documentation</a></p> <p>对输入采用Batch Normalization，可以加快神经网络的训练速度</p> <pre data-index="100"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:1161px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">CLASS</span> torch.nn.BatchNorm<span class="hljs-number">2</span>d(num_features, eps<span class="hljs-operator">=</span><span class="hljs-number">1</span>e-<span class="hljs-number">05</span>, momentum<span class="hljs-operator">=</span><span class="hljs-number">0.1</span>, affine<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>, track_running_stats<span class="hljs-operator">=</span><span class="hljs-keyword">True</span>, device<span class="hljs-operator">=</span>None, dtype<span class="hljs-operator">=</span>None)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"># num_features C-输入的channel</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <pre data-index="101"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># With Learnable Parameters</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">m = nn.BatchNorm2d(<span class="hljs-number">100</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Without Learnable Parameters</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">m = nn.BatchNorm2d(<span class="hljs-number">100</span>, affine=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 正则化层num_feature等于channel，即100</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">35</span>, <span class="hljs-number">45</span>)   <span class="hljs-comment">#batch_size=20,100个channel,35x45的输入</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = m(<span class="hljs-built_in">input</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Recurrent%20Layers%EF%BC%88%E7%89%B9%E5%AE%9A%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%EF%BC%8C%E8%87%AA%E5%AD%A6%EF%BC%89"><a name="t90"></a>Recurrent Layers（特定网络中使用，自学）</h2> <p>RNN、LSTM等，用于文字识别中，特定的网络结构</p> <p><a href="https://pytorch.org/docs/stable/nn.html#recurrent-layers" title="torch.nn — PyTorch 1.13 documentation">torch.nn — PyTorch 1.13 documentation</a></p> <p><img alt="" height="901" src="https://img-blog.csdnimg.cn/5f0a1c4fbb154e6c84526c2b22fcf245.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Transformer%20Layers%EF%BC%88%E7%89%B9%E5%AE%9A%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%EF%BC%8C%E8%87%AA%E5%AD%A6%EF%BC%89"><a name="t91"></a>Transformer Layers（特定网络中使用，自学）</h2> <p>特定网络结构</p> <p><a href="https://pytorch.org/docs/stable/nn.html#transformer-layers" title="torch.nn — PyTorch 1.13 documentation">torch.nn — PyTorch 1.13 documentation</a></p> <p><img alt="" height="639" src="https://img-blog.csdnimg.cn/c201e1fc1eca4570905dd48375c13a81.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Linear%20Layers%EF%BC%88%E6%9C%AC%E8%8A%82%E8%AE%B2%E8%A7%A3%EF%BC%89"><a name="t92"></a><span style="color:#ff9900;">Linear Layers（本节讲解）</span></h2> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" title="Linear — PyTorch 1.10 documentation">Linear — PyTorch 1.10 documentation</a></p> <figure class="image">  <img alt="" height="1139" src="https://img-blog.csdnimg.cn/1dab54bcc3bc443ca86af98353ceb2ce.png" width="1200">  <figcaption>   d代表特征数，L代表神经元个数&nbsp; &nbsp; &nbsp;K和b在训练过程中神经网络会自行调整，以达到比较合理的预测  </figcaption> </figure> <p></p> <p><img alt="" height="198" src="https://img-blog.csdnimg.cn/dd2dd582a23d48abbe47cee24b4a4048.png" width="816"></p> <p><img alt="" height="256" src="https://img-blog.csdnimg.cn/544ee39657b941febe016bc14b6060be.png" width="1096"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B"><a name="t93"></a>代码实例</h3> <p id="%E7%BA%BF%E6%80%A7%E5%B1%82"><strong>vgg16 model</strong></p> <p><img alt="" height="786" src="https://img-blog.csdnimg.cn/8b097a37b0f64a0da4d81b5fa5f7015a.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E2%80%8Bflatten"><a name="t94"></a>flatten 摊平</h3> <p><a href="https://pytorch.org/docs/stable/generated/torch.flatten.html?highlight=flatten#torch.flatten" title="torch.flatten — PyTorch 1.10 documentation">torch.flatten — PyTorch 1.10 documentation</a></p> <pre data-index="102"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Example</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-meta">&gt;&gt;&gt; </span>t = torch.tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                   [<span class="hljs-number">3</span>, <span class="hljs-number">4</span>]],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                  [[<span class="hljs-number">5</span>, <span class="hljs-number">6</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                   [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]])   <span class="hljs-comment">#3个中括号，所以是3维的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-meta">&gt;&gt;&gt; </span>torch.flatten(t)  <span class="hljs-comment">#摊平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-meta">&gt;&gt;&gt; </span>torch.flatten(t, start_dim=<span class="hljs-number">1</span>)  <span class="hljs-comment">#变为1行</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]])</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <ul><li>reshape()：可以指定尺寸进行变换</li><li>flatten()：变成1行，摊平</li></ul> <pre data-index="103" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = torch.flatten(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 等价于</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = torch.reshape(imgs,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(imgs.shape)  <span class="hljs-comment">#torch.Size([64, 3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = torch.reshape(imgs,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,-<span class="hljs-number">1</span>))  <span class="hljs-comment"># 想把图片展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># torch.Size([1, 1, 1, 196608])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># torch.Size([1, 1, 1, 10])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(imgs.shape)  <span class="hljs-comment">#torch.Size([64, 3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = torch.flatten(imgs)   <span class="hljs-comment">#摊平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)   <span class="hljs-comment">#torch.Size([196608])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)   <span class="hljs-comment">#torch.Size([10])</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;--------------------------------------------------------------------------------------------------------------------------------</p> <p><img alt="" height="410" src="https://img-blog.csdnimg.cn/c99cd40ada1e48578bd6be7f66bc974a.png" width="1200"></p> <pre data-index="104" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1077px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Linear</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">64</span>,drop_last=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.linear1 = Linear(<span class="hljs-number">196608</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,<span class="hljs-built_in">input</span></span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        output = self.linear1(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> output</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(imgs.shape)  <span class="hljs-comment">#torch.Size([64, 3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># output = torch.reshape(imgs,(1,1,1,-1))  # 想把图片展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(output.shape)  # torch.Size([1, 1, 1, 196608])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># output = tudui(output)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(output.shape)  # torch.Size([1, 1, 1, 10])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = torch.flatten(imgs)   <span class="hljs-comment">#摊平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)   <span class="hljs-comment">#torch.Size([196608])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)   <span class="hljs-comment">#torch.Size([10])</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;运行结果如下：</p> <p><img alt="" height="250" src="https://img-blog.csdnimg.cn/a6dc40e899b7418eae5ed591fc8f89b4.png" width="300"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Dropout%20Layers%EF%BC%88%E8%87%AA%E5%AD%A6%EF%BC%89"><a name="t95"></a>Dropout Layers（不难，自学）</h2> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" title="Dropout — PyTorch 1.10 documentation">Dropout — PyTorch 1.10 documentation</a></p> <p>在训练过程中，随机把一些 input（输入的tensor数据类型）中的一些元素变为0，变为0的概率为p</p> <p>目的：防止过拟合</p> <p><img alt="" height="1100" src="https://img-blog.csdnimg.cn/c411fdd52a2345f29e910d4eb2220891.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Sparse%20Layers%EF%BC%88%E7%89%B9%E5%AE%9A%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%EF%BC%8C%E8%87%AA%E5%AD%A6%EF%BC%89"><a name="t96"></a>Sparse Layers（特定网络中使用，自学）</h2> <h3 id="Embedding"><a name="t97"></a>Embedding</h3> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" title="Embedding — PyTorch 1.10 documentation">Embedding — PyTorch 1.10 documentation</a></p> <p>用于自然语言处理&nbsp;</p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="Distance%20Functions"><a name="t98"></a>Distance Functions</h2> <p>计算两个值之间的误差</p> <p><a href="https://pytorch.org/docs/stable/nn.html#distance-functions" title="torch.nn — PyTorch 1.13 documentation">torch.nn — PyTorch 1.13 documentation</a></p> <p><img alt="" height="322" src="https://img-blog.csdnimg.cn/e7a7c754d04544d99b30e7a76614c2fa.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="Loss%20Functions"><a name="t99"></a>Loss Functions</h2> <p>loss 误差大小</p> <p><a href="https://pytorch.org/docs/stable/nn.html#loss-functions" title="torch.nn — PyTorch 1.13 documentation">torch.nn — PyTorch 1.13 documentation</a></p> <p><img alt="" height="1200" src="https://img-blog.csdnimg.cn/92235e61f533425b81f7815a343e456a.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="pytorch%E6%8F%90%E4%BE%9B%E7%9A%84%E4%B8%80%E4%BA%9B%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><a name="t100"></a>pytorch提供的一些网络模型</h2> <ul><li><strong><span style="color:#ff9900;">图片相关：torchvision</span></strong>&nbsp; &nbsp;<a href="https://pytorch.org/vision/stable/models.html" title="torchvision.models — Torchvision 0.11.0 documentation">torchvision.models — Torchvision 0.11.0 documentation</a><br> 分类、语义分割、目标检测、实例分割、人体关键节点识别（姿态估计）等等</li><li><span style="color:#ff9900;"><strong>文本相关：torchtext</strong></span>&nbsp; &nbsp;无</li><li><span style="color:#ff9900;"><strong>语音相关：torchaudio</strong></span>&nbsp;&nbsp;<a href="https://pytorch.org/audio/stable/models.html" title="torchaudio.models — Torchaudio 0.10.0 documentation">torchaudio.models — Torchaudio 0.10.0 documentation</a></li></ul> <p>下一节：Container ——&gt; Sequential（序列）</p> <hr> <h1 id="18.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%20-%20%E6%90%AD%E5%BB%BA%E5%B0%8F%E5%AE%9E%E6%88%98%E5%92%8C%20Sequential%20%E7%9A%84%E4%BD%BF%E7%94%A8"><a name="t101"></a>18. 神经网络 - 搭建小实战和 Sequential 的使用</h1> <p>Containers中有Module、Sequential等&nbsp;</p> <p><a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential" title="Sequential — PyTorch 1.10 documentation">Sequential — PyTorch 1.10 documentation</a></p> <p>Example：</p> <pre data-index="105" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Using Sequential to create a small model. When `model` is run,</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># input will first be passed to `Conv2d(1,20,5)`. The output of</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># `Conv2d(1,20,5)` will be used as the input to the first</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># `ReLU`; the output of the first `ReLU` will become the input</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># for `Conv2d(20,64,5)`. Finally, the output of</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># `Conv2d(20,64,5)` will be used as input to the second `ReLU`</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          nn.ReLU(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          nn.ReLU()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Using Sequential with OrderedDict. This is functionally the</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># same as the above code</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = nn.Sequential(OrderedDict([</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          (<span class="hljs-string">'conv1'</span>, nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>)),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          (<span class="hljs-string">'relu1'</span>, nn.ReLU()),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          (<span class="hljs-string">'conv2'</span>, nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>)),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">          (<span class="hljs-string">'relu2'</span>, nn.ReLU())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        ]))</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>好处：代码简洁易懂</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%AF%B9%20CIFAR10%20%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%E7%9A%84%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><a name="t102"></a>对 CIFAR10 进行分类的简单神经网络</h2> <p>CIFAR 10：根据图片内容，识别其究竟属于哪一类（10代表有10个类别）</p> <p><a href="https://www.cs.toronto.edu/~kriz/cifar.html" title="CIFAR-10 and CIFAR-100 datasets">CIFAR-10 and CIFAR-100 datasets</a></p> <p><img alt="" height="559" src="https://img-blog.csdnimg.cn/17332f27d1944e74a0d3a851317f05ce.png" width="1200"></p> <p>第一次卷积：首先加了几圈 padding（图像大小不变，还是32x32），然后卷积了32次</p> <ul><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" title="Conv2d — PyTorch 1.10 documentation">Conv2d — PyTorch 1.10 documentation</a></li><li>输入尺寸是32x32，经过卷积后尺寸不变，如何设置参数？&nbsp; —— padding=2，stride=1</li><li>计算公式：<img alt="" height="365" src="https://img-blog.csdnimg.cn/4e7d6db8f15d4cce92bebd0272701d12.png" width="1110"></li></ul> <p>几个卷积核就是几通道的，一个卷积核作用于RGB三个通道后会把得到的三个矩阵的对应值相加，也就是说会合并，所以一个卷积核会产生一个通道</p> <p>任何卷积核在设置padding的时候为保持输出尺寸不变都是卷积核大小的一半</p> <p>通道变化时通过调整卷积核的个数（即输出通道）来实现的，在 nn.conv2d 的参数中有 out_channel 这个参数，就是对应输出通道</p> <p>kernel 的内容是不一样的，可以理解为不同的特征抓取，因此一个核会产生一个channel</p> <h3 id="%E7%9B%B4%E6%8E%A5%E6%90%AD%E5%BB%BA%EF%BC%8C%E5%AE%9E%E7%8E%B0%E4%B8%8A%E5%9B%BE%20CIFAR10%20model%20%E7%9A%84%E4%BB%A3%E7%A0%81"><a name="t103"></a><strong>直接搭建，实现上图 CIFAR10 model 的代码</strong></h3> <pre data-index="106" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1053px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv1 = Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)  <span class="hljs-comment">#第一个卷积</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">2</span>)   <span class="hljs-comment">#池化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv2 = Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>)  <span class="hljs-comment">#维持尺寸不变，所以padding仍为2</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool2 = MaxPool2d(<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv3 = Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool3 = MaxPool2d(<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.flatten = Flatten()  <span class="hljs-comment">#展平为64x4x4=1024个数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 经过两个线性层：第一个线性层（1024为in_features，64为out_features)、第二个线性层（64为in_features，10为out_features)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.linear1 = Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.linear2 = Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)  <span class="hljs-comment">#10为10个类别，若预测的是概率，则取最大概率对应的类别，为该图片网络预测到的类别</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment">#x为input</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv2(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool2(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv3(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool3(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.flatten(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.linear1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.linear2(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(tudui)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>可以看到网络结构：</strong></p> <p><img alt="" height="524" src="https://img-blog.csdnimg.cn/cd673feac3db48929ecbe5f63cbccd15.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E5%AE%9E%E9%99%85%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%A6%82%E4%BD%95%E6%A3%80%E6%9F%A5%E7%BD%91%E7%BB%9C%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%80%A7%EF%BC%9F"><a name="t104"></a>实际过程中如何检查网络的正确性？</h3> <p>核心：一定尺寸的数据经过网络后，能够得到我们想要的输出</p> <p><span style="color:#fe2c24;"><strong>对网络结构进行检验的代码：&nbsp;</strong></span></p> <pre data-index="107"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))  <span class="hljs-comment">#全是1，batch_size=64,3通道，32x32</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output.shape)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <pre data-index="108"><code class="language-python hljs">torch.Size([<span class="hljs-number">64</span>, <span class="hljs-number">10</span>])</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E8%8B%A5%E4%B8%8D%E7%9F%A5%E9%81%93flatten%E4%B9%8B%E5%90%8E%E7%9A%84%E7%BB%B4%E5%BA%A6%E6%98%AF%E5%A4%9A%E5%B0%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F"><a name="t105"></a>若不知道flatten之后的维度是多少该怎么办？</h3> <pre data-index="109" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1053px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv1 = Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)  <span class="hljs-comment">#第一个卷积</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">2</span>)   <span class="hljs-comment">#池化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv2 = Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>)  <span class="hljs-comment">#维持尺寸不变，所以padding仍为2</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool2 = MaxPool2d(<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv3 = Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.maxpool3 = MaxPool2d(<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.flatten = Flatten()  <span class="hljs-comment">#展平为64x4x4=1024个数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 经过两个线性层：第一个线性层（1024为in_features，64为out_features)、第二个线性层（64为in_features，10为out_features)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.linear1 = Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.linear2 = Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)  <span class="hljs-comment">#10为10个类别，若预测的是概率，则取最大概率对应的类别，为该图片网络预测到的类别</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment">#x为input</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv2(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool2(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv3(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.maxpool3(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.flatten(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(tudui)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))  <span class="hljs-comment">#全是1，batch_size=64（64张图片）,3通道，32x32</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output.shape)  <span class="hljs-comment"># torch.Size([64,1024])</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;看到输出的维度是(64,1024)，64可以理解为64张图片，1024就是flatten之后的维度了</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="Sequential"><a name="t106"></a>用 Sequential&nbsp;<strong>搭建，实现上图 CIFAR10 model 的代码</strong></h3> <p>作用：<span style="color:#fe2c24;"><strong>代码更加简洁</strong></span></p> <pre data-index="110" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model1 = Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Flatten(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment">#x为input</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(tudui)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))  <span class="hljs-comment">#全是1，batch_size=64,3通道，32x32</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output.shape)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>运行结果：</strong></p> <p><img alt="" height="641" src="https://img-blog.csdnimg.cn/de49f7fb0ddf4b2aa28f6e14bf18b0a9.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E5%BC%95%E5%85%A5%20tensorboard%20%E5%8F%AF%E8%A7%86%E5%8C%96%EF%BC%9A"><a name="t107"></a>引入 tensorboard 可视化模型结构</h3> <p>在上述代码后面加上以下代码：</p> <pre data-index="111"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_seq"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.add_graph(tudui,<span class="hljs-built_in">input</span>)   <span class="hljs-comment"># add_graph 计算图</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后在 terminal 里输入：</p> <pre data-index="112"><code class="language-python hljs"> tensorboard --logdir=logs_seq</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;打开网址，双击图片中的矩形，可以放大每个部分：</p> <p><img alt="" height="632" src="https://img-blog.csdnimg.cn/608cde1502ec4cd487f8f2901f428d6a.png" width="500"></p> <hr> <h1 id="19.%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><a name="t108"></a>19. 损失函数与反向传播</h1> <p>torch.nn 里的 loss function 衡量误差，在使用过程中根据需求使用，注意输入形状和输出形状即可</p> <p>loss 衡量实际神经网络输出 output 与真实想要结果 target 的差距，<strong>越小越好</strong></p> <p><strong>作用：</strong></p> <ul><li><span style="color:#956fe7;">计算实际输出和目标之间的差距</span></li><li><span style="color:#956fe7;">为我们更新输出提供一定的依据（反向传播）</span>：给每一个卷积核中的参数提供了梯度 grad，采用反向传播时，每一个要更新的参数都会计算出对应的梯度，优化过程中根据梯度对参数进行优化，最终达到整个 loss 进行降低的目的</li></ul> <p><strong>梯度下降法：</strong></p> <p><img alt="" height="216" src="https://img-blog.csdnimg.cn/8e762f4f0d844c96931de506637b2074.png" width="400"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="L1LOSS"><a name="t109"></a>L1LOSS</h2> <p><img alt="" height="622" src="https://img-blog.csdnimg.cn/f8a14f6c1d7049e4a55ac36ee7b07fdd.png" width="1163"></p> <p>input：(N,*)&nbsp; &nbsp; N是batch_size，即有多少个数据；*可以是任意维度&nbsp;</p> <pre data-index="113"><code class="language-python hljs">CLASS torch.nn.L1Loss(size_average=<span class="hljs-literal">None</span>, reduce=<span class="hljs-literal">None</span>, reduction=<span class="hljs-string">'mean'</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h3 id="%E4%BB%A3%E7%A0%81"><a name="t110"></a><strong>代码</strong></h3> <ul><li><strong><span style="color:#ff9900;">取平均的方式：&nbsp;</span></strong></li></ul> <pre data-index="114"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> L1Loss</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 实际数据或网络默认情况下就是float类型，不写测试案例的话一般不需要加dtype</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">inputs = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],dtype=torch.float32)   <span class="hljs-comment"># 计算时要求数据类型为浮点数，不能是整型的long</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">targets = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>],dtype=torch.float32)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">inputs = torch.reshape(inputs,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))   <span class="hljs-comment"># 1 batch_size, 1 channel, 1行3列</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">targets = torch.reshape(targets,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss = L1Loss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">result = loss(inputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(result)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <pre data-index="115"><code class="language-python hljs">tensor(<span class="hljs-number">0.6667</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <ul><li><span style="color:#ff9900;"><strong>求和的方式：</strong></span></li></ul> <p>修改上述代码中的一句即可</p> <pre data-index="116"><code class="language-python hljs">loss = L1Loss(reduction=<span class="hljs-string">'sum'</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <pre data-index="117"><code class="hljs language-scss"><span class="hljs-built_in">tensor</span>(<span class="hljs-number">2</span>.)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="MSELOSS"><a name="t111"></a>MSELOSS（均方误差）</h2> <p>input：(N,*)&nbsp; &nbsp; N是batch_size，即有多少个数据；*可以是任意维度&nbsp;</p> <pre data-index="118"><code class="language-python hljs">CLASS torch.nn.MSELoss(size_average=<span class="hljs-literal">None</span>, reduce=<span class="hljs-literal">None</span>, reduction=<span class="hljs-string">'mean'</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="605" src="https://img-blog.csdnimg.cn/832d3c7f3e904c3fa7443e896524685d.png" width="1195"></p> <h3><a name="t112"></a><strong>代码</strong></h3> <pre data-index="119"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 实际数据或网络默认情况下就是float类型，不写测试案例的话一般不需要加dtype</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">inputs = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],dtype=torch.float32)   <span class="hljs-comment"># 计算时要求数据类型为浮点数，不能是整型的long</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">targets = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>],dtype=torch.float32)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">inputs = torch.reshape(inputs,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))   <span class="hljs-comment"># 1 batch_size, 1 channel, 1行3列</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">targets = torch.reshape(targets,(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_mse = nn.MSELoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">result_mse = loss_mse(inputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(result_mse)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果：</strong></p> <pre data-index="120"><code class="language-python hljs">tensor(<span class="hljs-number">1.3333</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="135" src="https://img-blog.csdnimg.cn/4aed6abd8aa54a0391179b12db132353.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="CROSSENTROPYLOSS"><a name="t113"></a>CROSSENTROPYLOSS（交叉熵）</h2> <p>适用于训练分类问题，有C个类别</p> <p><strong>例：</strong>三分类问题，person，dog，cat</p> <figure class="image">  <img alt="" height="851" src="https://img-blog.csdnimg.cn/66ce37cabecc43d3b354b1a659531d96.png" width="1200">  <figcaption>   公式中的 log 可以按 ln 算  </figcaption> </figure> <p>这里的output不是概率，是评估分数</p> <p></p> <p><img alt="" height="366" src="https://img-blog.csdnimg.cn/b18ec6ac1c094e32814742fd5a63c9af.png" width="1101">input 为没有进行处理过的对每一类的得分</p> <p><strong>代码：</strong></p> <pre data-index="121"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">x = torch.tensor([<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>,<span class="hljs-number">0.3</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">y = torch.tensor([<span class="hljs-number">1</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">x = torch.reshape(x,(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_cross = nn.CrossEntropyLoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">result_cross = loss_cross(x,y)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(result_cross)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果：</strong></p> <pre data-index="122"><code class="language-python hljs">tensor(<span class="hljs-number">1.1019</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B9%8B%E5%89%8D%E5%86%99%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%94%A8%E5%88%B0%20Loss%20Function%EF%BC%88%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%89"><a name="t114"></a>如何在之前写的神经网络中用到 Loss Function（损失函数）</h2> <pre data-index="123" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1077px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model1 = Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Flatten(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为input</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss = nn.CrossEntropyLoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data  <span class="hljs-comment"># imgs为输入，放入神经网络中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    outputs = tudui(imgs)  <span class="hljs-comment"># outputs为输入通过神经网络得到的输出，targets为实际输出</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    result_loss = loss(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(result_loss)  <span class="hljs-comment"># 神经网络输出与真实输出的误差</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>结果：</strong></p> <p><img alt="" height="268" src="https://img-blog.csdnimg.cn/6c83ece015484af1bcb283418a6c54aa.png" width="400"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="backward%C2%A0%20%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><a name="t115"></a>backward&nbsp; 反向传播</h2> <p>计算出每一个节点参数的梯度</p> <p>在上述代码后加一行：</p> <pre data-index="124"><code class="language-python hljs">result_loss.backward()  <span class="hljs-comment"># backward反向传播，是对result_loss，而不是对loss</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>在这一句代码前打上断点（运行到该行代码的前一行，该行不运行），debug 后：<img alt="" height="465" src="https://img-blog.csdnimg.cn/5773513a629f49c189659bb98c699f14.png" width="1200"></p> <p>&nbsp;tudui ——&gt; model 1 ——&gt; Protected Attributes ——&gt; _modules ——&gt; '0' ——&gt; bias / weight——&gt; grad（是None）</p> <p>点击Step into My Code，运行完该行后，可以发现刚刚的None有值了（<span style="color:#956fe7;"><strong>损失函数一定要经过 .backward() 后才能反向传播，才能有每个需要调节的参数的grad的值</strong></span>）</p> <p><strong>下一节：</strong>选择合适的优化器，利用梯度对网络中的参数进行优化更新，以达到整个 loss最低的目的</p> <hr> <h1 id="20.%20%E4%BC%98%E5%8C%96%E5%99%A8"><a name="t116"></a>20. 优化器</h1> <p>当使用损失函数时，可以调用损失函数的 backward，得到反向传播，反向传播可以求出每个需要调节的参数对应的梯度，有了梯度就可以利用优化器，优化器根据梯度对参数进行调整，以达到整体误差降低的目的</p> <p><a href="https://pytorch.org/docs/stable/optim.html" title="torch.optim — PyTorch 1.10 documentation">torch.optim — PyTorch 1.10 documentation</a></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E4%BC%98%E5%8C%96%E5%99%A8%EF%BC%9F"><a name="t117"></a>如何使用优化器？</h2> <p><span style="color:#956fe7;"><strong>（1）构造</strong></span></p> <pre data-index="125"><code class="language-python hljs"><ol class="hljs-ln" style="width:989px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Example：</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># SGD为构造优化器的算法，Stochastic Gradient Descent 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = optim.SGD(model.parameters(), lr=<span class="hljs-number">0.01</span>, momentum=<span class="hljs-number">0.9</span>)  <span class="hljs-comment">#模型参数、学习速率、特定优化器算法中需要设定的参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = optim.Adam([var1, var2], lr=<span class="hljs-number">0.0001</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><span style="color:#956fe7;"><strong>（2）调用优化器的step方法</strong></span></p> <p>利用之前得到的梯度对参数进行更新</p> <pre data-index="126"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> <span class="hljs-built_in">input</span>, target <span class="hljs-keyword">in</span> dataset:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    optimizer.zero_grad() <span class="hljs-comment">#把上一步训练的每个参数的梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = model(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    loss = loss_fn(output, target)  <span class="hljs-comment"># 输出跟真实的target计算loss</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    loss.backward() <span class="hljs-comment">#调用反向传播得到每个要更新参数的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    optimizer.step() <span class="hljs-comment">#每个参数根据上一步得到的梯度进行优化</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E7%AE%97%E6%B3%95"><a name="t118"></a>算法</h2> <p>如Adadelta、Adagrad、Adam、RMSProp、SGD等等，不同算法前两个参数：params、lr 都是一致的，后面的参数不同</p> <pre data-index="127"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">CLASS torch.optim.Adadelta(params, lr=<span class="hljs-number">1.0</span>, rho=<span class="hljs-number">0.9</span>, eps=<span class="hljs-number">1e-06</span>, weight_decay=<span class="hljs-number">0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># params为模型的参数、lr为学习速率（learning rate）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 后续参数都是特定算法中需要设置的</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><span style="color:#fe2c24;"><strong>学习速率不能太大（太大模型训练不稳定）也不能太小（太小模型训练慢），一般建议先采用较大学习速率，后采用较小学习速率</strong></span></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="SGD%E4%B8%BA%E4%BE%8B%C2%A0"><a name="t119"></a>SGD为例&nbsp;</h3> <p>以 <span style="color:#ff9900;"><strong>SGD（随机梯度下降法）</strong></span>为例进行说明：&nbsp;</p> <pre data-index="128" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1077px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载数据集并转为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络名叫Tudui</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model1 = Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Flatten(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为input，forward前向传播</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 计算loss</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss = nn.CrossEntropyLoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optim = torch.optim.SGD(tudui.parameters(),lr=<span class="hljs-number">0.01</span>)  <span class="hljs-comment"># SGD随机梯度下降法</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    imgs,targets = data  <span class="hljs-comment"># imgs为输入，放入神经网络中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    outputs = tudui(imgs)  <span class="hljs-comment"># outputs为输入通过神经网络得到的输出，targets为实际输出</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    result_loss = loss(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    optim.zero_grad()  <span class="hljs-comment"># 把网络模型中每一个可以调节的参数对应梯度设置为0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    result_loss.backward()  <span class="hljs-comment"># backward反向传播求出每一个节点的梯度，是对result_loss，而不是对loss</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    optim.step()  <span class="hljs-comment"># 对每个参数进行调优</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>可以在以下地方打断点，debug：</p> <p><img alt="" height="150" src="https://img-blog.csdnimg.cn/64b91481e1e84fa2b6ec5ed046bc7bde.png" width="1200"></p> <p>tudui ——&gt; Protected Attributes ——&gt; _modules ——&gt; 'model1' ——&gt; Protected Attributes ——&gt; _modules ——&gt; '0' ——&gt; weight ——&gt; data 或 grad</p> <p>通过每次按箭头所指的按钮（点一次运行一行），观察 data 和 grad 值的变化</p> <ul><li>第一行 optim.zero_grad() 是让grad清零</li><li>第三行 optim.step() 会通过grad更新data</li></ul> <p><img alt="" height="535" src="https://img-blog.csdnimg.cn/b3d7d110033d488f979ee8213d74b31a.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><a name="t120"></a><strong>完整代码</strong></h3> <p>在 data 循环外又套一层 epoch 循环，一次 data 循环相当于对数据训练一次，加了 epoch 循环相当于对数据训练 20 次</p> <pre data-index="129" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1077px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载数据集并转为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataset = torchvision.datasets.CIFAR10(<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">dataloader = DataLoader(dataset,batch_size=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络名叫Tudui</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model1 = Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">32</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Conv2d(<span class="hljs-number">32</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            MaxPool2d(<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Flatten(),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">1024</span>,<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            Linear(<span class="hljs-number">64</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为input，forward前向传播</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model1(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 计算loss</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss = nn.CrossEntropyLoss()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建网络</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optim = torch.optim.SGD(tudui.parameters(),lr=<span class="hljs-number">0.01</span>)  <span class="hljs-comment"># SGD随机梯度下降法</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    running_loss = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># 在每一轮开始前将loss设置为0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:  <span class="hljs-comment"># 该循环相当于只对数据进行了一轮学习</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data  <span class="hljs-comment"># imgs为输入，放入神经网络中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)  <span class="hljs-comment"># outputs为输入通过神经网络得到的输出，targets为实际输出</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        result_loss = loss(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optim.zero_grad()  <span class="hljs-comment"># 把网络模型中每一个可以调节的参数对应梯度设置为0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        result_loss.backward()  <span class="hljs-comment"># backward反向传播求出每一个节点的梯度，是对result_loss，而不是对loss</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optim.step()  <span class="hljs-comment"># 对每个参数进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        running_loss = running_loss + result_loss  <span class="hljs-comment"># 每一轮所有loss的和</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(running_loss)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>部分运行结果：</strong></p> <p><img alt="" height="138" src="https://img-blog.csdnimg.cn/a0b109b57b274ad09b5d55757441c829.png" width="350"></p> <p>优化器对模型参数不断进行优化，每一轮的 loss 在不断减小</p> <p>实际过程中模型在整个数据集上的训练次数（即最外层的循环）都是成百上千/万的，本例仅以 20 次为例</p> <hr> <h1 id="21.%20%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E4%BF%AE%E6%94%B9"><a name="t121"></a>21. 现有网络模型的使用及修改</h1> <p><img alt="" height="546" src="https://img-blog.csdnimg.cn/5f87362b51c245f2a7dceddc994e30ef.png" width="300"></p> <p>本节主要讲解 torchvision</p> <p><img alt="" height="179" src="https://img-blog.csdnimg.cn/444aa9af84ff46628be0c55f1d3b6e19.png" width="350"></p> <p>本节主要讲解 Classification 里的 VGG 模型，数据集仍为 CIFAR10 数据集（主要用于分类）</p> <p><a href="https://pytorch.org/vision/stable/models.html#id2" title="torchvision.models — Torchvision 0.11.0 documentation">torchvision.models — Torchvision 0.11.0 documentation</a></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%95%B0%E6%8D%AE%E9%9B%86%20ImageNet"><a name="t122"></a>数据集 ImageNet</h2> <p>注意：必须要先有 package <span style="color:#956fe7;"><strong>scipy</strong></span></p> <p>在 Terminal 里输入</p> <pre data-index="130"><code class="language-python hljs">pip <span class="hljs-built_in">list</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>寻找是否有 scipy，若没有的话输入</p> <pre data-index="131"><code class="hljs language-undefined">pip install scipy</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><span style="color:#fe2c24;"><strong>（注意关闭代理！！！）</strong></span></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E5%8F%82%E6%95%B0%E5%8F%8A%E4%B8%8B%E8%BD%BD%C2%A0"><a name="t123"></a>参数及下载&nbsp;</h3> <p><img alt="" height="348" src="https://img-blog.csdnimg.cn/3017872ec0d64285991e3658c11a2a2a.png" width="1114"></p> <p><strong>下载 ImageNet 数据集：</strong></p> <pre data-index="132"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.ImageNet(<span class="hljs-string">"../data_image_net"</span>,split=<span class="hljs-string">'train'</span>,download=<span class="hljs-literal">True</span>,</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                                           transform=torchvision.transforms.ToTensor())</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <blockquote>  <p>./xxx表示当前路径下，../xxx表示返回上一级目录&nbsp;</p>  <p>多行注释快捷键：ctrl+/</p> </blockquote> <p><strong>运行后会报错：</strong></p> <pre data-index="133"><code class="hljs language-vbnet"><span class="hljs-symbol">RuntimeError:</span> The dataset <span class="hljs-built_in">is</span> no longer publicly accessible. You need <span class="hljs-keyword">to</span> download the archives externally <span class="hljs-built_in">and</span> place them <span class="hljs-keyword">in</span> the root directory.</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="347" src="https://img-blog.csdnimg.cn/dd72e6ccf1b14a3b9b347c57b6bd1dba.png" width="1200">  <figcaption>   数据集不再可以公开访问，必须手动下载压缩文件，放在目录中  </figcaption> </figure> <p><strong>下载地址：</strong></p> <p><a href="https://blog.csdn.net/u014515463/article/details/80748125?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164450268416781685313820%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=164450268416781685313820&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-80748125.pc_search_result_cache&amp;utm_term=imagenet+%E5%AE%8C%E6%95%B4%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8B%E8%BD%BD&amp;spm=1018.2226.3001.4187" title="Imagenet 完整数据集下载_wendell 的博客-CSDN博客_imagenet下载">Imagenet 完整数据集下载_wendell 的博客-CSDN博客_imagenet下载</a></p> <p><span style="color:#ed7976;">100 多个G，太大... 放弃</span></p> <p>按住 Ctrl 键，点击 ImageNet，查看其源码：</p> <p><img alt="" height="461" src="https://img-blog.csdnimg.cn/5a31e7fa1ade43aab17b0334c8f38ffb.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="VGG16%20%E6%A8%A1%E5%9E%8B"><a name="t124"></a>VGG16 模型</h2> <p>VGG 11/13/16/19&nbsp; 常用16和19</p> <h3 id="%E5%8F%82%E6%95%B0%20pretrained%3DTrue%2FFalse%C2%A0"><a name="t125"></a>参数 pretrained=True/False&nbsp;</h3> <p><img alt="" height="187" src="https://img-blog.csdnimg.cn/d88e067d308d4ee08c13249934885f77.png" width="977"></p> <ul><li><span style="color:#ff9900;">pretrained 为 False</span> 的情况下，只是加载网络模型，参数都为默认参数，<span style="color:#ff9900;">不需要下载</span></li><li><span style="color:#ff9900;">为 True 时</span>需要从网络中<span style="color:#ff9900;">下载</span>，卷积层、池化层对应的参数等等（在ImageNet数据集中训练好的）</li></ul> <pre data-index="134"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.models</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 另一个参数progress显示进度条，默认为True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">'ok'</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>断点打在 print('ok') 前，debug 一下，结果如图：</p> <p>&nbsp;<img alt="" height="569" src="https://img-blog.csdnimg.cn/2415d2ab76864158a2e64c1ab58adebb.png" width="550"></p> <p>vgg16_true ——&gt; classifier ——&gt; Protected Attributes ——&gt; modules ——&gt; '0'（线性层）&nbsp;——&gt; weight</p> <p><img alt="" height="146" src="https://img-blog.csdnimg.cn/db0c72789aa443db91db15b264ea313d.png" width="1200"></p> <p>为 false 的情况，同理找到 weight 值：</p> <p><img alt="" height="99" src="https://img-blog.csdnimg.cn/8fd3b0f91c1644028bf996c4e1c34e7f.png" width="1200"></p> <p><strong>总结：&nbsp;</strong></p> <ul><li><span style="color:#fe2c24;">设置为 False 的情况，相当于网络模型中的参数都是初始化的、默认的</span></li><li><span style="color:#fe2c24;">设置为 True 时，网络模型中的参数在数据集上是训练好的，能达到比较好的效果</span></li></ul> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="vgg16%20%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%C2%A0"><a name="t126"></a>vgg16 网络架构&nbsp;</h3> <pre data-index="135"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.models</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 另一个参数progress显示进度条，默认为True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_true = torchvision.models.vgg16(pretrained=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16_true)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>输出：</p> <pre data-index="136" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">VGG(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  (features): Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 输入图片先经过卷积，输入是3通道的、输出是64通道的，卷积核大小是3×3的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 非线性</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 卷积、非线性、池化...</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">2</span>): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">3</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">4</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">5</span>): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">6</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">7</span>): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">8</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">9</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">10</span>): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">11</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">12</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">13</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">14</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">15</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">16</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">17</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">18</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">19</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">20</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">21</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">22</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">23</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">24</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">25</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">26</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">27</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">28</span>): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">29</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">30</span>): MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="hljs-number">7</span>, <span class="hljs-number">7</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  (classifier): Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">25088</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">4</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">5</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 最后线性层输出为1000（vgg16也是一个分类模型，能分出1000个类别）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">6</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;<a href="https://www.image-net.org/challenges/LSVRC/2012/index.php" title="ImageNet">ImageNet</a></p> <p><img alt="" height="369" src="https://img-blog.csdnimg.cn/3e9dbeb7f182414a98de957f96cb6ae3.png" width="1200">所以 out_features = 1000</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E5%8E%BB%E6%94%B9%E5%8A%A8%E5%AE%83%E7%9A%84%E7%BB%93%E6%9E%84%EF%BC%9F"><a name="t127"></a>如何利用现有网络去改动它的结构？</h2> <pre data-index="137"><code class="language-python hljs">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"./dataset"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>CIFAR10 把数据分成了10类，而 vgg16 模型把数据分成了 1000 类，如何应用这个网络模型呢？</p> <ul><li>把最后线性层的 out_features 从1000改为10</li><li><strong><span style="color:#956fe7;">在最后的线性层下面再加一层，in_features为1000，out_features为10</span></strong></li></ul> <p>利用现有网络去改动它的结构，避免写 vgg16</p> <p>很多框架会把 vgg16 当做前置的网络结构，提取一些特殊的特征，再在后面加一些网络结构，实现功能</p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E6%B7%BB%E5%8A%A0%C2%A0"><a name="t128"></a>添加&nbsp;</h3> <p><strong>以 vgg16_true 为例讲解，实现上面的<span style="color:#956fe7;">第二种</span>思路：</strong></p> <pre data-index="138"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 给 vgg16 添加一个线性层，输入1000个类别，输出10个类别</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_true.add_module(<span class="hljs-string">'add_linear'</span>,nn.Linear(in_features=<span class="hljs-number">1000</span>,out_features=<span class="hljs-number">10</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16_true)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果如图：</p> <p><img alt="" height="265" src="https://img-blog.csdnimg.cn/65e670fcf2f44c74a68ac57c4d31b05b.png" width="550"></p> <p><strong>如果想将 module 添加至 classifier 里：</strong></p> <pre data-index="139"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 给 vgg16 添加一个线性层，输入1000个类别，输出10个类别</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_true.classifier.add_module(<span class="hljs-string">'add_linear'</span>,nn.Linear(in_features=<span class="hljs-number">1000</span>,out_features=<span class="hljs-number">10</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16_true)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>&nbsp;结果如图：</p> <p><img alt="" height="243" src="https://img-blog.csdnimg.cn/d351a2f8543e4811aba424d34d6a2f53.png" width="550"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E4%BF%AE%E6%94%B9%C2%A0"><a name="t129"></a>修改&nbsp;</h3> <p>以上为<strong><span style="color:#ff9900;">添加</span></strong>，那么如何<span style="color:#ff9900;"><strong>修改</strong></span>呢？</p> <p><strong>以 vgg16_false 为例：</strong></p> <pre data-index="140"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_false = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 另一个参数progress显示进度条，默认为True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16_false)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果如下：</p> <pre data-index="141"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  (classifier): Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">25088</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">1</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">2</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">4096</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">4</span>): ReLU(inplace=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">5</span>): Dropout(p=<span class="hljs-number">0.5</span>, inplace=<span class="hljs-literal">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    (<span class="hljs-number">6</span>): Linear(in_features=<span class="hljs-number">4096</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">  )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>想将最后一层 Linear 的 out_features 改为10：</strong></p> <pre data-index="142"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16_false.classifier[<span class="hljs-number">6</span>] = nn.Linear(<span class="hljs-number">4096</span>,<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16_false)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果如下：</p> <p><img alt="" height="252" src="https://img-blog.csdnimg.cn/64538faa297a450bab09e96cd93437c3.png" width="550"></p> <p><strong>本节：</strong></p> <ul><li>如何加载现有的一些 pytorch 提供的网络模型</li><li>如何对网络模型中的结构进行修改，包括添加自己想要的一些网络模型结构</li></ul> <hr> <h1 id="22.%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><a name="t130"></a>22. 网络模型的保存与读取</h1> <p><strong>后续内容：</strong></p> <p><img alt="" height="338" src="https://img-blog.csdnimg.cn/6089f28769174faa9a41b9b8fb0c8944.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E4%BF%9D%E5%AD%98%EF%BC%9A"><a name="t131"></a>两种方式保存模型</h2> <pre data-index="143"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.models</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16 = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 网络中模型的参数是没有经过训练的、初始化的参数</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>方式1：不仅保存了网络模型的<strong><span style="color:#956fe7;">结构</span></strong>，也保存了网络模型的<strong><span style="color:#956fe7;">参数</span></strong></p> <pre data-index="144"><code class="language-php hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 保存方式1：模型结构+模型参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">torch.<span class="hljs-title function_ invoke__">save</span>(vgg16,<span class="hljs-string">"vgg16_method1.pth"</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>方式2：网络模型的<span style="color:#956fe7;"><strong>参数</strong></span>保存为字典，不保存网络模型的结构<strong><span style="color:#4da8ee;">（官方推荐的保存方式，用的空间小）</span></strong></p> <pre data-index="145"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 保存方式2：模型参数（官方推荐）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">torch.save(vgg16.state_dict(),<span class="hljs-string">"vgg16_method2.pth"</span>)   </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 把vgg16的状态保存为字典形式（Python中的一种数据格式）</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后 src 文件夹底下会多出以下两个文件：</p> <p><img alt="" height="55" src="https://img-blog.csdnimg.cn/37711df28c4548baa2a5e7d34ac3bff6.png" width="200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E5%8A%A0%E8%BD%BD%EF%BC%9A"><a name="t132"></a>两种方式加载模型</h2> <p>方式1：对应保存方式1，打印出的是<strong><span style="color:#956fe7;">网络模型的结构</span></strong></p> <pre data-index="146"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 方式1 对应 保存方式1，加载模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"vgg16_method1.pth"</span>,)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)  <span class="hljs-comment"># 打印出的只是模型的结构，其实它的参数也被保存下来了</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="339" src="https://img-blog.csdnimg.cn/17b2176e99204b75a89d7d8d32b4f0fc.png" width="550">  <figcaption>   保存的是网络模型的结构  </figcaption> </figure> <p>在print这句打上断点，debug一下，可以看一下模型参数&nbsp;</p> <p>方式2：对应保存方式2，打印出的是<span style="color:#956fe7;"><strong>参数的字典形式</strong></span></p> <pre data-index="147"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 方式2 加载模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"vgg16_method2.pth"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="339" src="https://img-blog.csdnimg.cn/b3f30aac7e94480284d0d19b79ffe554.png" width="550">  <figcaption>   保存的是参数的字典形式，不再是网络模型  </figcaption> </figure> <p><span style="color:#ff9900;"><strong>如何恢复网络模型结构？</strong></span></p> <pre data-index="148"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.models</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16 = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># 预训练设置为False</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">vgg16.load_state_dict(torch.load(<span class="hljs-string">"vgg16_method2.pth"</span>))  <span class="hljs-comment"># vgg16通过字典形式，加载状态即参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(vgg16)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="176" src="https://img-blog.csdnimg.cn/672f6566b8cd4e3dad975af98d587ccb.png" width="550"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%96%B9%E5%BC%8F1%20%E6%9C%89%E9%99%B7%E9%98%B1%EF%BC%88%E8%87%AA%E5%B7%B1%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%EF%BC%8C%E6%B2%A1%E6%9C%89%E7%94%A8%20vgg16%20%E6%97%B6%EF%BC%89"><a name="t133"></a>方式1 有陷阱（自己定义网络结构，没有用 vgg16 时）</h2> <p><strong><span style="color:#fe2c24;">用方式1保存的话，加载时要让程序能够访问到其定义模型的一种方式</span></strong>&nbsp;</p> <h3 id="%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0%C2%A0"><a name="t134"></a>问题描述&nbsp;</h3> <p>首先在 model_save.py 中写以下代码：</p> <pre data-index="149"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 陷阱</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv = nn.Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为输入</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()  <span class="hljs-comment"># 有一个卷积层和一些初始化的参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">torch.save(tudui,<span class="hljs-string">"tudui_method1.pth"</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后 src 文件夹底下多出一个文件：</p> <p><img alt="" height="35" src="https://img-blog.csdnimg.cn/7d2aea493ac745eb956e0dfae3858060.png" width="242"></p> <p>再在 model_load.py 中写以下代码：</p> <pre data-index="150"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 陷阱</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"tudui_method1.pth"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后发现报错：</p> <p><img alt="" height="453" src="https://img-blog.csdnimg.cn/22859e9ded2d4aeebe665a4023130770.png" width="1200"></p> <pre data-index="151"><code class="hljs language-cobol"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">AttributeError: Can<span class="hljs-string">'t get attribute '</span>Tudui<span class="hljs-string">' on &lt;module '</span>__main__<span class="hljs-string">' from '</span>C:<span class="hljs-operator">/</span>Users<span class="hljs-operator">/</span><span class="hljs-number">11842</span><span class="hljs-operator">/</span>Desktop<span class="hljs-operator">/</span>Learn_torch<span class="hljs-operator">/</span>src<span class="hljs-operator">/</span>model_load.py<span class="hljs-string"><span class="hljs-string">'&gt;</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"># 不能得到'</span>Tudui<span class="hljs-string">'这个属性，因为没有这个类</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E8%A7%A3%E5%86%B3%EF%BC%9A"><a name="t135"></a><span style="color:#fe2c24;"><strong>解决</strong></span></h3> <p>还是需要将 model_save.py 中的网络结构复制到 model_load.py 中，即下列代码<span style="color:#ff9900;"><strong>需要复制</strong></span>到 model_load.py 中（为了确保加载的网络模型是想要的网络模型）：</p> <pre data-index="152"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv = nn.Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为输入</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>但是不需要创建了，即在 model_load.py 中<span style="color:#ff9900;"><strong>不需要</strong></span>写：</p> <pre data-index="153"><code class="language-python hljs">tudui = Tudui()</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>此时 model_load.py 完整代码为：</p> <pre data-index="154"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 陷阱</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.conv = nn.Conv2d(<span class="hljs-number">3</span>,<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">3</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):   <span class="hljs-comment"># x为输入</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.conv(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"tudui_method1.pth"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果如下：</p> <p><img alt="" height="131" src="https://img-blog.csdnimg.cn/c30f94426dc14b1d85c57a3f4990a397.png" width="550"></p> <h3 id="%E8%A7%A3%E5%86%B3%E5%8F%A6%E6%B3%95%EF%BC%9A"><a name="t136"></a><span style="color:#fe2c24;"><strong>解决另法：</strong></span></h3> <p>实际写项目过程中，直接定义在一个单独的文件中（如model_save.py），再在 model_load.py 中：</p> <pre data-index="155"><code class="language-python hljs"><span class="hljs-keyword">from</span> model_save <span class="hljs-keyword">import</span> *</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <hr> <h1 id="23.%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF"><a name="t137"></a>23. 完整的模型训练套路</h1> <p>以 CIFAR10 数据集为例，分类问题（10分类）</p> <blockquote>  <p>在语句后面按 Ctrl + d 可以复制这条语句</p> </blockquote> <p><img alt="" height="535" src="https://img-blog.csdnimg.cn/d36fd8fe37de42479783b4d0781f784b.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="model.py%20%E6%96%87%E4%BB%B6%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><a name="t138"></a><strong><span style="color:#ff9900;">model.py </span></strong>文件代码</h2> <pre data-index="156" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1192px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络（10分类网络）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 把网络放到序列中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>), <span class="hljs-comment">#输入是32x32的，输出还是32x32的（padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),  <span class="hljs-comment">#输入输出都是16x16的（同理padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Flatten(),   <span class="hljs-comment"># 展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>,out_features=<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>,out_features=<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试网络的验证正确性</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))  <span class="hljs-comment"># batch_size=64（代表64张图片）,3通道，32x32</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = tudui(<span class="hljs-built_in">input</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(output.shape)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果如下：</p> <p><img alt="" height="44" src="https://img-blog.csdnimg.cn/24be21baa4b049e884c70579d547be48.png" width="300"></p> <p>返回64行数据，每一行数据有10个数据，代表每一张图片在10个类别中的概率</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="train.py%20%E6%96%87%E4%BB%B6%E4%BB%A3%E7%A0%81%E5%A6%82%E4%B8%8B%EF%BC%9A"><a name="t139"></a><strong><span style="color:#ff9900;">train.py</span></strong> 文件代码</h2> <p><strong><span style="color:#fe2c24;">（与 model.py 文件必须在同一个文件夹底下）</span></strong></p> <pre data-index="157" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">10</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"----------第&#123;&#125;轮训练开始-----------"</span>.<span class="hljs-built_in">format</span>(i+<span class="hljs-number">1</span>))  <span class="hljs-comment"># i从0-9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:   <span class="hljs-comment"># 从训练的dataloader中取数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果如下：&nbsp;</p> <p><img alt="" height="319" src="https://img-blog.csdnimg.cn/cef9cbd37cf443b69d3a0c7bcb810cd8.png" width="300"></p> <blockquote>  <p><strong>print(a) 和 print(a.item()) 的区别</strong></p>  <pre data-index="158">import torcha = torch.tensor(5)print(a)print(a.item())</pre>  <p><img alt="" height="53" src="https://img-blog.csdnimg.cn/3891cc34c5ae405ab0ac73cc5bc4d85d.png" width="100"></p> </blockquote> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E6%A8%A1%E5%9E%8B%E6%98%AF%E5%90%A6%E8%AE%AD%E7%BB%83%E5%A5%BD%EF%BC%8C%E6%88%96%E8%BE%BE%E5%88%B0%E9%9C%80%E6%B1%82%EF%BC%9F"><a name="t140"></a>如何知道模型是否训练好，或达到需求？</h2> <p><span style="color:#956fe7;"><strong>每次训练完一轮就进行测试，以测试数据集上的损失或正确率来评估模型有没有训练好</strong></span></p> <p><strong><span style="color:#fe2c24;">测试过程中不需要对模型进行调优，利用现有模型进行测试</span></strong>，所以有以下命令：</p> <pre data-index="159"><code class="language-python hljs"><span class="hljs-keyword">with</span> torch.no_grad(): </code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>在上述 train.py 代码后继续写：</p> <pre data-index="160"><code class="language-python hljs"><ol class="hljs-ln" style="width:1127px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字，所以要.item()一下</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>结果如下：</p> <p><img alt="" height="342" src="https://img-blog.csdnimg.cn/d54278d37ee148bebfd5e1b7aff0d528.png" width="350"></p> <p>此处为了使测试的 loss 结果易找，在&nbsp;train.py 中添加了一句 if 的代码，使train每训练100轮才打印1次：</p> <pre data-index="161"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <h3><a name="t141"></a>完整代码</h3> <pre data-index="162" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">10</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"----------第&#123;&#125;轮训练开始-----------"</span>.<span class="hljs-built_in">format</span>(i+<span class="hljs-number">1</span>))  <span class="hljs-comment"># i从0-9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%8E%20TensorBoard%20%E7%BB%93%E5%90%88%EF%BC%9A"><a name="t142"></a>与 TensorBoard 结合</h2> <pre data-index="163" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">10</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 添加tensorboard</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_train"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"----------第&#123;&#125;轮训练开始-----------"</span>.<span class="hljs-built_in">format</span>(i+<span class="hljs-number">1</span>))  <span class="hljs-comment"># i从0-9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            writer.add_scalar(<span class="hljs-string">"train_loss"</span>,loss.item(),total_train_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_loss"</span>,total_test_loss,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <p><img alt="" height="557" src="https://img-blog.csdnimg.cn/a58a2e8da62e4bcaaeff6158359a0832.png" width="300"></p> <p>在 Terminal 里输入：</p> <pre data-index="164"><code class="language-python hljs">tensorboard --logdir=logs_train</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="562" src="https://img-blog.csdnimg.cn/d246d1dd11d64669b00f964ecaff269b.png" width="350"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%BF%9D%E5%AD%98%E6%AF%8F%E4%B8%80%E8%BD%AE%E8%AE%AD%E7%BB%83%E7%9A%84%E6%A8%A1%E5%9E%8B%C2%A0"><a name="t143"></a>保存每一轮训练的模型&nbsp;</h2> <p>添加两句代码：&nbsp;</p> <pre data-index="165"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    torch.save(tudui,<span class="hljs-string">"tudui_&#123;&#125;.pth"</span>.<span class="hljs-built_in">format</span>(i))  <span class="hljs-comment"># 每一轮保存一个结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"模型已保存"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后：</p> <p><img alt="" height="303" src="https://img-blog.csdnimg.cn/bc6efc7c94c442329a845109368c5539.png" width="205">&nbsp;&nbsp;</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%AD%A3%E7%A1%AE%E7%8E%87%E7%9A%84%E5%AE%9E%E7%8E%B0%EF%BC%88%E5%AF%B9%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%89%C2%A0"><a name="t144"></a>正确率的实现（对分类问题）&nbsp;</h2> <p id="%E5%8D%B3%E4%BE%BF%E5%BE%97%E5%88%B0%E6%95%B4%E4%BD%93%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E7%9A%84%20loss%EF%BC%8C%E4%B9%9F%E4%B8%8D%E8%83%BD%E5%BE%88%E5%A5%BD%E5%9C%B0%E8%AF%B4%E6%98%8E%E5%9C%A8%E6%B5%8B%E8%AF%95%E9%9B%86%E4%B8%8A%E7%9A%84%E8%A1%A8%E7%8E%B0%E6%95%88%E6%9E%9C"><strong>即便得到整体测试集上的 loss，也不能很好说明在测试集上的表现效果</strong></p> <ul><li><span style="color:#956fe7;">在<strong>分类问题</strong>中可以用<strong>正确率</strong>表示（下述代码改进）</span></li><li>在目标检测/语义分割中，可以把输出放在tensorboard里显示，看测试结果</li></ul> <p><strong>例子：&nbsp;</strong></p> <p><img alt="" height="1026" src="https://img-blog.csdnimg.cn/22da9e11df18401ca4969a4f5bcf99f8.png" width="1200"></p> <p><span style="color:#ff9900;"><strong>第一步：</strong></span></p> <pre data-index="166"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">outputs = torch.tensor([[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.2</span>],</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                        [<span class="hljs-number">0.3</span>,<span class="hljs-number">0.4</span>]])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(outputs.argmax(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 0或1表示方向，1为横向比较大小. 运行结果：tensor([1, 1])</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="201" src="https://img-blog.csdnimg.cn/b764fc20833b4d769469d4af471eca01.png" width="1200"></p> <p><span style="color:#ff9900;"><strong>第二步：</strong></span></p> <pre data-index="167"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">preds = outputs.argmax(<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">targets = torch.tensor([<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(preds == targets)  <span class="hljs-comment"># tensor([False,  True])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sum</span>(preds == targets).<span class="hljs-built_in">sum</span>())  <span class="hljs-comment"># tensor(1)，对应位置相等的个数</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>上例说明了基本用法，现对原问题的代码再进一步优化，<strong>计算整体正确率：</strong></p> <pre data-index="168" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1017px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_accuracy = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># 1：横向比较，==：True或False，sum：计算True或False个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_accuracy = total_accuracy + accuracy</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的正确率：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_accuracy/imgs.size(<span class="hljs-number">0</span>)))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_loss"</span>,total_test_loss,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_accuracy"</span>,total_accuracy/imgs.size(<span class="hljs-number">0</span>),total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    torch.save(tudui,<span class="hljs-string">"tudui_&#123;&#125;.pth"</span>.<span class="hljs-built_in">format</span>(i))  <span class="hljs-comment"># 每一轮保存一个结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"模型已保存"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <p><img alt="" height="594" src="https://img-blog.csdnimg.cn/aa87069917134c3bb1a36d4885294c0e.png" width="300"></p> <p>在 Terminal 里输入：</p> <pre data-index="169"><code class="language-python hljs">tensorboard --logdir=logs_train</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>打开网址&nbsp;&nbsp;http://localhost:6006/ ：</p> <p><img alt="" height="663" src="https://img-blog.csdnimg.cn/2c7c00e15af84154bd53873c5383dbd2.png" width="300"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="train.py%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><a name="t145"></a><span style="color:#ff9900;"><strong>train.py 完整代码</strong></span></h2> <pre data-index="170" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">10</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 添加tensorboard</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_train"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"----------第&#123;&#125;轮训练开始-----------"</span>.<span class="hljs-built_in">format</span>(i+<span class="hljs-number">1</span>))  <span class="hljs-comment"># i从0-9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            writer.add_scalar(<span class="hljs-string">"train_loss"</span>,loss.item(),total_train_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_accuracy = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># 1：横向比较，==：True或False，sum：计算True或False个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_accuracy = total_accuracy + accuracy</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的正确率：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_accuracy/test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_loss"</span>,total_test_loss,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_accuracy"</span>,total_accuracy/test_data_size,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    torch.save(tudui,<span class="hljs-string">"tudui_&#123;&#125;.pth"</span>.<span class="hljs-built_in">format</span>(i))  <span class="hljs-comment"># 每一轮保存一个结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"模型已保存"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E4%B8%80%E4%BA%9B%E7%BB%86%E8%8A%82"><a name="t146"></a>model.train() 和 model.eval()</h2> <p><img alt="" height="239" src="https://img-blog.csdnimg.cn/36474c83c5464528be015f3011d7e599.png" width="500"></p> <p>训练步骤开始之前会把网络模型（我们这里的网络模型叫 tudui）设置为train，并不是说把网络设置为训练模型它才能够开始训练</p> <p><img alt="" height="837" src="https://img-blog.csdnimg.cn/7c7d7c7845ac47849bb4927ebe17a29d.png" width="1200"></p> <p>测试网络前写 网络.eval()，并不是说需要这一行才能把网络设置成 eval 状态，才能进行网络测试</p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E4%BD%9C%E7%94%A8%C2%A0"><a name="t147"></a>作用&nbsp;</h3> <p>这两句不写网络依然可以运行，<strong>它们的作用是：</strong></p> <p><img alt="" height="629" src="https://img-blog.csdnimg.cn/b7816fe7f7d147d19dc6ac6a990b97ab.png" width="1200"></p> <p><img alt="" height="632" src="https://img-blog.csdnimg.cn/3d1a597df8474e159462f0039dc5474f.png" width="1197">本节写的案例没有 Dropout 层或 BatchNorm 层，所以有没有这两行无所谓</p> <p>如果有这些特殊层，一定要调用</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E5%9B%9E%E9%A1%BE%E6%A1%88%E4%BE%8B"><a name="t148"></a>回顾案例</h2> <p>首先，要准备数据集，准备对应的 dataloader</p> <pre data-index="171" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1136px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>然后，创建网络模型、损失函数、优化器，设置训练中的一些参数、训练轮数 epoch（为了能够进行多次训练）</p> <pre data-index="172"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">10</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>调用</p> <pre data-index="173"><code class="language-python hljs">tudui.train() </code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>使网络进入训练状态，从训练的 dataloader 中不断取数据，算出误差，放到优化器中进行优化，采用某种特定的方式展示输出，一轮结束后或特定步数后进行测试</p> <pre data-index="174"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            writer.add_scalar(<span class="hljs-string">"train_loss"</span>,loss.item(),total_train_step)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>测试过程中可以设置</p> <pre data-index="175"><code class="language-python hljs">    tudui.<span class="hljs-built_in">eval</span>() </code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>要设置</p> <pre data-index="176"><code class="language-python hljs">    <span class="hljs-keyword">with</span> torch.no_grad(): </code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>让网络模型中的参数都没有，因为我们只需要进行测试，不需要对网络模型进行调整，更不需要利用梯度来优化</p> <p>从测试数据集中取数据，计算误差，构建特殊指标显示出来</p> <pre data-index="177"><code class="language-python hljs"><ol class="hljs-ln" style="width:1017px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># 1：横向比较，==：True或False，sum：计算True或False个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_accuracy = total_accuracy + accuracy</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>最后可以通过一些方式来展示一下训练的网络在测试集上的效果</p> <pre data-index="178"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的正确率：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_accuracy/test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_loss"</span>,total_test_loss,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    writer.add_scalar(<span class="hljs-string">"test_accuracy"</span>,total_accuracy/test_data_size,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_step += <span class="hljs-number">1</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>在特定步数或某一轮可以保存模型，保存模型的方式是之前讲的方式1：</p> <pre data-index="179"><code class="language-python hljs">    torch.save(tudui,<span class="hljs-string">"tudui_&#123;&#125;.pth"</span>.<span class="hljs-built_in">format</span>(i))</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>回忆官方推荐的方式2：</p> <pre data-index="180"><code class="language-python hljs">    torch.save(tudui.state_dict,<span class="hljs-string">"tudui_&#123;&#125;.pth"</span>.<span class="hljs-built_in">format</span>(i))</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>（将网络模型的状态转化为字典型，展示它的特定保存位置）</p> <hr> <h1 id="24.%20%E5%88%A9%E7%94%A8GPU%E8%AE%AD%E7%BB%83"><a name="t149"></a>24. 利用GPU训练</h1> <p>两种方式实现代码在GPU上训练：</p> <h2 id="%E7%AC%AC%E4%B8%80%E7%A7%8D%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%9A"><a name="t150"></a>第一种使用GPU训练的方式</h2> <p><img alt="" height="245" src="https://img-blog.csdnimg.cn/4efa7fb1dc5d4546820ac0fdaef9d947.png" width="500"></p> <p><strong><span style="color:#ff9900;">网络模型：&nbsp;</span></strong></p> <p><img alt="" height="97" src="https://img-blog.csdnimg.cn/8deb360a9c704edba4a2f3e2e29c1961.png" width="400"></p> <p><span style="color:#ff9900;"><strong>数据（包括输入、标注）：</strong></span></p> <figure class="image">  <img alt="" height="245" src="https://img-blog.csdnimg.cn/ae52da255050443fbffb1f26eaf596fa.png" width="400">  <figcaption>   训练过程  </figcaption> </figure> <figure class="image">  <img alt="" height="285" src="https://img-blog.csdnimg.cn/0010222f0f134cc3910a16269c41df1d.png" width="1200">  <figcaption>   测试过程  </figcaption> </figure> <p><span style="color:#ff9900;"><strong>损失函数：</strong></span></p> <p><img alt="" height="77" src="https://img-blog.csdnimg.cn/ad6984b7fa4f4dee87a1a44cb177beb9.png" width="450"></p> <p>更好的写法：</p> <p><img alt="" height="111" src="https://img-blog.csdnimg.cn/7ec63c8e24d144f2be2d3819ee95ddec.png" width="450"></p> <p>其他地方同理加上&nbsp;</p> <p>这种写法在CPU和GPU上都可以跑，优先在GPU上跑</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E6%AF%94%E8%BE%83CPU%2FGPU%E8%AE%AD%E7%BB%83%E6%97%B6%E9%97%B4%C2%A0"><a name="t151"></a>比较CPU/GPU训练时间&nbsp;</h2> <p id="%E4%B8%BA%E4%BA%86%E6%AF%94%E8%BE%83%E6%97%B6%E9%97%B4%EF%BC%8C%E5%BC%95%E5%85%A5%20time%20%E8%BF%99%E4%B8%AA%20package">为了比较时间，引入 time 这个 package</p> <h3 id="%E5%AF%B9%E4%BA%8ECPU"><a name="t152"></a><strong><span style="color:#ff9900;">对于CPU</span></strong></h3> <p><img alt="" height="438" src="https://img-blog.csdnimg.cn/7e2e0bf461224af2a12b932ef96708f2.png" width="992"></p> <p><img alt="" height="557" src="https://img-blog.csdnimg.cn/c9a0989b0b7c42369801848312793348.png" width="1107">&nbsp;<img alt="" height="474" src="https://img-blog.csdnimg.cn/9d726466bd734e64bf7ba0101e09f833.png" width="1128"></p> <p>运行 train.py，可以看到它运行了4.53s</p> <p><img alt="" height="224" src="https://img-blog.csdnimg.cn/b2fc94c5b4004991a0a30dfd1b120dc4.png" width="450"></p> <h3 id="%E5%AF%B9%E4%BA%8EGPU"><a name="t153"></a><strong><span style="color:#ff9900;">对于GPU</span></strong></h3> <p><img alt="" height="235" src="https://img-blog.csdnimg.cn/a81d598f5c014c20a096c25f063c2d08.png" width="450"></p> <p><span style="color:#0d0016;">时间竟然比CPU长（我不理解orz）</span></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h3 id="%E6%9F%A5%E7%9C%8BGPU%E4%BF%A1%E6%81%AF%C2%A0"><a name="t154"></a>查看GPU信息&nbsp;</h3> <p>在 Terminal 里输入</p> <pre data-index="181"><code class="language-python hljs">nvidia-smi</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>会出现一些GPU的信息</p> <p><img alt="" height="811" src="https://img-blog.csdnimg.cn/2a5d9691a37244648f49b8af06b995af.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="Google%20Colab"><a name="t155"></a>Google Colab</h2> <p>Google 为我们提供了一个免费的GPU，默认提供的环境当中就有Pytorch</p> <p><img alt="" height="300" src="https://img-blog.csdnimg.cn/19c50ce73c1a4ba7b279c9047bd2b519.png" width="450"></p> <h3 id="%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8GPU%EF%BC%9F"><a name="t156"></a><strong>如何使用GPU？</strong></h3> <p><strong><span style="color:#fe2c24;">修改 ——&gt; 笔记本设置 ——&gt; 硬件加速器选择GPU（每周免费使用30h）</span></strong></p> <p>使用GPU后会重新启动环境</p> <figure class="image">  <img alt="" height="256" src="https://img-blog.csdnimg.cn/c1a5c63f198e499fab7dddbb22324c99.png" width="400">  <figcaption>   前后的序号都没有了，要重新运行  </figcaption> </figure> <figure class="image">  <img alt="" height="305" src="https://img-blog.csdnimg.cn/e98aed3140224126ae0d78de52fb20fc.png" width="400">  <figcaption>   重新运行后为True  </figcaption> </figure> <p>将 train_gpu_1.py 代码复制进去运行，速度很快，结果如下：</p> <p><img alt="" height="735" src="https://img-blog.csdnimg.cn/ce2895d409cb410fbd077302a6e28bc1.png" width="1126"></p> <h3 id="%E6%9F%A5%E7%9C%8BGPU%E9%85%8D%E7%BD%AE%C2%A0"><a name="t157"></a>查看GPU配置&nbsp;</h3> <p>在 Google Colab 上运行 terminal 中运行的东西，在语句前加 !（感叹号）</p> <p><img alt="" height="577" src="https://img-blog.csdnimg.cn/5b1950643ff34636a76079347c052451.png" width="985"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2 id="%E7%AC%AC%E4%BA%8C%E7%A7%8D%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83%E7%9A%84%E6%96%B9%E5%BC%8F%EF%BC%9A"><a name="t158"></a>第二种使用GPU训练的方式（更常用）</h2> <p><img alt="" height="292" src="https://img-blog.csdnimg.cn/e79f6450be2b459a8389b34778214330.png" width="550"></p> <p><strong>以下两种写法对于单显卡来说等价：</strong></p> <pre data-index="182"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">device = torch.device(<span class="hljs-string">"cuda"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">device = torch.device(<span class="hljs-string">"cuda:0"</span>)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>语法糖（一种语法的简写），程序在 CPU 或 GPU/cuda 环境下都能运行：&nbsp;</strong></p> <pre data-index="183"><code class="language-python hljs">device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <figure class="image">  <img alt="" height="419" src="https://img-blog.csdnimg.cn/8957db224243446d9dbfd90fbb5e3756.png" width="450">  <figcaption>   通过这个变量可以控制是在CPU上运行还是GPU（改成 "cuda" 或 "cuda:0" ）上运行  </figcaption> </figure> <p></p> <figure class="image">  <img alt="" height="103" src="https://img-blog.csdnimg.cn/d694883018a74274a01b3a34c00897ca.png" width="300">  <figcaption>   这里第二句可以不用再赋值给 tudui，直接 tudui.to(device) 也可以  </figcaption> </figure> <p></p> <figure class="image">  <img alt="" height="94" src="https://img-blog.csdnimg.cn/ec9f96e9177c4bdab92c8544501da829.png" width="500">  <figcaption>   同上  </figcaption> </figure> <p></p> <figure class="image">  <img alt="" height="469" src="https://img-blog.csdnimg.cn/ef2a0336ce3242b593c83489c14b3c5d.png" width="1111">  <figcaption>   必须要赋值  </figcaption> </figure> <p></p> <figure class="image">  <img alt="" height="518" src="https://img-blog.csdnimg.cn/cd8c0f0e7d7b466da97959cd7c1c32ee.png" width="1200">  <figcaption>   必须要赋值  </figcaption> </figure> <p><strong><span style="color:#fe2c24;">网络模型、损失函数都不需要另外赋值，直接 .to(device) 就可以</span></strong></p> <p><strong><span style="color:#fe2c24;">但是数据（图片、标注）需要另外转移之后再重新赋值给变量</span></strong></p> <hr> <h1 id="25.%20%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%EF%BC%88%E6%B5%8B%E8%AF%95%E3%80%81demo%EF%BC%89%E5%A5%97%E8%B7%AF"><a name="t159"></a>25. 完整的模型验证（测试、demo）套路</h1> <p><strong>核心：</strong>利用已经训练好的模型，给它提供输入进行测试（类似之前案例中测试集的测试部分）</p> <p><img alt="" height="605" src="https://img-blog.csdnimg.cn/ab35739c9f164982b7e94c2a38b62183.png" width="1200"></p> <p><a class="link-info" href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" title="pytorch-CycleGAN-and-pix2pix">pytorch-CycleGAN-and-pix2pix</a></p> <p><img alt="" height="949" src="https://img-blog.csdnimg.cn/0f3132558be341fa8d789bfe295a326b.png" width="1200"></p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <h2><a name="t160"></a>示例&nbsp;</h2> <p>Resize()：&nbsp;</p> <p><img alt="" height="307" src="https://img-blog.csdnimg.cn/06ad76c3659b4f318fe2c9df341a911d.png" width="450"></p> <p>随便在网络上找图片，通过<span style="color:#fe2c24;"><strong> Resize() </strong></span>使图片符合模型</p> <pre data-index="184" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1192px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如何从test.py文件去找到dog文件（相对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path = <span class="hljs-string">"../imgs/dog.png"</span>  <span class="hljs-comment"># 或右键-&gt; Copy Path-&gt; Absolute Path（绝对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 读取图片（PIL Image），再用ToTensor进行转换</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = Image.<span class="hljs-built_in">open</span>(image_path)  <span class="hljs-comment"># 现在的image是PIL类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image)  <span class="hljs-comment"># &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=430x247 at 0x1DF29D33AF0&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># image = image.convert('RGB')</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 因为png格式是四通道，除了RGB三通道外，还有一个透明度通道，所以要调用上述语句保留其颜色通道</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 当然，如果图片本来就是三颜色通道，经过此操作，不变</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加上这一步后，可以适应 png jpg 各种格式的图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 该image大小为430x247，网络模型的输入只能是32x32，进行一个Resize()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Compose()：把transforms几个变换联立在一起</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)),  <span class="hljs-comment"># 32x32大小的PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                                            torchvision.transforms.ToTensor()])  <span class="hljs-comment"># 转为Tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = transform(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image.shape)  <span class="hljs-comment"># torch.Size([3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载网络模型（之前采用的是第一种方式保存，故需要采用第一种方式加载）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 首先搭建神经网络（10分类网络）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 把网络放到序列中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>), <span class="hljs-comment">#输入是32x32的，输出还是32x32的（padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),  <span class="hljs-comment">#输入输出都是16x16的（同理padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Flatten(),   <span class="hljs-comment"># 展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>,out_features=<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>,out_features=<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 然后加载网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"tudui_0.pth"</span>)  <span class="hljs-comment"># 因为test.py和tudui_0.pth在同一个层级下，所以地址可以直接写</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">output = model(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行会报错，报错提示如下：</p> <pre data-index="185"><code class="hljs language-cobol">RuntimeError: Expected <span class="hljs-number">4</span>-dimensional <span class="hljs-keyword">input</span> <span class="hljs-keyword">for</span> <span class="hljs-number">4</span>-dimensional weight [<span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>], but got <span class="hljs-number">3</span>-dimensional <span class="hljs-keyword">input</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">size</span> [<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>] instead</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="61" src="https://img-blog.csdnimg.cn/f64d0180f834444e968d0d310072cea4.png" width="1200"></p> <p>原因：要求是四维的输入 [batch_size,channel,length,width]，但是获得的图片是三维的 —— 图片没有指定 batch_size<strong><span style="color:#fe2c24;">（网络训练过程中是需要 batch_size 的，而图片输入是三维的，需要reshape() 一下）</span></strong></p> <p><strong>解决：torch.reshape() 方法</strong></p> <p>在上述代码后面加上：</p> <pre data-index="186"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = torch.reshape(image,(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 模型转化为测试类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 节约内存和性能</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = model(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>运行结果：</strong><img alt="" height="94" src="https://img-blog.csdnimg.cn/ceac1f7332214f66ab5f30b991b5cd87.png" width="1200"></p> <p>1.3220 概率最大，预测的是第六类</p> <pre data-index="187"><code class="language-python hljs"><span class="hljs-built_in">print</span>(output.argmax(<span class="hljs-number">1</span>))</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="55" src="https://img-blog.csdnimg.cn/0f119419252d455b83d598c2924f0d18.png" width="200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <figure class="image">  <img alt="" height="490" src="https://img-blog.csdnimg.cn/0a7650b957644b17a47e13981f7f510d.png" width="1200">  <figcaption>   CIFAR10 对应的真实类别  </figcaption> </figure> <p>怎么找到？</p> <p><img alt="" height="1200" src="https://img-blog.csdnimg.cn/1f6e7785ca18474798b8741b9e756057.png" width="1200"></p> <p>第六类对应的是 frog（青蛙）</p> <p>---------------------------------------------------------------------------------------------------------------------------------</p> <p>预测错误的原因可能是训练次数不够多，在 Google Colab 里，将训练轮数 epoch 改为 30 次，完整代码<strong><span style="color:#ff9900;">（train.py）</span></strong>：</p> <pre data-index="188" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln hundred" style="width:1198px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.datasets</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># from model import *</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> time  <span class="hljs-comment"># time这个package是用来计时的</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 准备数据集，CIFAR10 数据集是PIL Image，要转换为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">device = torch.device(<span class="hljs-string">"cuda"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">True</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data = torchvision.datasets.CIFAR10(root=<span class="hljs-string">"../data"</span>,train=<span class="hljs-literal">False</span>,transform=torchvision.transforms.ToTensor(),download=<span class="hljs-literal">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 看一下训练数据集和测试数据集都有多少张（如何获得数据集的长度）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_data_size = <span class="hljs-built_in">len</span>(train_data)   <span class="hljs-comment"># length 长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_data_size = <span class="hljs-built_in">len</span>(test_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如果train_data_size=10，那么打印出的字符串为：训练数据集的长度为：10</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"训练数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(train_data_size))   <span class="hljs-comment"># 字符串格式化，把format中的变量替换&#123;&#125;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(<span class="hljs-string">"测试数据集的长度为：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(test_data_size))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 利用 DataLoader 来加载数据集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">train_dataloader = DataLoader(train_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">test_dataloader = DataLoader(test_data,batch_size=<span class="hljs-number">64</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 搭建神经网络（10分类网络）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 把网络放到序列中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>), <span class="hljs-comment">#输入是32x32的，输出还是32x32的（padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),  <span class="hljs-comment">#输入输出都是16x16的（同理padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Flatten(),   <span class="hljs-comment"># 展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>,out_features=<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>,out_features=<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui = Tudui()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">tudui.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 创建损失函数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn = nn.CrossEntropyLoss()   <span class="hljs-comment"># 分类问题可以用交叉熵</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">loss_fn.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 定义优化器</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">learning_rate = <span class="hljs-number">0.01</span>   <span class="hljs-comment"># 另一写法：1e-2，即1x 10^(-2)=0.01</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)   <span class="hljs-comment"># SGD 随机梯度下降</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 设置训练网络的一些参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_train_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录训练次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">total_test_step = <span class="hljs-number">0</span>  <span class="hljs-comment"># 记录测试次数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">epoch = <span class="hljs-number">30</span>   <span class="hljs-comment"># 训练轮数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 添加tensorboard</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer = SummaryWriter(<span class="hljs-string">"../logs_train"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">start_time = time.time()  <span class="hljs-comment"># 记录下此时的时间，赋值给开始时间</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">"----------第&#123;&#125;轮训练开始-----------"</span>.<span class="hljs-built_in">format</span>(i+<span class="hljs-number">1</span>))  <span class="hljs-comment"># i从0-9</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 训练步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tudui.train()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        imgs = imgs.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        targets = targets.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss = loss_fn(outputs,targets)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 优化器优化模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="81"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.zero_grad()    <span class="hljs-comment"># 首先要梯度清零</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="82"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        loss.backward()  <span class="hljs-comment"># 反向传播得到每一个参数节点的梯度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="83"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        optimizer.step()   <span class="hljs-comment"># 对参数进行优化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="84"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_train_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="85"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> ==<span class="hljs-number">0</span>:  <span class="hljs-comment"># 逢百才打印记录</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="86"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            end_time = time.time()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="87"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(end_time - start_time)  <span class="hljs-comment"># 第一次训练100次所花费的时间</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="88"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">"训练次数：&#123;&#125;,loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_train_step,loss.item()))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="89"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            writer.add_scalar(<span class="hljs-string">"train_loss"</span>,loss.item(),total_train_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="90"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="91"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 测试步骤开始</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="92"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tudui.<span class="hljs-built_in">eval</span>()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="93"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_test_loss = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="94"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_accuracy = <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="95"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">with</span> torch.no_grad():  <span class="hljs-comment"># 无梯度，不进行调优</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="96"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="97"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs,targets = data</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="98"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            imgs = imgs.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="99"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            targets = targets.to(device)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="100"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            outputs = tudui(imgs)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="101"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            loss = loss_fn(outputs,targets)  <span class="hljs-comment"># 该loss为部分数据在网络模型上的损失，为tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="102"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-comment"># 求整体测试数据集上的误差或正确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="103"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_test_loss = total_test_loss + loss.item()  <span class="hljs-comment"># loss为tensor数据类型，而total_test_loss为普通数字</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="104"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># 1：横向比较，==：True或False，sum：计算True或False个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="105"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_accuracy = total_accuracy + accuracy</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="106"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的Loss：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_test_loss))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="107"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"整体测试集上的正确率：&#123;&#125;"</span>.<span class="hljs-built_in">format</span>(total_accuracy/test_data_size))  <span class="hljs-comment"># 正确率为预测对的个数除以测试集长度</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="108"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        writer.add_scalar(<span class="hljs-string">"test_loss"</span>,total_test_loss,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="109"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        writer.add_scalar(<span class="hljs-string">"test_accuracy"</span>,total_test_loss,total_test_step,total_test_step)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="110"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        total_test_step += <span class="hljs-number">1</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="111"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="112"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        torch.save(tudui,<span class="hljs-string">"tudui_&#123;&#125;_gpu.pth"</span>.<span class="hljs-built_in">format</span>(i))  <span class="hljs-comment"># 每一轮保存一个结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="113"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">"模型已保存"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="114"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="115"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">writer.close()</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <p><img alt="" height="346" src="https://img-blog.csdnimg.cn/2001e79fedb3412d8c6e3d2ab70a45ae.png" width="300"></p> <p><img alt="" height="579" src="https://img-blog.csdnimg.cn/0c70c973ee0749dd889be52b17a8ced9.png" width="300"></p> <p>下载后复制到 PyCharm 中 Learn_Torch 的 src 文件夹下，然后将之前 test.py 中的路径修改为：</p> <pre data-index="189"><code class="language-python hljs">model = torch.load(<span class="hljs-string">"tudui_29_gpu.pth"</span>)</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行后报错，报错提示：</p> <pre data-index="190"><code class="hljs language-haskell"><span class="hljs-type">RuntimeError</span>: <span class="hljs-type">Input</span> <span class="hljs-class"><span class="hljs-keyword">type</span> (<span class="hljs-title">torch</span>.<span class="hljs-type">FloatTensor</span>) and weight <span class="hljs-keyword">type</span> (<span class="hljs-title">torch</span>.<span class="hljs-title">cuda</span>.<span class="hljs-type">FloatTensor</span>) should be the same or input should be a <span class="hljs-type">MKLDNN</span> tensor and weight is a dense tensor</span></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><strong>原因：</strong>采用GPU训练的模型，在CPU上加载，要从GPU上映射到CPU上<strong><span style="color:#fe2c24;">（在不同环境中加载已经训练好的模型，需要经过映射）</span></strong></p> <p><strong>解决：</strong></p> <pre data-index="191"><code class="language-python hljs">model = torch.load(<span class="hljs-string">"tudui_29_gpu.pth"</span>,map_location=torch.device(<span class="hljs-string">'cpu'</span>))</code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="test.py%EF%BC%88%E6%8A%8A%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E8%BF%90%E7%94%A8%E5%88%B0%E5%AE%9E%E9%99%85%E7%8E%AF%E5%A2%83%E4%B8%AD%EF%BC%89%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><a name="t161"></a><span style="color:#ff9900;"><strong>test.py（把训练模型运用到实际环境中）</strong></span>完整代码</h3> <pre data-index="192" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1192px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如何从test.py文件去找到dog文件（相对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path = <span class="hljs-string">"../imgs/airplane.png"</span>  <span class="hljs-comment"># 或右键-&gt; Copy Path-&gt; Absolute Path（绝对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 读取图片（PIL Image），再用ToTensor进行转换</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = Image.<span class="hljs-built_in">open</span>(image_path)  <span class="hljs-comment"># 现在的image是PIL类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image)  <span class="hljs-comment"># &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=430x247 at 0x1DF29D33AF0&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># image = image.convert('RGB')</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 因为png格式是四通道，除了RGB三通道外，还有一个透明度通道，所以要调用上述语句保留其颜色通道</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 当然，如果图片本来就是三颜色通道，经过此操作，不变</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加上这一步后，可以适应 png jpg 各种格式的图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 该image大小为430x247，网络模型的输入只能是32x32，进行一个Resize()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Compose()：把transforms几个变换联立在一起</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)),  <span class="hljs-comment"># 32x32大小的PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                                            torchvision.transforms.ToTensor()])  <span class="hljs-comment"># 转为Tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = transform(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image.shape)  <span class="hljs-comment"># torch.Size([3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载网络模型（之前采用的是第一种方式保存，故需要采用第一种方式加载）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 首先搭建神经网络（10分类网络）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 把网络放到序列中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>), <span class="hljs-comment">#输入是32x32的，输出还是32x32的（padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),  <span class="hljs-comment">#输入输出都是16x16的（同理padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Flatten(),   <span class="hljs-comment"># 展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>,out_features=<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>,out_features=<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 然后加载网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"tudui_29_gpu.pth"</span>,map_location=torch.device(<span class="hljs-string">'cpu'</span>))  <span class="hljs-comment"># 因为test.py和tudui_0.pth在同一个层级下，所以地址可以直接写</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = torch.reshape(image,(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 模型转化为测试类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">with</span> torch.no_grad():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = model(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output.argmax(<span class="hljs-number">1</span>))</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="%E7%A4%BA%E4%BE%8B%E4%BA%8C"><a name="t162"></a>示例二</h2> <p>再以飞机的图片为例（airplane.png 保存在 imgs 文件夹里）</p> <pre data-index="193" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1192px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 如何从test.py文件去找到dog文件（相对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torch</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> torchvision.transforms</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image_path = <span class="hljs-string">"../imgs/airplane.png"</span>  <span class="hljs-comment"># 或右键-&gt; Copy Path-&gt; Absolute Path（绝对路径）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 读取图片（PIL Image），再用ToTensor进行转换</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = Image.<span class="hljs-built_in">open</span>(image_path)  <span class="hljs-comment"># 现在的image是PIL类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image)  <span class="hljs-comment"># &lt;PIL.PngImagePlugin.PngImageFile image mode=RGB size=430x247 at 0x1DF29D33AF0&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># image = image.convert('RGB')</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 因为png格式是四通道，除了RGB三通道外，还有一个透明度通道，所以要调用上述语句保留其颜色通道</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 当然，如果图片本来就是三颜色通道，经过此操作，不变</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加上这一步后，可以适应 png jpg 各种格式的图片</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 该image大小为430x247，网络模型的输入只能是32x32，进行一个Resize()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># Compose()：把transforms几个变换联立在一起</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="hljs-number">32</span>,<span class="hljs-number">32</span>)),  <span class="hljs-comment"># 32x32大小的PIL Image</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                                            torchvision.transforms.ToTensor()])  <span class="hljs-comment"># 转为Tensor数据类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = transform(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(image.shape)  <span class="hljs-comment"># torch.Size([3, 32, 32])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 加载网络模型（之前采用的是第一种方式保存，故需要采用第一种方式加载）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 首先搭建神经网络（10分类网络）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Tudui</span>(nn.Module):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">super</span>(Tudui, self).__init__()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># 把网络放到序列中</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.model = nn.Sequential(</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">3</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>), <span class="hljs-comment">#输入是32x32的，输出还是32x32的（padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">32</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),  <span class="hljs-comment">#输入输出都是16x16的（同理padding经计算为2）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Conv2d(in_channels=<span class="hljs-number">32</span>,out_channels=<span class="hljs-number">64</span>,kernel_size=<span class="hljs-number">5</span>,stride=<span class="hljs-number">1</span>,padding=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Flatten(),   <span class="hljs-comment"># 展平</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>,out_features=<span class="hljs-number">64</span>),</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            nn.Linear(in_features=<span class="hljs-number">64</span>,out_features=<span class="hljs-number">10</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        )</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        x = self.model(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> x</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 然后加载网络模型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model = torch.load(<span class="hljs-string">"tudui_29_gpu.pth"</span>,map_location=torch.device(<span class="hljs-string">'cpu'</span>))  <span class="hljs-comment"># 因为test.py和tudui_0.pth在同一个层级下，所以地址可以直接写</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(model)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">image = torch.reshape(image,(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">32</span>,<span class="hljs-number">32</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 模型转化为测试类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">with</span> torch.no_grad():</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    output = model(image)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-built_in">print</span>(output.argmax(<span class="hljs-number">1</span>))  <span class="hljs-comment"># 把输出转换为一种利于解读的方式</span></div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>运行结果：</p> <p><img alt="" height="424" src="https://img-blog.csdnimg.cn/2ea4c904654941ccbf12b40568df4d0b.png" width="1200"></p> <p>第 0 类就是 airplane，预测正确&nbsp;</p> <p>注意：</p> <pre data-index="194"><code class="language-python hljs"><ol class="hljs-ln" style="width:100%"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">model.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 模型转化为测试类型</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">with</span> torch.no_grad():</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p>这两行不写也可以，但为了养成良好的代码习惯，最好写上。如果网络模型中正好有 Dropout 或 BatchNorm 时，不写的话预测就会有问题</p> <hr> <h1 id="26.%20%E7%9C%8B%E7%9C%8B%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE"><a name="t163"></a>26. 看看开源项目</h1> <p><img alt="" height="912" src="https://img-blog.csdnimg.cn/8ea1ad9ff3cf41b5b8161075bc366f7b.png" width="1200"></p> <p><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" title="GitHub - junyanz/pytorch-CycleGAN-and-pix2pix: Image-to-Image Translation in PyTorch">GitHub - junyanz/pytorch-CycleGAN-and-pix2pix: Image-to-Image Translation in PyTorch</a></p> <h2 id="README.md%C2%A0"><a name="t164"></a>README.md&nbsp;</h2> <p>先读 README.md（怎么安装、注意事项）</p> <p><img alt="" height="1189" src="https://img-blog.csdnimg.cn/7b60fb7a6b3248adbd9ec7b7352f4b19.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h2 id="train.py"><a name="t165"></a>train.py</h2> <pre data-index="195" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1642px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"><span class="hljs-string">"""General-purpose training script for image-to-image translation.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">This script works for various models (with option '--model': e.g., pix2pix, cyclegan, colorization) and</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">different datasets (with option '--dataset_mode': e.g., aligned, unaligned, single, colorization).</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">You need to specify the dataset ('--dataroot'), experiment name ('--name'), and model ('--model').</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">It first creates model, dataset, and visualizer given the option.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">It then does standard network training. During the training, it also visualize/save the images, print/save the loss plot, and save models.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">The script supports continue/resume training. Use '--continue_train' to resume your previous training.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">Example:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Train a CycleGAN model:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        python train.py --dataroot ./datasets/maps --name maps_cyclegan --model cycle_gan</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    Train a pix2pix model:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">        python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">See options/base_options.py and options/train_options.py for more training options.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">See training and test tips at: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/tips.md</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">See frequently asked questions at: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/qa.md</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">"""</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">import</span> time</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> options.train_options <span class="hljs-keyword">import</span> TrainOptions</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> data <span class="hljs-keyword">import</span> create_dataset</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> models <span class="hljs-keyword">import</span> create_model</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> util.visualizer <span class="hljs-keyword">import</span> Visualizer</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    opt = TrainOptions().parse()   <span class="hljs-comment"># get training options</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dataset = create_dataset(opt)  <span class="hljs-comment"># create a dataset given opt.dataset_mode and other options</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dataset_size = <span class="hljs-built_in">len</span>(dataset)    <span class="hljs-comment"># get the number of images in the dataset.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-built_in">print</span>(<span class="hljs-string">'The number of training images = %d'</span> % dataset_size)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    model = create_model(opt)      <span class="hljs-comment"># create a model given opt.model and other options</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    model.setup(opt)               <span class="hljs-comment"># regular setup: load and print networks; create schedulers</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    visualizer = Visualizer(opt)   <span class="hljs-comment"># create a visualizer that display/save images and plots</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    total_iters = <span class="hljs-number">0</span>                <span class="hljs-comment"># the total number of training iterations</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + <span class="hljs-number">1</span>):    <span class="hljs-comment"># outer loop for different epochs; we save the model by &lt;epoch_count&gt;, &lt;epoch_count&gt;+&lt;save_latest_freq&gt;</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        epoch_start_time = time.time()  <span class="hljs-comment"># timer for entire epoch</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        iter_data_time = time.time()    <span class="hljs-comment"># timer for data loading per iteration</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        epoch_iter = <span class="hljs-number">0</span>                  <span class="hljs-comment"># the number of training iterations in current epoch, reset to 0 every epoch</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        visualizer.reset()              <span class="hljs-comment"># reset the visualizer: make sure it saves the results to HTML at least once every epoch</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        model.update_learning_rate()    <span class="hljs-comment"># update learning rates in the beginning of every epoch.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataset):  <span class="hljs-comment"># inner loop within one epoch</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            iter_start_time = time.time()  <span class="hljs-comment"># timer for computation per iteration</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> total_iters % opt.print_freq == <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                t_data = iter_start_time - iter_data_time</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            total_iters += opt.batch_size</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            epoch_iter += opt.batch_size</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            model.set_input(data)         <span class="hljs-comment"># unpack data from dataset and apply preprocessing</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            model.optimize_parameters()   <span class="hljs-comment"># calculate loss functions, get gradients, update network weights</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> total_iters % opt.display_freq == <span class="hljs-number">0</span>:   <span class="hljs-comment"># display images on visdom and save images to a HTML file</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                save_result = total_iters % opt.update_html_freq == <span class="hljs-number">0</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                model.compute_visuals()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                visualizer.display_current_results(model.get_current_visuals(), epoch, save_result)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> total_iters % opt.print_freq == <span class="hljs-number">0</span>:    <span class="hljs-comment"># print training losses and save logging information to the disk</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                losses = model.get_current_losses()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                t_comp = (time.time() - iter_start_time) / opt.batch_size</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                visualizer.print_current_losses(epoch, epoch_iter, losses, t_comp, t_data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-keyword">if</span> opt.display_id &gt; <span class="hljs-number">0</span>:</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                    visualizer.plot_current_losses(epoch, <span class="hljs-built_in">float</span>(epoch_iter) / dataset_size, losses)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-keyword">if</span> total_iters % opt.save_latest_freq == <span class="hljs-number">0</span>:   <span class="hljs-comment"># cache our latest model every &lt;save_latest_freq&gt; iterations</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                <span class="hljs-built_in">print</span>(<span class="hljs-string">'saving the latest model (epoch %d, total_iters %d)'</span> % (epoch, total_iters))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                save_suffix = <span class="hljs-string">'iter_%d'</span> % total_iters <span class="hljs-keyword">if</span> opt.save_by_iter <span class="hljs-keyword">else</span> <span class="hljs-string">'latest'</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">                model.save_networks(save_suffix)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            iter_data_time = time.time()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">if</span> epoch % opt.save_epoch_freq == <span class="hljs-number">0</span>:              <span class="hljs-comment"># cache our model every &lt;save_epoch_freq&gt; epochs</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            <span class="hljs-built_in">print</span>(<span class="hljs-string">'saving the model at the end of epoch %d, iters %d'</span> % (epoch, total_iters))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            model.save_networks(<span class="hljs-string">'latest'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">            model.save_networks(epoch)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-built_in">print</span>(<span class="hljs-string">'End of epoch %d / %d \t Time Taken: %d sec'</span> % (epoch, opt.n_epochs + opt.n_epochs_decay, time.time() - epoch_start_time))</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="1200" src="https://img-blog.csdnimg.cn/56e93735f1aa4550bb6b28e8ec47eb14.png" width="1200"></p> <p>--------------------------------------------------------------------------------------------------------------------------------&nbsp;</p> <h3 id="%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE"><a name="t166"></a>训练参数设置</h3> <p><img alt="" height="257" src="https://img-blog.csdnimg.cn/95d71993ac4242a88f2469adaec8584e.png" width="500"></p> <pre data-index="196" class="set-code-hide" name="code"><code class="language-python hljs"><ol class="hljs-ln" style="width:1844px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> .base_options <span class="hljs-keyword">import</span> BaseOptions</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TrainOptions</span>(<span class="hljs-title class_ inherited__">BaseOptions</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""This class includes training options.</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string"></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    It also includes shared options defined in BaseOptions.</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">def</span> <span class="hljs-title function_">initialize</span>(<span class="hljs-params">self, parser</span>):</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser = BaseOptions.initialize(self, parser)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># visdom and HTML visualization parameters</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_freq'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">400</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'frequency of showing training results on screen'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_ncols'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">4</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'if positive, display all images in a single visdom web panel with certain number of images per row.'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_id'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'window id of the web display'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_server'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">"http://localhost"</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'visdom server of the web display'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_env'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'main'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'visdom display environment name (default is "main")'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--display_port'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">8097</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'visdom port of the web display'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--update_html_freq'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1000</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'frequency of saving training results to html'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--print_freq'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'frequency of showing training results on console'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--no_html'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># network saving and loading parameters</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--save_latest_freq'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">5000</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'frequency of saving the latest results'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--save_epoch_freq'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">5</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'frequency of saving checkpoints at the end of epochs'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--save_by_iter'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'whether saves model by iteration'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--continue_train'</span>, action=<span class="hljs-string">'store_true'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'continue training: load the latest model'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--epoch_count'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'the starting epoch count, we save the model by &lt;epoch_count&gt;, &lt;epoch_count&gt;+&lt;save_latest_freq&gt;, ...'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--phase'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'train'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'train, val, test, etc'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-comment"># training parameters</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--n_epochs'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'number of epochs with the initial learning rate'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--n_epochs_decay'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'number of epochs to linearly decay learning rate to zero'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--beta1'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.5</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'momentum term of adam'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--lr'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.0002</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'initial learning rate for adam'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--gan_mode'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'lsgan'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--pool_size'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">50</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'the size of image buffer that stores previously generated images'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--lr_policy'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">'linear'</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'learning rate policy. [linear | step | plateau | cosine]'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        parser.add_argument(<span class="hljs-string">'--lr_decay_iters'</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">50</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">'multiply by a gamma every lr_decay_iters iterations'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        self.isTrain = <span class="hljs-literal">True</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">        <span class="hljs-keyword">return</span> parser</div></div></li></ol></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre> <p><img alt="" height="1196" src="https://img-blog.csdnimg.cn/4b8217f091a149a093c5256b10f57877.png" width="1200"></p> <p>没有dataroot&nbsp;</p> <p><img alt="" height="538" src="https://img-blog.csdnimg.cn/ddc5cd7e86df44298ed9e8c37c4d5c11.png" width="1200"></p> <p>点进其继承的父类查看，可以看到有dataroot&nbsp;</p> <p><img alt="" height="627" src="https://img-blog.csdnimg.cn/11bd3503dcc54d709e23356af9665c7a.png" width="1200"></p> <p><span style="color:#fe2c24;"><strong>下载代码用 PyCharm 打开后，查看代码里有没有 required=True，若有，删掉 required=True ，加一个默认值 default="./dataset/maps" ，就可以在 PyCharm 里右键运行了</strong></span></p> <p>即找到所有 required=True 的参数，将它删去并添加上默认值default&nbsp;</p>                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_43629945/article/details/122767670&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>        </div>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch完整笔记</title>
    <link href="/2023/08/09/PyTorch%E5%AE%8C%E6%95%B4%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/08/09/PyTorch%E5%AE%8C%E6%95%B4%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<div id="article_content" class="article_content clearfix">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css">        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-25cebea3f9.css">                <div id="content_views" class="markdown_views prism-atom-one-dark">                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>                    </svg>                    <p></p> <div class="toc">  <h3><a name="t0"></a>文章目录</h3>  <ul><li><a href="#PyTorch_8" target="_self">一、PyTorch环境的配置及安装</a></li><li><a href="#Pycharmjupyter_45" target="_self">二、Pycharm、jupyter的安装</a></li><li><ul><li><a href="#1_Pycharm_46" target="_self">1. Pycharm</a></li><li><a href="#2jupyter_51" target="_self">2.jupyter</a></li></ul>   </li><li><a href="#Pythonhelpdir_60" target="_self">三、Python学习中的两大法宝函数（help、dir）</a></li><li><a href="#Dataset_65" target="_self">四、加载数据（Dataset）</a></li><li><a href="#TensorBorad_141" target="_self">五、TensorBorad的使用</a></li><li><a href="#Transformer_147" target="_self">六、Transformer</a></li><li><ul><li><a href="#1compose_153" target="_self">1.compose</a></li><li><a href="#2toTensor_155" target="_self">2.toTensor</a></li><li><a href="#3Normalize_161" target="_self">3.Normalize</a></li><li><a href="#4Resize_164" target="_self">4.Resize</a></li></ul>   </li><li><a href="#torchvision_167" target="_self">七、torchvision中数据集的使用</a></li><li><ul><li><a href="#1torchvisiondatasets_180" target="_self">1.torchvision.datasets</a></li></ul>   </li><li><a href="#dataloader_183" target="_self">八、dataloader</a></li><li><ul><li><a href="#nnmodule_187" target="_self">九、nn.module</a></li><li><a href="#_189" target="_self">十、卷积操作</a></li></ul>   </li><li><a href="#_192" target="_self">十一、卷积层</a></li><li><a href="#_234" target="_self">十二、池化层</a></li><li><a href="#_273" target="_self">十三、非线性激活</a></li><li><a href="#_310" target="_self">十四、线性层</a></li><li><a href="#Sequential_343" target="_self">十五、Sequential</a></li><li><a href="#_381" target="_self">十六、损失函数和反向传播</a></li><li><ul><li><a href="#1_383" target="_self">1.损失函数</a></li><li><a href="#2_424" target="_self">2.反向传播及优化</a></li></ul>   </li><li><a href="#_474" target="_self">十七、现有模型的使用及修改</a></li><li><a href="#_498" target="_self">十八、网络模型的保存和修改</a></li><li><ul><li><a href="#1_501" target="_self">1.保存</a></li><li><a href="#2_527" target="_self">2.读取</a></li></ul>   </li><li><a href="#_560" target="_self">十九、完整的模型训练套路</a></li><li><a href="#GPU_656" target="_self">二十、利用GPU训练</a></li><li><a href="#_784" target="_self">二十一、完整的模型验证套路</a></li><li><a href="#_839" target="_self">总结</a></li></ul> </div> <p></p> <hr> <h1><a name="t1"></a><a id="PyTorch_8"></a>一、PyTorch环境的配置及安装</h1> <p>1.官网下载最新版Anaconda，完成后打开Anaconda Prompt，显示（base）即安装成功<br> 2.<code>conda create -n pytorch python=3.6</code>建立一个命名为pytorch的环境，且环境python版本为3.6<br> 3.<code>conda activate pytorch</code>激活并进入pytorch这个环境;linux：source activate pytorch<br> 4.<code>pip list</code>来查看环境内安装了哪些包，可以发现并没有我们需要的pytorch<br> 5.打开<a href="https://pytorch.org/get-started/locally/">PyTorch官网</a>，直接找到最新版pytorch指令<code>conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch</code>（无脑最新版就完事了。。。。老版本调了半天，最后还出问题了），打开pytorch环境，输入指令下载安装<br> 6.检验是否安装成功。输入<code>python</code>，<code>import torch</code>不报错即pytorch安装成功。输入<code>torch.cuda.is_available()</code>,若返回True即机器显卡是可以被pytorch使用的（如失败，建议去英伟达官网下载更新驱动程序，并删除环境，使用各种最新版重新安装）。<br> 7.linux服务器安装时出现环境安装不到conda/envs下，而在.conda下，进行如下操作<br> <img src="https://img-blog.csdnimg.cn/c7279fe414a24eb3a9967587c182d943.png" alt="在这里插入图片描述"></p> <p>other:conda info -e （查看所有的虚拟环境）</p> <p>删除环境：<br> 第一步：首先退出环境<br> conda deactivate<br> 第二步：删除环境<br> conda remove -n 需要删除的环境名 --all</p> <p>rm -rf + 文件名 删除文件夹<br> df -h查看linux系统各分区的情况<br> nohup 命令 &gt; 文件 2&gt;&amp;1 &amp; # 使模型在后台训练 exit退出黑窗口<br> 1.&gt; 会重写文件，如果文件里面有内容会覆盖，没有则创建并写入。<br> 2.&gt;&gt; 将内容追加到文件中，即如果文件里面有内容会把新内容追加到文件尾，如果文件不存在，就创建文件<br> kill -9 PID # 关闭特定进程<br> tar -xvf #解压tar包<br> 查看当前文件夹的大小：du -ah<br> 查看当前文件夹下面各个文件夹的大小：du -ah --max-depth=1<br> anaconda下的pkgs怎么清理:conda clean -a<br> ps u pid 查询显卡谁在使用<br> sudo chmod -R 777 myResources 修改文件的权限为所有用户拥有最高权限<br> pip install *** -i https://pypi.tuna.tsinghua.edu.cn/simple 镜像加速安装<br> ps -f -p 26359 可以看到进程26359在跑训练<br> cp -r /TEST/test1 /TEST/test2 复制文件夹<br> Defaulting to user installation because normal site-packages is not writeable ： python3 -m pip install requests</p> <p>fuser -v /dev/nvidia* nvidia-smi 无进程占用GPU，但GPU显存却被占用了</p> <h1><a name="t2"></a><a id="Pycharmjupyter_45"></a>二、Pycharm、jupyter的安装</h1> <h2><a name="t3"></a><a id="1_Pycharm_46"></a>1. Pycharm</h2> <p>1.pycharm官网下载安装<br> 2.新建项目（lean_pytorch)，<img src="https://img-blog.csdnimg.cn/c7bffcba67174cf198d1442add8312c0.png" alt="在这里插入图片描述"><br> 点击已存在的编译器，点进去寻找刚刚我们安装好的环境。<img src="https://img-blog.csdnimg.cn/05a505d8963f4e57b74aa693cd57c06e.png" alt="在这里插入图片描述"><br> 导入成功。</p> <h2><a name="t4"></a><a id="2jupyter_51"></a>2.jupyter</h2> <ol><li>安装好anaconda后无需再次安装。</li><li>jupyter默认安装在base环境中，所以我们需要在pytorch环境中安装jupyter.</li><li>进入pytorch环境，输入<code>conda install nb_conda</code>安装juypter</li><li>安装完成后输入<code>juypter notebook</code>即可打开。</li><li><img src="https://img-blog.csdnimg.cn/0f2a577be008433dbeac3c203534d8ba.png" alt="在这里插入图片描述"><br> 新建pytorch环境下的juypter文件。</li><li>输入<code>import torch</code>,<code>torch.cuda.is_available()</code>，返回TRUE即安装成功。</li></ol> <h1><a name="t5"></a><a id="Pythonhelpdir_60"></a>三、Python学习中的两大法宝函数（help、dir）</h1> <p><img src="https://img-blog.csdnimg.cn/373021fd58014914b34a8c2d12531bd8.png" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/5a9f2228b0b54ee9bd2b3c9d70febe4c.png" alt="在这里插入图片描述"><br> 进入pycharm的python console，输入dir(torch),dir(torch.cuda),dir(torch.cuda.is_available()),help(torch.cuda.is_available)。</p> <h1><a name="t6"></a><a id="Dataset_65"></a>四、加载数据（Dataset）</h1> <p><img src="https://img-blog.csdnimg.cn/a9135ddaa79746888eb0932a4f39f95b.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/aef53b761331401e93b9ff49da43ff94.png" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/1b158f209c324ad4a0583e0168bf760d.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/efda402c39504573b27164a750a75bf3.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/3798da530cf44f43baf465480cd2d66e.png" alt="在这里插入图片描述"></p> <pre data-index="0" class="set-code-hide prettyprint"><code class="has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;">from torch.utils.data import Dataset, DataLoaderimport numpy as npfrom PIL import Imageimport osfrom torchvision import transformsfrom torch.utils.tensorboard import SummaryWriterfrom torchvision.utils import make_grid<p>writer &#x3D; SummaryWriter(“logs”)</p><p>class MyData(Dataset):</p><pre><code class="hljs">def __init__(self, root_dir, image_dir, label_dir, transform):    self.root_dir = root_dir    self.image_dir = image_dir    self.label_dir = label_dir    self.label_path = os.path.join(self.root_dir, self.label_dir)    self.image_path = os.path.join(self.root_dir, self.image_dir)    self.image_list = os.listdir(self.image_path)    self.label_list = os.listdir(self.label_path)    self.transform = transform    # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的    self.image_list.sort()    self.label_list.sort()def __getitem__(self, idx):    img_name = self.image_list[idx]    label_name = self.label_list[idx]    img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)    label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)    img = Image.open(img_item_path)    with open(label_item_path, &#39;r&#39;) as f:        label = f.readline()    # img = np.array(img)    img = self.transform(img)    sample = &#123;&#39;img&#39;: img, &#39;label&#39;: label&#125;    return sampledef __len__(self):    assert len(self.image_list) == len(self.label_list)    return len(self.image_list)</code></pre><p>if <strong>name</strong> &#x3D;&#x3D; ‘<strong>main</strong>‘:<br>    transform &#x3D; transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])<br>    root_dir &#x3D; “dataset&#x2F;train”<br>    image_ants &#x3D; “ants_image”<br>    label_ants &#x3D; “ants_label”<br>    ants_dataset &#x3D; MyData(root_dir, image_ants, label_ants, transform)<br>    image_bees &#x3D; “bees_image”<br>    label_bees &#x3D; “bees_label”<br>    bees_dataset &#x3D; MyData(root_dir, image_bees, label_bees, transform)<br>    train_dataset &#x3D; ants_dataset + bees_dataset</p><pre><code class="hljs"># transforms = transforms.Compose([transforms.Resize(256, 256)])dataloader = DataLoader(train_dataset, batch_size=1, num_workers=2)writer.add_image(&#39;error&#39;, train_dataset[119][&#39;img&#39;])writer.close()# for i, j in enumerate(dataloader):#     # imgs, labels = j#     print(type(j))#     print(i, j[&#39;img&#39;].shape)#     # writer.add_image(&quot;train_data_b2&quot;, make_grid(j[&#39;img&#39;]), i)## writer.close()</code></pre><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li style="color: rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li style="color: rgb(153, 153, 153);">67</li></ul></pre> <h1><a name="t7"></a><a id="TensorBorad_141"></a>五、TensorBorad的使用</h1> <p>安装tensorborad:pip install tensorboard<br> <img src="https://img-blog.csdnimg.cn/56359c84655541d8a39f15be7a33c38b.png" alt="在这里插入图片描述"><br> 更改端口：<br> <img src="https://img-blog.csdnimg.cn/74e3a450a61e45eb97f8bbba49fd016b.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/f574b2d5d4794b3ca4475c20f2268954.png" alt="在这里插入图片描述"></p> <h1><a name="t8"></a><a id="Transformer_147"></a>六、Transformer</h1> <p><img src="https://img-blog.csdnimg.cn/92414a402a0449918da45cb1c8f231c6.png" alt="在这里插入图片描述"></p> <p><img src="https://img-blog.csdnimg.cn/fda4b62c305b4806bb552197955a0461.png" alt="在这里插入图片描述"></p> <p>进入structure</p> <h2><a name="t9"></a><a id="1compose_153"></a>1.compose</h2> <p>将几个步骤合为一个</p> <h2><a name="t10"></a><a id="2toTensor_155"></a>2.toTensor</h2> <p>将PIL和numpy类型的图片转为Tensor（可用于训练）<br> <img src="https://img-blog.csdnimg.cn/e6ef9d73fbaf40599ff9e156e899d28f.png" alt="在这里插入图片描述"></p> <p>__call__的使用：<img src="https://img-blog.csdnimg.cn/f045b0e65be04acfa339fb2cf330e31c.png" alt="在这里插入图片描述"><br> ctrl+p提示函数参数</p> <h2><a name="t11"></a><a id="3Normalize_161"></a>3.Normalize</h2> <p>讲一个tensor类型进行归一化<br> <img src="https://img-blog.csdnimg.cn/015068e480e54059ab49df4b2ff87d11.png" alt="在这里插入图片描述"></p> <h2><a name="t12"></a><a id="4Resize_164"></a>4.Resize</h2> <p><img src="https://img-blog.csdnimg.cn/69e573b9e902420b84a77ccda89b8d9b.png" alt="在这里插入图片描述"><br> tips:<img src="https://img-blog.csdnimg.cn/95daa6a6747c433ab3e5b478993b3ea3.png" alt="在这里插入图片描述"></p> <h1><a name="t13"></a><a id="torchvision_167"></a>七、<a href="https://so.csdn.net/so/search?q=torchvision&amp;spm=1001.2101.3001.7020" target="_blank" class="hl hl-1" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=torchvision&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;torchvision\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7020&quot;,&quot;dest&quot;:&quot;https://so.csdn.net/so/search?q=torchvision&amp;spm=1001.2101.3001.7020&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;torchvision\&quot;}&quot;}" data-tit="torchvision" data-pretit="torchvision">torchvision</a>中数据集的使用</h1> <p>torchvision 是PyTorch中专门用来处理图像的库。这个包中有四个大类。</p> <p>torchvision.datasets</p> <p>torchvision.models</p> <p>torchvision.transforms</p> <p>torchvision.utils</p> <p>这里主要介绍前三个。</p> <h2><a name="t14"></a><a id="1torchvisiondatasets_180"></a>1.torchvision.datasets</h2> <p><img src="https://img-blog.csdnimg.cn/86317b030cd043c3babd8a6e2363d3bd.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/47bd93730fc044e7b0f1d42ad8c89cb2.png" alt="在这里插入图片描述"></p> <h1><a name="t15"></a><a id="dataloader_183"></a>八、dataloader</h1> <p><img src="https://img-blog.csdnimg.cn/763cf5f7d09043f3b72f352c33118384.png" alt="在这里插入图片描述"><br> drop_last=true,舍去最后的余数图片，如上半张图片将会舍去，下半张图片为FALSE<br> <img src="https://img-blog.csdnimg.cn/77025205484340efb28f10bd2234a0ba.png" alt="在这里插入图片描述"></p> <h2><a name="t16"></a><a id="nnmodule_187"></a>九、nn.module</h2> <p><img src="https://img-blog.csdnimg.cn/0f840e1b8db74921942c13a91068c9a9.png" alt="在这里插入图片描述"></p> <h2><a name="t17"></a><a id="_189"></a>十、卷积操作</h2> <p><img src="https://img-blog.csdnimg.cn/56f18e9e64074c19b333bd3bafd120ee.png" alt="在这里插入图片描述"><br> <img src="https://img-blog.csdnimg.cn/deac499ac6ac4cfba2a0c66ee9f0c13a.png" alt="在这里插入图片描述"></p> <h1><a name="t18"></a><a id="_192"></a>十一、卷积层</h1> <pre data-index="1" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> Conv2dfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoaderfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">tensorboard</span> <span class="token keyword">import</span> SummaryWriter<p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                       download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span><br>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">conv1</span> <span class="token operator">&#x3D;</span> <span class="token function">Conv2d</span><span class="token punctuation">(</span>in_channels<span class="token operator">&#x3D;</span><span class="token number">3</span><span class="token punctuation">,</span> out_channels<span class="token operator">&#x3D;</span><span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">&#x3D;</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">&#x3D;</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">0</span><span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs”</span></span><span class="token punctuation">)</span></p><p>step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br>for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>    imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>    output <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>    <span class="token function">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span><br>    <span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span><br>    <span class="token comment"># torch.Size([64, 3, 32, 32])</span><br>    writer<span class="token punctuation">.</span><span class="token function">add_images</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“input”</span></span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span><br>    <span class="token comment"># torch.Size([64, 6, 30, 30])  -&gt; [xxx, 3, 30, 30]</span></p><pre><code class="hljs">output &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; torch&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;output&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_images&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;output&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; output&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;step &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; step &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;</code></pre><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li></ul></pre> <h1><a name="t19"></a><a id="_234"></a>十二、池化层</h1> <pre data-index="2" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> MaxPool2dfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoaderfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">tensorboard</span> <span class="token keyword">import</span> SummaryWriter<p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> download<span class="token operator">&#x3D;</span>True<span class="token punctuation">,</span><br>                                       transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><p>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">maxpool1</span> <span class="token operator">&#x3D;</span> <span class="token function">MaxPool2d</span><span class="token punctuation">(</span>kernel_size<span class="token operator">&#x3D;</span><span class="token number">3</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">&#x3D;</span>False<span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    output &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;maxpool1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return output</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs_maxpool”</span></span><span class="token punctuation">)</span><br>step <span class="token operator">&#x3D;</span> <span class="token number">0</span></p><p>for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>    imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>    writer<span class="token punctuation">.</span><span class="token function">add_images</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“input”</span></span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span><br>    output <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>    writer<span class="token punctuation">.</span><span class="token function">add_images</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“output”</span></span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span><br>    step <span class="token operator">&#x3D;</span> step <span class="token operator">+</span> <span class="token number">1</span></p><p>writer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li></ul></pre> <p><img src="https://img-blog.csdnimg.cn/788773addb0e4329aa30f321b7066e6e.png" alt="在这里插入图片描述"></p> <h1><a name="t20"></a><a id="_273"></a>十三、非线性激活</h1> <pre data-index="3" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;">input <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token function">tensor</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><p>input <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>input<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>input<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span></p><p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> download<span class="token operator">&#x3D;</span>True<span class="token punctuation">,</span><br>                                       transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><p>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">relu1</span> <span class="token operator">&#x3D;</span> <span class="token function">ReLU</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">sigmoid1</span> <span class="token operator">&#x3D;</span> <span class="token function">Sigmoid</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    output &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sigmoid1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return output</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs_relu”</span></span><span class="token punctuation">)</span><br>step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br>for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>    imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>    writer<span class="token punctuation">.</span><span class="token function">add_images</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“input”</span></span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> global_step<span class="token operator">&#x3D;</span>step<span class="token punctuation">)</span><br>    output <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>    writer<span class="token punctuation">.</span><span class="token function">add_images</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“output”</span></span><span class="token punctuation">,</span> output<span class="token punctuation">,</span> step<span class="token punctuation">)</span><br>    step <span class="token operator">+</span><span class="token operator">&#x3D;</span> <span class="token number">1</span></p><p>writer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li></ul></pre> <h1><a name="t21"></a><a id="_310"></a>十四、线性层</h1> <pre data-index="4" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> Linearfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoader<p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                       download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">linear1</span> <span class="token operator">&#x3D;</span> <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">196608</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    output &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;input&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return output</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p>for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>    imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>    <span class="token function">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span><br>    output <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">flatten</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>    <span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span><br>    output <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span><br>    <span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li></ul></pre> <h1><a name="t22"></a><a id="Sequential_343"></a>十五、Sequential</h1> <pre data-index="5" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequentialfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">tensorboard</span> <span class="token keyword">import</span> SummaryWriter<p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">model1</span> <span class="token operator">&#x3D;</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><br>        <span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>tudui<span class="token punctuation">)</span><br>input <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">ones</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br>output <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span></p><p>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs_seq”</span></span><span class="token punctuation">)</span><br>writer<span class="token punctuation">.</span><span class="token function">add_graph</span><span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> input<span class="token punctuation">)</span><br>writer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li></ul></pre> <h1><a name="t23"></a><a id="_381"></a>十六、损失函数和反向传播</h1> <h2><a name="t24"></a><a id="1_383"></a>1.损失函数</h2> <pre data-index="6" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linearfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoader<p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                       download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">1</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">model1</span> <span class="token operator">&#x3D;</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><br>        <span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>loss <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>    imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>    outputs <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>    result_loss <span class="token operator">&#x3D;</span> <span class="token function">loss</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><br>    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“ok”</span></span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li></ul></pre> <h2><a name="t25"></a><a id="2_424"></a>2.反向传播及优化</h2> <pre data-index="7" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nnfrom torch<span class="token punctuation">.</span><span class="token function">nn</span> <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linearfrom torch<span class="token punctuation">.</span><span class="token function">optim</span><span class="token punctuation">.</span><span class="token function">lr_scheduler</span> <span class="token keyword">import</span> StepLRfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoader<p>dataset <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span> transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                       download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p>dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">&#x3D;</span><span class="token number">1</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">model1</span> <span class="token operator">&#x3D;</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">&#x3D;</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            <span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><br>        <span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;model1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>loss <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>optim <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">optim</span><span class="token punctuation">.</span><span class="token function">SGD</span><span class="token punctuation">(</span>tudui<span class="token punctuation">.</span><span class="token function">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">&#x3D;</span><span class="token number">0.01</span><span class="token punctuation">)</span><br>scheduler <span class="token operator">&#x3D;</span> <span class="token function">StepLR</span><span class="token punctuation">(</span>optim<span class="token punctuation">,</span> step_size<span class="token operator">&#x3D;</span><span class="token number">5</span><span class="token punctuation">,</span> gamma<span class="token operator">&#x3D;</span><span class="token number">0.1</span><span class="token punctuation">)</span><br>for epoch <span class="token operator">in</span> <span class="token function">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    running_loss <span class="token operator">&#x3D;</span> <span class="token number">0.0</span><br>    for data <span class="token operator">in</span> dataloader<span class="token punctuation">:</span><br>        imgs<span class="token punctuation">,</span> targets <span class="token operator">&#x3D;</span> data<br>        outputs <span class="token operator">&#x3D;</span> <span class="token function">tudui</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><br>        result_loss <span class="token operator">&#x3D;</span> <span class="token function">loss</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><br>        optim<span class="token punctuation">.</span><span class="token function">zero_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        result_loss<span class="token punctuation">.</span><span class="token function">backward</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        scheduler<span class="token punctuation">.</span><span class="token function">step</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        running_loss <span class="token operator">&#x3D;</span> running_loss <span class="token operator">+</span> result_loss<br>    <span class="token function">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li></ul></pre> <h1><a name="t26"></a><a id="_474"></a>十七、现有模型的使用及修改</h1> <pre data-index="8" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchvision<p><span class="token comment"># train_data &#x3D; torchvision.datasets.ImageNet(“..&#x2F;data_image_net”, split&#x3D;’train’, download&#x3D;True,</span><br><span class="token comment">#                                            transform&#x3D;torchvision.transforms.ToTensor())</span><br>from torch <span class="token keyword">import</span> nn</p><p>vgg16_false <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">models</span><span class="token punctuation">.</span><span class="token function">vgg16</span><span class="token punctuation">(</span>pretrained<span class="token operator">&#x3D;</span>False<span class="token punctuation">)</span><br>vgg16_true <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">models</span><span class="token punctuation">.</span><span class="token function">vgg16</span><span class="token punctuation">(</span>pretrained<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p><span class="token function">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span></p><p>train_data <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span><span class="token string">‘..&#x2F;data’</span><span class="token punctuation">,</span> train<span class="token operator">&#x3D;</span>True<span class="token punctuation">,</span> transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                          download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p>vgg16_true<span class="token punctuation">.</span><span class="token function">classifier</span><span class="token punctuation">.</span><span class="token function">add_module</span><span class="token punctuation">(</span><span class="token string">‘add_linear’</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>vgg16_true<span class="token punctuation">)</span></p><p><span class="token function">print</span><span class="token punctuation">(</span>vgg16_false<span class="token punctuation">)</span><br>vgg16_false<span class="token punctuation">.</span><span class="token function">classifier</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span> <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>vgg16_false<span class="token punctuation">)</span></p><div class="hljs-button &#123;2&#125;" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li></ul></pre> <h1><a name="t27"></a><a id="_498"></a>十八、网络模型的保存和修改</h1> <h2><a name="t28"></a><a id="1_501"></a>1.保存</h2> <pre data-index="9" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nn<p>vgg16 <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">models</span><span class="token punctuation">.</span><span class="token function">vgg16</span><span class="token punctuation">(</span>pretrained<span class="token operator">&#x3D;</span>False<span class="token punctuation">)</span><br><span class="token comment"># 保存方式1,模型结构+模型参数</span><br>torch<span class="token punctuation">.</span><span class="token function">save</span><span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span> <span class="token string"><span class="token double-quoted">“vgg16_method1.pth”</span></span><span class="token punctuation">)</span></p><p><span class="token comment"># 保存方式2，模型参数（官方推荐）</span><br>torch<span class="token punctuation">.</span><span class="token function">save</span><span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span><span class="token function">state_dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string"><span class="token double-quoted">“vgg16_method2.pth”</span></span><span class="token punctuation">)</span></p><p><span class="token comment"># 陷阱</span><br><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">conv1</span> <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">&#x3D;</span><span class="token number">3</span><span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>torch<span class="token punctuation">.</span><span class="token function">save</span><span class="token punctuation">(</span>tudui<span class="token punctuation">,</span> <span class="token string"><span class="token double-quoted">“tudui_method1.pth”</span></span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li></ul></pre> <h2><a name="t29"></a><a id="2_527"></a>2.读取</h2> <pre data-index="10" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchfrom model_save <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment"># 方式1-》保存方式1，加载模型</span><span class="token keyword">import</span> torchvisionfrom torch <span class="token keyword">import</span> nn<p>model <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“vgg16_method1.pth”</span></span><span class="token punctuation">)</span><br><span class="token comment"># print(model)</span></p><p><span class="token comment"># 方式2，加载模型</span><br>vgg16 <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">models</span><span class="token punctuation">.</span><span class="token function">vgg16</span><span class="token punctuation">(</span>pretrained<span class="token operator">&#x3D;</span>False<span class="token punctuation">)</span><br>vgg16<span class="token punctuation">.</span><span class="token function">load_state_dict</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“vgg16_method2.pth”</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token comment"># model &#x3D; torch.load(“vgg16_method2.pth”)</span><br><span class="token comment"># print(vgg16)</span></p><p><span class="token comment"># 陷阱1</span><br><span class="token comment"># class Tudui(nn.Module):</span><br><span class="token comment">#     def <strong>init</strong>(self):</span><br><span class="token comment">#         super(Tudui, self).<strong>init</strong>()</span><br><span class="token comment">#         self.conv1 &#x3D; nn.Conv2d(3, 64, kernel_size&#x3D;3)</span><br><span class="token comment">#</span><br><span class="token comment">#     def forward(self, x):</span><br><span class="token comment">#         x &#x3D; self.conv1(x)</span><br><span class="token comment">#         return x</span></p><p>model <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token string">‘tudui_method1.pth’</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span></p><div class="hljs-button &#123;2&#125;" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li></ul></pre> <p>只用方式2！！！！</p> <h1><a name="t30"></a><a id="_560"></a>十九、完整的模型训练套路</h1> <p><img src="https://img-blog.csdnimg.cn/c2e22acbb0644a24aaf863432d5ce18d.png" alt="在这里插入图片描述"></p> <pre data-index="11" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchvisionfrom my_model <span class="token keyword">import</span>  <span class="token operator">*</span>from torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">tensorboard</span> <span class="token keyword">import</span> SummaryWriter<p><span class="token comment">#准备数据集</span><br>from torch <span class="token keyword">import</span> nn<br>from torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoader</p><p>train_data <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span>root<span class="token operator">&#x3D;</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span>train<span class="token operator">&#x3D;</span>True<span class="token punctuation">,</span>transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span><br>test_data <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span>root<span class="token operator">&#x3D;</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span>train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span>transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p><span class="token comment"># length 长度</span><br>train_data_size <span class="token operator">&#x3D;</span> <span class="token function">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><br>test_data_size <span class="token operator">&#x3D;</span> <span class="token function">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><br><span class="token comment"># 如果train_data_size&#x3D;10,训练数据集的长度为：10</span><br><span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“训练数据集的长度为:&#123;&#125;”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“测试数据集的长度为:&#123;&#125;”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></p><p><span class="token comment">#利用 DataLoader 来加载数据集</span><br>train_dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span><br>test_dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token comment">#创建网络模型</span><br>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p><span class="token comment">#损失函数</span><br>loss_fn <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><p><span class="token comment">#优化器</span><br>learning_rate <span class="token operator">&#x3D;</span> <span class="token number">1e-2</span><br>optimizer <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">optim</span><span class="token punctuation">.</span><span class="token function">SGD</span><span class="token punctuation">(</span>tudui<span class="token punctuation">.</span><span class="token function">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">&#x3D;</span>learning_rate<span class="token punctuation">)</span></p><p><span class="token comment">#训练网络的一些参数</span><br><span class="token comment">#记录训练的次数</span><br>total_train_step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br><span class="token comment">#记录测试的次数</span><br>total_test_step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br><span class="token comment">#训练的轮数</span><br>epoch <span class="token operator">&#x3D;</span> <span class="token number">10</span></p><p><span class="token comment">#添加tensorboard</span><br>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs_train”</span></span><span class="token punctuation">)</span></p><p>for i <span class="token operator">in</span> <span class="token function">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“———–第&#123;&#125;轮训练开始———–”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><pre><code class="hljs">&lt;span class=&quot;token comment&quot;&gt;#训练步骤开始&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;for data &lt;span class=&quot;token operator&quot;&gt;in&lt;/span&gt; train_dataloader&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    imgs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; data    outputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;tudui&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;imgs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;token comment&quot;&gt;#优化器优化模型&lt;/span&gt;    optimizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    optimizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    total_train_step &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; total_train_step &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;        &lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;训练次数：&#123;&#125;,Loss:&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_train_step&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;train_loss&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_train_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token comment&quot;&gt;# 测试步骤开始&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;total_test_loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;total_accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;with torch&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    for data &lt;span class=&quot;token operator&quot;&gt;in&lt;/span&gt; test_dataloader&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;        imgs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; data        outputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;tudui&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;imgs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        total_test_loss &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; loss        accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        total_accuracy &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; accuracy&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;整体集上的Loss:&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_test_loss&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;整体数据集上的正确率：&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_accuracy&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;test_data_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;test_loss&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;test_accuracy&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_accuracy&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;test_data_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;total_test_step &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;torch&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;tudui_&#123;&#125;.pth&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token comment&quot;&gt;#torch.save(tudui.state_dict(),&quot;tudui_&#123;&#125;&quot;.format(i))&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;模型已保存&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;</code></pre><p>writer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li style="color: rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li style="color: rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li style="color: rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, 153);">73</li><li style="color: rgb(153, 153, 153);">74</li><li style="color: rgb(153, 153, 153);">75</li><li style="color: rgb(153, 153, 153);">76</li><li style="color: rgb(153, 153, 153);">77</li><li style="color: rgb(153, 153, 153);">78</li><li style="color: rgb(153, 153, 153);">79</li><li style="color: rgb(153, 153, 153);">80</li><li style="color: rgb(153, 153, 153);">81</li><li style="color: rgb(153, 153, 153);">82</li><li style="color: rgb(153, 153, 153);">83</li><li style="color: rgb(153, 153, 153);">84</li><li style="color: rgb(153, 153, 153);">85</li><li style="color: rgb(153, 153, 153);">86</li><li style="color: rgb(153, 153, 153);">87</li><li style="color: rgb(153, 153, 153);">88</li><li style="color: rgb(153, 153, 153);">89</li><li style="color: rgb(153, 153, 153);">90</li><li style="color: rgb(153, 153, 153);">91</li></ul></pre> <h1><a name="t31"></a><a id="GPU_656"></a>二十、利用GPU训练</h1> <p><img src="https://img-blog.csdnimg.cn/022208fc454341fd9bb76b40fb71e7e2.png" alt="在这里插入图片描述"></p> <pre data-index="12" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token keyword">import</span> torchvisionfrom torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">tensorboard</span> <span class="token keyword">import</span> SummaryWriter<span class="token keyword">import</span> torch<span class="token keyword">import</span> time<p><span class="token comment">#准备数据集</span><br>from torch <span class="token keyword">import</span> nn<br>from torch<span class="token punctuation">.</span><span class="token function">utils</span><span class="token punctuation">.</span><span class="token function">data</span> <span class="token keyword">import</span> DataLoader</p><p>device <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">device</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“cuda”</span></span><span class="token punctuation">)</span><br>train_data <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span>root<span class="token operator">&#x3D;</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span>train<span class="token operator">&#x3D;</span>True<span class="token punctuation">,</span>transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span><br>test_data <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">datasets</span><span class="token punctuation">.</span><span class="token function">CIFAR10</span><span class="token punctuation">(</span>root<span class="token operator">&#x3D;</span><span class="token string"><span class="token double-quoted">“..&#x2F;data”</span></span><span class="token punctuation">,</span>train<span class="token operator">&#x3D;</span>False<span class="token punctuation">,</span>transform<span class="token operator">&#x3D;</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">&#x3D;</span>True<span class="token punctuation">)</span></p><p><span class="token comment"># length 长度</span><br>train_data_size <span class="token operator">&#x3D;</span> <span class="token function">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><br>test_data_size <span class="token operator">&#x3D;</span> <span class="token function">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><br><span class="token comment"># 如果train_data_size&#x3D;10,训练数据集的长度为：10</span><br><span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“训练数据集的长度为:&#123;&#125;”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“测试数据集的长度为:&#123;&#125;”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span></p><p><span class="token comment">#利用 DataLoader 来加载数据集</span><br>train_dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span><br>test_dataloader <span class="token operator">&#x3D;</span> <span class="token function">DataLoader</span><span class="token punctuation">(</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">&#x3D;</span><span class="token number">64</span><span class="token punctuation">)</span></p><p><span class="token comment">#创建网络模型</span><br><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">model</span> <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token operator"><em></span><span class="token number">4</span><span class="token operator"></em></span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><br>        <span class="token punctuation">)</span><br>    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        x<span class="token operator">&#x3D;</span>self<span class="token punctuation">.</span><span class="token function">model</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><br>        return x<br>tudui <span class="token operator">&#x3D;</span> <span class="token function">Tudui</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>tudui<span class="token operator">&#x3D;</span>tudui<span class="token punctuation">.</span><span class="token function">to</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span></p><p><span class="token comment">#损失函数</span><br>loss_fn <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">CrossEntropyLoss</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>loss_fn <span class="token operator">&#x3D;</span> loss_fn<span class="token punctuation">.</span><span class="token function">to</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span></p><p><span class="token comment">#优化器</span><br>learning_rate <span class="token operator">&#x3D;</span> <span class="token number">1e-2</span><br>optimizer <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">optim</span><span class="token punctuation">.</span><span class="token function">SGD</span><span class="token punctuation">(</span>tudui<span class="token punctuation">.</span><span class="token function">parameters</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">&#x3D;</span>learning_rate<span class="token punctuation">)</span></p><p><span class="token comment">#训练网络的一些参数</span><br><span class="token comment">#记录训练的次数</span><br>total_train_step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br><span class="token comment">#记录测试的次数</span><br>total_test_step <span class="token operator">&#x3D;</span> <span class="token number">0</span><br><span class="token comment">#训练的轮数</span><br>epoch <span class="token operator">&#x3D;</span> <span class="token number">10</span></p><p><span class="token comment">#添加tensorboard</span><br>writer <span class="token operator">&#x3D;</span> <span class="token function">SummaryWriter</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“..&#x2F;logs_train”</span></span><span class="token punctuation">)</span></p><p>start_time<span class="token operator">&#x3D;</span>time<span class="token punctuation">.</span><span class="token function">time</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>for i <span class="token operator">in</span> <span class="token function">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span><br>    <span class="token function">print</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“———–第&#123;&#125;轮训练开始———–”</span></span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><pre><code class="hljs">&lt;span class=&quot;token comment&quot;&gt;#训练步骤开始&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;for data &lt;span class=&quot;token operator&quot;&gt;in&lt;/span&gt; train_dataloader&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    imgs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; data    imgs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; imgs&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;device&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; targets&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;device&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    outputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;tudui&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;imgs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;token comment&quot;&gt;#优化器优化模型&lt;/span&gt;    optimizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    optimizer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    total_train_step &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;    &lt;span class=&quot;token keyword&quot;&gt;if&lt;/span&gt; total_train_step &lt;span class=&quot;token operator&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;        end_time &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; time&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        &lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;end_time&lt;span class=&quot;token operator&quot;&gt;-&lt;/span&gt;start_time&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        &lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;训练次数：&#123;&#125;,Loss:&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_train_step&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;train_loss&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;loss&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_train_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token comment&quot;&gt;# 测试步骤开始&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;total_test_loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;total_accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;0&lt;/span&gt;with torch&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    for data &lt;span class=&quot;token operator&quot;&gt;in&lt;/span&gt; test_dataloader&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;        imgs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; data        imgs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; imgs&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;device&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        targets &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; targets&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;device&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        outputs &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;tudui&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;imgs&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        loss &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token function&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        total_test_loss &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; loss        accuracy &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;outputs&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;==&lt;/span&gt;targets&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;        total_accuracy &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; accuracy&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;整体集上的Loss:&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_test_loss&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;整体数据集上的正确率：&#123;&#125;&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;total_accuracy&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;test_data_size&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;test_loss&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_loss&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;writer&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;add_scalar&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;test_accuracy&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_accuracy&lt;span class=&quot;token operator&quot;&gt;/&lt;/span&gt;test_data_size&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;total_test_step&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;total_test_step &lt;span class=&quot;token operator&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;torch&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;tudui&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;tudui_&#123;&#125;.pth&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;i&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token comment&quot;&gt;#torch.save(tudui.state_dict(),&quot;tudui_&#123;&#125;&quot;.format(i))&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;token string&quot;&gt;&lt;span class=&quot;token double-quoted&quot;&gt;&quot;模型已保存&quot;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;</code></pre><p>writer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li><li style="color: rgb(153, 153, 153);">49</li><li style="color: rgb(153, 153, 153);">50</li><li style="color: rgb(153, 153, 153);">51</li><li style="color: rgb(153, 153, 153);">52</li><li style="color: rgb(153, 153, 153);">53</li><li style="color: rgb(153, 153, 153);">54</li><li style="color: rgb(153, 153, 153);">55</li><li style="color: rgb(153, 153, 153);">56</li><li style="color: rgb(153, 153, 153);">57</li><li style="color: rgb(153, 153, 153);">58</li><li style="color: rgb(153, 153, 153);">59</li><li style="color: rgb(153, 153, 153);">60</li><li style="color: rgb(153, 153, 153);">61</li><li style="color: rgb(153, 153, 153);">62</li><li style="color: rgb(153, 153, 153);">63</li><li style="color: rgb(153, 153, 153);">64</li><li style="color: rgb(153, 153, 153);">65</li><li style="color: rgb(153, 153, 153);">66</li><li style="color: rgb(153, 153, 153);">67</li><li style="color: rgb(153, 153, 153);">68</li><li style="color: rgb(153, 153, 153);">69</li><li style="color: rgb(153, 153, 153);">70</li><li style="color: rgb(153, 153, 153);">71</li><li style="color: rgb(153, 153, 153);">72</li><li style="color: rgb(153, 153, 153);">73</li><li style="color: rgb(153, 153, 153);">74</li><li style="color: rgb(153, 153, 153);">75</li><li style="color: rgb(153, 153, 153);">76</li><li style="color: rgb(153, 153, 153);">77</li><li style="color: rgb(153, 153, 153);">78</li><li style="color: rgb(153, 153, 153);">79</li><li style="color: rgb(153, 153, 153);">80</li><li style="color: rgb(153, 153, 153);">81</li><li style="color: rgb(153, 153, 153);">82</li><li style="color: rgb(153, 153, 153);">83</li><li style="color: rgb(153, 153, 153);">84</li><li style="color: rgb(153, 153, 153);">85</li><li style="color: rgb(153, 153, 153);">86</li><li style="color: rgb(153, 153, 153);">87</li><li style="color: rgb(153, 153, 153);">88</li><li style="color: rgb(153, 153, 153);">89</li><li style="color: rgb(153, 153, 153);">90</li><li style="color: rgb(153, 153, 153);">91</li><li style="color: rgb(153, 153, 153);">92</li><li style="color: rgb(153, 153, 153);">93</li><li style="color: rgb(153, 153, 153);">94</li><li style="color: rgb(153, 153, 153);">95</li><li style="color: rgb(153, 153, 153);">96</li><li style="color: rgb(153, 153, 153);">97</li><li style="color: rgb(153, 153, 153);">98</li><li style="color: rgb(153, 153, 153);">99</li><li style="color: rgb(153, 153, 153);">100</li><li style="color: rgb(153, 153, 153);">101</li><li style="color: rgb(153, 153, 153);">102</li><li style="color: rgb(153, 153, 153);">103</li><li style="color: rgb(153, 153, 153);">104</li><li style="color: rgb(153, 153, 153);">105</li><li style="color: rgb(153, 153, 153);">106</li><li style="color: rgb(153, 153, 153);">107</li><li style="color: rgb(153, 153, 153);">108</li><li style="color: rgb(153, 153, 153);">109</li><li style="color: rgb(153, 153, 153);">110</li><li style="color: rgb(153, 153, 153);">111</li><li style="color: rgb(153, 153, 153);">112</li><li style="color: rgb(153, 153, 153);">113</li><li style="color: rgb(153, 153, 153);">114</li><li style="color: rgb(153, 153, 153);">115</li><li style="color: rgb(153, 153, 153);">116</li><li style="color: rgb(153, 153, 153);">117</li><li style="color: rgb(153, 153, 153);">118</li><li style="color: rgb(153, 153, 153);">119</li><li style="color: rgb(153, 153, 153);">120</li><li style="color: rgb(153, 153, 153);">121</li><li style="color: rgb(153, 153, 153);">122</li></ul></pre> <h1><a name="t32"></a><a id="_784"></a>二十一、完整的模型验证套路</h1> <pre data-index="13" class="set-code-hide prettyprint"><code class="prism language-puppet has-numbering" onclick="mdcp.copyCode(event)" style="position: unset;"><span class="token comment"># -*- coding: utf-8 -*-</span><span class="token comment"># 作者：小土堆</span><span class="token comment"># 公众号：土堆碎念</span><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvisionfrom PIL <span class="token keyword">import</span> Imagefrom torch <span class="token keyword">import</span> nn<p>image_path <span class="token operator">&#x3D;</span> <span class="token string"><span class="token double-quoted">“..&#x2F;imgs&#x2F;airplane.png”</span></span><br>image <span class="token operator">&#x3D;</span> Image<span class="token punctuation">.</span><span class="token function">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><br>image <span class="token operator">&#x3D;</span> image<span class="token punctuation">.</span><span class="token function">convert</span><span class="token punctuation">(</span><span class="token string">‘RGB’</span><span class="token punctuation">)</span>    <span class="token comment"># 因为png格式是四通道，除了RGB三通道外，还有一个透明度通道，</span><br><span class="token comment"># 调用convert保留其颜色通道。当然，如果图片本来就是三个颜色通道，经此操作，不变。加上这一步可以适应png jpg各种格式的图片</span><br>transform <span class="token operator">&#x3D;</span> torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">Compose</span><span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">Resize</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>                                            torchvision<span class="token punctuation">.</span><span class="token function">transforms</span><span class="token punctuation">.</span><span class="token function">ToTensor</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span></p><p>image <span class="token operator">&#x3D;</span> <span class="token function">transform</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span><span class="token function">shape</span><span class="token punctuation">)</span></p><p><span class="token keyword">class</span> <span class="token function">Tudui</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span><span class="token function">Module</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    def <span class="token function"><strong>init</strong></span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><br>        <span class="token function">super</span><span class="token punctuation">(</span>Tudui<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function"><strong>init</strong></span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        self<span class="token punctuation">.</span><span class="token function">model</span> <span class="token operator">&#x3D;</span> nn<span class="token punctuation">.</span><span class="token function">Sequential</span><span class="token punctuation">(</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Conv2d</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">MaxPool2d</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Flatten</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token operator"><em></span><span class="token number">4</span><span class="token operator"></em></span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span><br>            nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><br>        <span class="token punctuation">)</span></p><pre><code class="hljs">def &lt;span class=&quot;token function&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;self&lt;span class=&quot;token punctuation&quot;&gt;,&lt;/span&gt; x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;/span&gt;    x &lt;span class=&quot;token operator&quot;&gt;=&lt;/span&gt; self&lt;span class=&quot;token punctuation&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;token function&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;token punctuation&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;token punctuation&quot;&gt;)&lt;/span&gt;    return x</code></pre><p>model <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span><span class="token string"><span class="token double-quoted">“tudui_29_gpu.pth”</span></span><span class="token punctuation">,</span> map_location<span class="token operator">&#x3D;</span>torch<span class="token punctuation">.</span><span class="token function">device</span><span class="token punctuation">(</span><span class="token string">‘cpu’</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><br>image <span class="token operator">&#x3D;</span> torch<span class="token punctuation">.</span><span class="token function">reshape</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br>model<span class="token punctuation">.</span><span class="token function">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>with torch<span class="token punctuation">.</span><span class="token function">no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><br>    output <span class="token operator">&#x3D;</span> <span class="token function">model</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><br><span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></p><p><span class="token function">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span><span class="token function">argmax</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span></p><div class="hljs-button {2}" data-title="复制"></div></code><div class="hide-preCode-box"><span class="hide-preCode-bt" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.7365&quot;}"><img class="look-more-preCode contentImg-no-view" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCodeMoreWhite.png" alt="" title=""></span></div><ul class="pre-numbering" style=""><li style="color: rgb(153, 153, 153);">1</li><li style="color: rgb(153, 153, 153);">2</li><li style="color: rgb(153, 153, 153);">3</li><li style="color: rgb(153, 153, 153);">4</li><li style="color: rgb(153, 153, 153);">5</li><li style="color: rgb(153, 153, 153);">6</li><li style="color: rgb(153, 153, 153);">7</li><li style="color: rgb(153, 153, 153);">8</li><li style="color: rgb(153, 153, 153);">9</li><li style="color: rgb(153, 153, 153);">10</li><li style="color: rgb(153, 153, 153);">11</li><li style="color: rgb(153, 153, 153);">12</li><li style="color: rgb(153, 153, 153);">13</li><li style="color: rgb(153, 153, 153);">14</li><li style="color: rgb(153, 153, 153);">15</li><li style="color: rgb(153, 153, 153);">16</li><li style="color: rgb(153, 153, 153);">17</li><li style="color: rgb(153, 153, 153);">18</li><li style="color: rgb(153, 153, 153);">19</li><li style="color: rgb(153, 153, 153);">20</li><li style="color: rgb(153, 153, 153);">21</li><li style="color: rgb(153, 153, 153);">22</li><li style="color: rgb(153, 153, 153);">23</li><li style="color: rgb(153, 153, 153);">24</li><li style="color: rgb(153, 153, 153);">25</li><li style="color: rgb(153, 153, 153);">26</li><li style="color: rgb(153, 153, 153);">27</li><li style="color: rgb(153, 153, 153);">28</li><li style="color: rgb(153, 153, 153);">29</li><li style="color: rgb(153, 153, 153);">30</li><li style="color: rgb(153, 153, 153);">31</li><li style="color: rgb(153, 153, 153);">32</li><li style="color: rgb(153, 153, 153);">33</li><li style="color: rgb(153, 153, 153);">34</li><li style="color: rgb(153, 153, 153);">35</li><li style="color: rgb(153, 153, 153);">36</li><li style="color: rgb(153, 153, 153);">37</li><li style="color: rgb(153, 153, 153);">38</li><li style="color: rgb(153, 153, 153);">39</li><li style="color: rgb(153, 153, 153);">40</li><li style="color: rgb(153, 153, 153);">41</li><li style="color: rgb(153, 153, 153);">42</li><li style="color: rgb(153, 153, 153);">43</li><li style="color: rgb(153, 153, 153);">44</li><li style="color: rgb(153, 153, 153);">45</li><li style="color: rgb(153, 153, 153);">46</li><li style="color: rgb(153, 153, 153);">47</li><li style="color: rgb(153, 153, 153);">48</li></ul></pre> <hr> <h1><a name="t33"></a><a id="_839"></a>总结</h1> <p>。</p>                </div><div data-report-view="{&quot;mod&quot;:&quot;1585297308_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6548&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_44428997/article/details/127117489&quot;,&quot;extend1&quot;:&quot;pc&quot;,&quot;ab&quot;:&quot;new&quot;}"><div></div></div>                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-98b95bb57c.css" rel="stylesheet">                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-c216769e99.css" rel="stylesheet">        </div>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch深度学习2: Tensorboard的使用</title>
    <link href="/2023/08/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-Tensorboard%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/08/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-Tensorboard%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>源代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>image_path = <span class="hljs-string">&quot;data/train/ants_image/6240329_72c01e663e.jpg&quot;</span><br>img_PIL = Image.<span class="hljs-built_in">open</span>(image_path)<br>img_array = np.array(img_PIL)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(img_array))<br><span class="hljs-built_in">print</span>(img_array.shape)<br><br>writer.add_image(<span class="hljs-string">&quot;train&quot;</span>, img_array, <span class="hljs-number">1</span>, dataformats=<span class="hljs-string">&#x27;HWC&#x27;</span>)  <span class="hljs-comment"># 此处注意dataformats需要和图片的对应</span><br><span class="hljs-comment"># y = 2x</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=2x&quot;</span>, <span class="hljs-number">3</span>*i, i)<br><br>writer.close()<br></code></pre></td></tr></table></figure><p>流程：</p><p>创建 SummaryWriter 类，传入 logs 文件输出地址<br>图片文件地址<br>Image 类打开图片文件<br>将 Image 类转换 numpy 格式<br>SummaryWriter 类加载 numpy 格式图片<br>画图<br>关闭 SummaryWriter 流</p><p>运行方式：</p><p>打开 anaconda prompt，输入</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs applescript">conda <span class="hljs-built_in">activate</span> pytorch<br></code></pre></td></tr></table></figure><p>进入 pytorch 环境下 ，输入</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">tensorboard <span class="hljs-params">--logdir</span> <span class="hljs-string">&quot;文件夹绝对地址&quot;</span> <span class="hljs-params">--port=6007</span><span class="hljs-params">(optional)</span><br></code></pre></td></tr></table></figure><p>然后进入 <a href="http://localhost:6006/">http://localhost:6006/</a> 查看图片和曲线</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch深度学习1：Dataset类</title>
    <link href="/2023/08/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01%EF%BC%9ADataset%E7%B1%BB/"/>
    <url>/2023/08/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01%EF%BC%9ADataset%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<p>来自于 b 站《PyTorch 深度学习快速入门教程（绝对通俗易懂！）【小土堆】》</p><p>本篇内容主要是对代码中的一些小知识点进行归纳总结，以便复习</p><p>下面是主要代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset    <span class="hljs-comment">#引入Dataset类</span><br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,root_dir,label_dir</span>):  <span class="hljs-comment">#属性</span><br><br>        self.root_dir=root_dir<br>        self.label_dir=label_dir<br>        self.path=os.path.join(self.root_dir,self.label_dir)<br>        self.img_path=os.listdir(self.path)     <span class="hljs-comment">#返回路径指定的文件夹包含的文件或文件夹的名字的列表</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):     <span class="hljs-comment">#方法</span><br><br>        img_name=self.img_path[idx]<br>        img_item_path=os.path.join(self.root_dir,self.label_dir,img_name) <span class="hljs-comment">#实现路径组合</span><br>        img=Image.<span class="hljs-built_in">open</span>(img_item_path)<br>        label=self.label_dir<br>        <span class="hljs-keyword">return</span> img, label<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):              <span class="hljs-comment">#获取列表的长度</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.img_path)<br><span class="hljs-comment">#实际运行</span><br>root_dir=<span class="hljs-string">&quot;dataset/train&quot;</span><br>ants_label_dir=<span class="hljs-string">&quot;ants_image&quot;</span><br>ants_dataset=MyData(root_dir,ants_label_dir)<br>target_dir=<span class="hljs-string">&quot;ants_image&quot;</span><br>label=target_dir.split(<span class="hljs-string">&#x27;_&#x27;</span>)[<span class="hljs-number">0</span>]<br>img_path=os.listdir(os.path.join(root_dir,target_dir))<br>out_dir=<span class="hljs-string">&quot;ants_label&quot;</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> img_path:<br>    file_name=i.split(<span class="hljs-string">&#x27;.jpg&#x27;</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(root_dir,out_dir,<span class="hljs-string">&quot;&#123;&#125;.txt&quot;</span>.<span class="hljs-built_in">format</span>(file_name)),<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(label)<br>        <span class="hljs-comment"># 写文件操作，将标签写入root_dir/out_dir并创建txt文件，文件内容为label</span><br>        <span class="hljs-comment"># &#x27;w&#x27;: 打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。</span><br></code></pre></td></tr></table></figure><p>另外，配环境配了好久。。。</p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>欢迎来到小何同学的博客！</title>
    <link href="/2023/08/06/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E5%B0%8F%E4%BD%95%E5%90%8C%E5%AD%A6%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%81/"/>
    <url>/2023/08/06/%E6%AC%A2%E8%BF%8E%E6%9D%A5%E5%88%B0%E5%B0%8F%E4%BD%95%E5%90%8C%E5%AD%A6%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%81/</url>
    
    <content type="html"><![CDATA[<p>大家好，我是何昊宇，现就读于南京大学</p><p>目前主要研究兴趣是 CV 和 DL</p><p>在这里我将分享我的学习笔记与心得体会</p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
